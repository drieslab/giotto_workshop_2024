[["index.html", "Workshop: Spatial multi-omics data analysis with Giotto Suite 1 Giotto Suite Workshop 2024 1.1 Instructors 1.2 Topics and Schedule: 1.3 License", " Workshop: Spatial multi-omics data analysis with Giotto Suite Ruben Dries, Jiaji George Chen, Joselyn Cristina Chávez-Fuentes, Junxiang Xu ,Edward Ruiz, Jeff Sheridan, Iqra Amin, Wen Wang 1 Giotto Suite Workshop 2024 Workshop: Spatial multi-omics data analysis with Giotto Suite Github repo: https://github.com/drieslab/giotto_workshop_2024/ Giotto Suite Website: http://www.giottosuite.com Twitter/X: https://x.com/GiottoSpatial 1.1 Instructors Ruben Dries: Assistant Professor of Medicine at Boston University Joselyn Cristina Chávez Fuentes: Postdoctoral fellow at Icahn School of Medicine at Mount Sinai Jiaji George Chen: Ph.D. student at Boston University Junxiang Xu: Ph.D. student at Boston University Edward C. Ruiz: Ph.D. student at Boston University Jeff Sheridan: Postdoctoral fellow at Boston University Iqra Amin: Bioinformatician Wen Wang: Postdoctoral fellow at Icahn School of Medicine at Mount Sinai 1.2 Topics and Schedule: Day 1: Introduction Spatial omics technologies Spatial sequencing Spatial in situ Spatial proteomics spatial other: ATAC-seq, lipidomics, etc Introduction to the Giotto package Ecosystem Installation + python environment Giotto instructions Data formatting and Pre-processing Creating a Giotto object From matrix + locations From subcellular raw data (transcripts or images) + polygons Using convenience functions for popular technologies (Vizgen, Xenium, CosMx, …) Spatial plots Subsetting: Based on IDs Based on locations Visualizations Introduction to spatial multi-modal dataset (10X Genomics breast cancer) and goal for the next days Quality control Statistics Normalization Feature selection: Highly Variable Features: loess regression binned pearson residuals Spatial variable genes Dimension Reduction PCA UMAP/t-SNE Visualizations Clustering Non-spatial k-means Hierarchical clustering Leiden/Louvain Spatial Spatial variable genes Spatial co-expression modules Day 2: Spatial Data Analysis Spatial sequencing based technology: Visium Differential expression Enrichment &amp; Deconvolution PAGE/Rank SpatialDWLS Visualizations Interactive tools Spatial expression patterns Spatial variable genes Spatial co-expression modules Spatial HMRF Spatial sequencing based technology: Visium HD Tiling and aggregation Scalability (duckdb) and projection functions Spatial expression patterns Spatial co-expression module Spatial in situ technology: Xenium Read in raw data Transcript coordinates Polygon coordinates Visualizations Overlap txs &amp; polygons Typical aggregated workflow Feature/molecule specific analysis Visualizations Transcript enrichment GSEA Spatial location analysis Spatial cell type co-localization analysis Spatial niche analysis Spatial niche trajectory analysis Visualizations Spatial proteomics: multiplex IF Read in raw data Intensity data (IF or any other image) Polygon coordinates Visualizations Overlap intensity &amp; workflows Typical aggregated workflow Visualizations Day 3: Advanced Tutorials Multiple samples Create individual giotto objects Join Giotto Objects Perform Harmony and default workflows Visualizations Spatial multi-modal Co-registration of datasets Examples in giotto suite manuscript Multi-omics integration Example in giotto suite manuscript Interoperability w/ other frameworks AnnData/SpatialData SpatialExperiment Seurat Interoperability w/ isolated tools Spatial niche trajectory analysis Interactivity with the R/Spatial ecosystem Kriging Contributing to Giotto 1.3 License This material has a Creative Commons Attribution-ShareAlike 4.0 International License. To get more information about this license, visit http://creativecommons.org/licenses/by-sa/4.0/ "],["datasets-packages.html", "2 Datasets &amp; Packages 2.1 Datasets to download 2.2 Needed packages", " 2 Datasets &amp; Packages 2.1 Datasets to download Please download the following datasets to reproduce the examples. You can download them from their original source using the individual links listed below or download all of them from the following Zenodo repository: 2.1.1 Zenodo repository https://zenodo.org/communities/gw2024/records?q=&amp;l=list&amp;p=1&amp;s=10&amp;sort=newest 2.1.2 10X Genomics Visium Mouse Brain Section (Coronal) dataset https://support.10xgenomics.com/spatial-gene-expression/datasets/1.1.0/V1_Adult_Mouse_Brain 2.1.3 10X Genomics Visium HD: FFPE Human Colon Cancer https://www.10xgenomics.com/datasets/visium-hd-cytassist-gene-expression-libraries-of-human-crc 2.1.4 10X Genomics multi-modal dataset https://www.10xgenomics.com/products/xenium-in-situ/preview-dataset-human-breast 2.1.5 10X Genomics multi-omics Visium CytAssist Human Tonsil dataset https://www.10xgenomics.com/resources/datasets/gene-protein-expression-library-of-human-tonsil-cytassist-ffpe-2-standard 2.1.6 10X Genomics Human Prostate Cancer Adenocarcinoma with Invasive Carcinoma (FFPE) https://www.10xgenomics.com/datasets/human-prostate-cancer-adenocarcinoma-with-invasive-carcinoma-ffpe-1-standard-1-3-0 2.1.7 10X Genomics Normal Human Prostate (FFPE) https://www.10xgenomics.com/datasets/normal-human-prostate-ffpe-1-standard-1-3-0 2.1.8 Xenium https://www.10xgenomics.com/datasets/preview-data-ffpe-human-lung-cancer-with-xenium-multimodal-cell-segmentation-1-standard 2.1.9 MERFISH cortex dataset https://doi.brainimagelibrary.org/doi/10.35077/g.21 2.2 Needed packages 2.2.1 CRAN dependencies: cran_dependencies &lt;- c(&quot;BiocManager&quot;, &quot;devtools&quot;, &quot;pak&quot;) install.packages(cran_dependencies, Ncpus = 4) 2.2.2 terra installation terra may have some additional steps when installing depending on which system you are on. Please see the terra repo for specifics. Installations of the CRAN release on Windows and Mac are expected to be simple, only requiring the code below. For Linux, there are several prerequisite installs: GDAL (&gt;= 2.2.3), GEOS (&gt;= 3.4.0), PROJ (&gt;= 4.9.3), sqlite3 On our AlmaLinux 8 HPC, the following versions have been working well: gdal/3.6.4 geos/3.11.1 proj/9.2.0 sqlite3/3.37.2 install.packages(&quot;terra&quot;) 2.2.3 Matrix installation !! FOR R VERSIONS LOWER THAN 4.4.0 !! Giotto requires Matrix 1.6-2 or greater, but when installing Giotto with pak on an R version lower than 4.4.0, the installation can fail asking for R 4.5 which doesn’t exist yet. We can solve this by installing the 1.6-5 version directly by un-commenting and running the line below. # devtools::install_version(&quot;Matrix&quot;, version = &quot;1.6-5&quot;) 2.2.4 Giotto installation pak::pak(&quot;drieslab/Giotto&quot;) pak::pak(&quot;drieslab/GiottoData&quot;) 2.2.5 irlba install Reinstall irlba from source. Avoids the common function 'as_cholmod_sparse' not provided by package 'Matrix' error. See this issue for more info. install.packages(&quot;irlba&quot;, type = &quot;source&quot;) 2.2.6 arrow install arrow is a suggested package that we use here to open parquet files. The parquet files that 10X provides use zstd compression which the default arrow installation may not provide. has_arrow &lt;- requireNamespace(&quot;arrow&quot;, quietly = TRUE) zstd &lt;- TRUE if (has_arrow) { zstd &lt;- arrow::arrow_info()$capabilities[[&quot;zstd&quot;]] } if (!has_arrow || !zstd) { Sys.setenv(ARROW_WITH_ZSTD = &quot;ON&quot;) install.packages(&quot;arrow&quot;, repos = c(&quot;https://apache.r-universe.dev&quot;)) } 2.2.7 Bioconductor dependencies: bioc_dependencies &lt;- c( &quot;scran&quot;, &quot;ComplexHeatmap&quot;, &quot;SpatialExperiment&quot;, &quot;ggspavis&quot;, &quot;scater&quot;, &quot;nnSVG&quot; ) 2.2.8 CRAN packages: needed_packages_cran &lt;- c( &quot;dplyr&quot;, &quot;gstat&quot;, &quot;hdf5r&quot;, &quot;miniUI&quot;, &quot;shiny&quot;, &quot;xml2&quot;, &quot;future&quot;, &quot;future.apply&quot;, &quot;exactextractr&quot;, &quot;tidyr&quot;, &quot;viridis&quot;, &quot;quadprog&quot;, &quot;Rfast&quot;, &quot;pheatmap&quot;, &quot;patchwork&quot;, &quot;Seurat&quot;, &quot;SeuratData&quot;, &quot;harmony&quot;, &quot;scatterpie&quot;, &quot;R.utils&quot;, &quot;qs&quot; ) pak::pkg_install(c(bioc_dependencies, needed_packages_cran)) 2.2.9 Packages from GitHub github_packages &lt;- c( &quot;satijalab/seurat-data&quot; ) pak::pkg_install(github_packages) 2.2.10 Python environments # default giotto environment Giotto::installGiottoEnvironment() # install another environment with py 3.8 for cellpose reticulate::conda_create(envname = &quot;giotto_cellpose&quot;, python_version = 3.8) reticulate::py_install( pip = TRUE, envname = &#39;giotto_cellpose&#39;, packages = c( &quot;pandas&quot;, &quot;networkx&quot;, &quot;python-igraph&quot;, &quot;leidenalg&quot;, &quot;scikit-learn&quot;, &quot;cellpose&quot;, &quot;smfishhmrf&quot;, &quot;git+https://github.com/wwang-chcn/bento-tools.git@giotto_install&quot; ) ) "],["spatial-omics-technologies.html", "3 Spatial omics technologies 3.1 Presentation 3.2 Short summary", " 3 Spatial omics technologies Ruben Dries August 5th 2024 3.1 Presentation 3.2 Short summary 3.2.1 Why do we need spatial omics technologies? Spatial omics allows us to examine the role of one or more cells within its normal context. This spatial context is typically organized at multiple length scales, and considers both adjacent neighboring cells and larger levels of tissue organization. 3.2.2 What is spatial omics? Spatial omics is typically a combination of spatial sequencing and/or imaging together with understanding the obtained results through spatial data science. 3.2.3 What are the main spatial omics technologies? The large majority - and most popular or accessible - spatial technologies are: - spatial antibody-multiplex proteomics - spatial multiplex in situ hybridization (ISH)-based transcriptomics - spatial sequencing-based transcriptomics 3.2.4 Other Spatial omics: ATAC-seq, CUT&amp;Tag, lipidomics, etc A growing number of other spatial technologies exist that profile different types of molecular analytes. One example is using a deterministic barcoding approach (Rong Fan’s group) to explore open (ATAC-seq) or modified (CUT&amp;Tag) chromatin in a spatially aware manner. 3.2.5 What are the different types of spatial downstream analyses? There exist a large and diverse amount of different downstream spatial data analyses that use different available data types and formats as input. "],["introduction-to-the-giotto-package.html", "4 Introduction to the Giotto package 4.1 Presentation 4.2 Ecosystem 4.3 Installation + python environment 4.4 Giotto instructions", " 4 Introduction to the Giotto package Ruben Dries &amp; Jiaji George Chen August 5th 2024 4.1 Presentation 4.2 Ecosystem Giotto Suite is a modular ecosystem of individual R packages that each provide different functionality and that together provide users with a fully integrated spatial multi-omics workflow. Each package also has its own website: - GiottoUtils: https://drieslab.github.io/GiottoUtils/ - GiottoClass: https://drieslab.github.io/GiottoClass/ - GiottoData: https://drieslab.github.io/GiottoData/ - GiottoVisuals: https://drieslab.github.io/GiottoVisuals/ More information is available at https://drieslab.github.io/Giotto_website/articles/ecosystem.html 4.3 Installation + python environment 4.4 Giotto instructions "],["data-formatting-and-pre-processing.html", "5 Data formatting and Pre-processing 5.1 Data formats 5.2 Pre-processing", " 5 Data formatting and Pre-processing Jiaji George Chen August 5th 2024 save_dir &lt;- &quot;~/Documents/GitHub/giotto_workshop_2024/img/01_session3&quot; 5.1 Data formats .h5 .mtx - get10xmatrix .parquet .csv/.tsv - fread .json -jsonlite .geojson .tiff/.ome.tif 5.2 Pre-processing necessary additional packages? "],["creating-a-giotto-object.html", "6 Creating a Giotto object 6.1 Overview 6.2 From matrix + locations 6.3 From subcellular raw data (transcripts or images) + polygons 6.4 From piece-wise 6.5 Using convenience functions for popular technologies (Vizgen, Xenium, CosMx, …) 6.6 Spatial plots 6.7 Subsetting 6.8 Mini objects &amp; GiottoData", " 6 Creating a Giotto object Jiaji George Chen August 5th 2024 6.0.1 Used packages Giotto GiottoClass GiottoData pak save_dir &lt;- &quot;~/Documents/GitHub/giotto_workshop_2024/img/01_session4&quot; 6.1 Overview Giotto has representations for both aggregated (cell by count) + xy(z) information and subcellular polygon or mask information and transcript xy(z) or image information. A Giotto object can be set up from either of the two above sets of information. 6.2 From matrix + locations createGiottoObject() 6.3 From subcellular raw data (transcripts or images) + polygons createGiottoObjectSubcellular() The above two methods accept data, converts them into Giotto’s compatible formats, and then assembles the final giotto object. If desired you can also assemble a giotto object piece-wise after creating the Giotto subobjects manually. 6.4 From piece-wise g &lt;- giotto() g &lt;- setGiotto(g, ??) 6.5 Using convenience functions for popular technologies (Vizgen, Xenium, CosMx, …) There are also several convenience functions we provide for loading in data from popular platforms. Many of these will be touched on later during other sessions createGiottoVisiumObject() createGiottoVisiumHDObject() createGiottoXeniumObject() createGiottoCosMxObject() createGiottoMerscopeObject() 6.6 Spatial plots Giotto has several spatial plotting functions. At the lowest level, you directly call plot() on several subobjects in order to see what they look like, particularly the ones containing spatial info. gpoints &lt;- GiottoData::loadSubObjectMini(&quot;giottoPoints&quot;) gpoly &lt;- GiottoData::loadSubObjectMini(&quot;giottoPolygon&quot;) spatlocs &lt;- GiottoData::loadSubObjectMini(&quot;spatLocsObj&quot;) spatnet &lt;- GiottoData::loadSubObjectMini(&quot;spatialNetworkObj&quot;) pca &lt;- GiottoData::loadSubObjectMini(&quot;dimObj&quot;) plot(pca, dims = c(3,10)) 6.7 Subsetting Based on IDs Based on locations Visualizations 6.8 Mini objects &amp; GiottoData Giotto makes available several mini objects to allow devs and users to work with easily loadable Giotto objects. These are small subsets of a larger dataset that often contain some worked through analyses and are fully functional. pak::pak(&quot;drieslab/GiottoData&quot;) "],["visium-part-i.html", "7 Visium Part I 7.1 The Visium technology 7.2 Introduction to the spatial dataset 7.3 Download dataset 7.4 Create the Giotto object 7.5 Subset on spots that were covered by tissue 7.6 Quality control 7.7 Filtering 7.8 Normalization 7.9 Feature selection 7.10 Dimension Reduction 7.11 Clustering 7.12 Save the object 7.13 Session info", " 7 Visium Part I Joselyn Cristina Chávez Fuentes August 5th 2024 7.1 The Visium technology Visium allows you to perform spatial transcriptomics, which combines histological information with whole transcriptome gene expression profiles (fresh frozen or FFPE) to provide you with spatially resolved gene expression. You can use standard fixation and staining techniques, including hematoxylin and eosin (H&amp;E) staining, to visualize tissue sections on slides using a brightfield microscope and immunofluorescence (IF) staining to visualize protein detection in tissue sections on slides using a fluorescent microscope. 7.2 Introduction to the spatial dataset The visium fresh frozen mouse brain tissue (Strain C57BL/6) dataset was obtained from 10X genomics. The tissue was embedded and cryosectioned as described in Visium Spatial Protocols - Tissue Preparation Guide (Demonstrated Protocol CG000240). Tissue sections of 10 µm thickness from a slice of the coronal plane were placed on Visium Gene Expression Slides. You can find more information about his sample here 7.3 Download dataset You need to download the expression matrix and spatial information by running these commands: dir.create(&quot;data&quot;) download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Adult_Mouse_Brain/V1_Adult_Mouse_Brain_raw_feature_bc_matrix.tar.gz&quot;, destfile = &quot;data/V1_Adult_Mouse_Brain_raw_feature_bc_matrix.tar.gz&quot;) download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Adult_Mouse_Brain/V1_Adult_Mouse_Brain_spatial.tar.gz&quot;, destfile = &quot;data/V1_Adult_Mouse_Brain_spatial.tar.gz&quot;) After downloading, unzip the gz files. You should get the “raw_feature_bc_matrix” and “spatial” folders inside “data/”. 7.4 Create the Giotto object library(Giotto) ## Set instructions results_folder &lt;- &quot;results/&quot; python_path &lt;- NULL instructions &lt;- createGiottoInstructions( save_dir = results_folder, save_plot = TRUE, show_plot = FALSE, return_plot = FALSE, python_path = python_path ) ## Provide the path to the visium folder data_path &lt;- &quot;data&quot; ## Create object directly from the visium folder visium_brain &lt;- createGiottoVisiumObject( visium_dir = data_path, expr_data = &quot;raw&quot;, png_name = &quot;tissue_lowres_image.png&quot;, gene_column_index = 2, instructions = instructions ) 7.5 Subset on spots that were covered by tissue spatPlot2D( gobject = visium_brain, cell_color = &quot;in_tissue&quot;, point_size = 2, cell_color_code = c(&quot;0&quot; = &quot;lightgrey&quot;, &quot;1&quot; = &quot;blue&quot;), show_image = TRUE, image_name = &quot;image&quot; ) metadata &lt;- getCellMetadata(gobject = visium_brain, output = &quot;data.table&quot;) in_tissue_barcodes &lt;- metadata[in_tissue == 1]$cell_ID visium_brain &lt;- subsetGiotto(gobject = visium_brain, cell_ids = in_tissue_barcodes) 7.6 Quality control Statistics visium_brain_statistics &lt;- addStatistics(gobject = visium_brain, expression_values = &quot;raw&quot;) ## visualize spatPlot2D(gobject = visium_brain_statistics, cell_color = &quot;nr_feats&quot;, color_as_factor = FALSE) filterDistributions(gobject = visium_brain_statistics, detection = &quot;cells&quot;) filterDistributions(gobject = visium_brain_statistics, detection = &quot;feats&quot;) filterCombinations() may be used to test how different filtering parameters will affect the number of cells and features in the filtered data: filterCombinations(gobject = visium_brain_statistics, expression_thresholds = c(1, 2, 3), feat_det_in_min_cells = c(50, 100, 200), min_det_feats_per_cell = c(500, 1000, 1500)) 7.7 Filtering visium_brain &lt;- filterGiotto( gobject = visium_brain, expression_threshold = 1, feat_det_in_min_cells = 50, min_det_feats_per_cell = 1000, expression_values = &quot;raw&quot;, verbose = TRUE ) Feature type: rna Number of cells removed: 4 out of 2702 Number of feats removed: 7311 out of 22125 7.8 Normalization visium_brain &lt;- normalizeGiotto( gobject = visium_brain, scalefactor = 6000, verbose = TRUE ) visium_brain &lt;- addStatistics(gobject = visium_brain) ## visualize spatPlot2D(gobject = visium_brain, cell_color = &quot;nr_feats&quot;, color_as_factor = FALSE) 7.9 Feature selection 7.9.1 Highly Variable Features: Calculating Highly Variable Features (HVF) is necessary to identify genes (or features) that display significant variability across spatial locations. There are a few methods to choose from: loess regression visium_brain &lt;- calculateHVF(gobject = visium_brain, method = &quot;cov_loess&quot;, save_plot = TRUE, default_save_name = &quot;HVFplot_loess&quot;) pearson residuals visium_brain &lt;- calculateHVF(gobject = visium_brain, method = &quot;var_p_resid&quot;, save_plot = TRUE, default_save_name = &quot;HVFplot_pearson&quot;) binned visium_brain &lt;- calculateHVF(gobject = visium_brain, method = &quot;cov_groups&quot;, save_plot = TRUE, default_save_name = &quot;HVFplot_binned&quot;) Depending on the underlying distribution of the data: loess regression is used when the relationship between mean expression and variance is non-linear or can be described by a non-parametric model pearson residuals are used when the relationship between mean expression and variance is linear or can be described by a parametric model binned (covariance groups) are used when variability in gene expression differs across expression levels or spatial regions, without assuming a specific relationship between mean expression and variance 7.10 Dimension Reduction 7.10.1 PCA Principal Components Analysis (PCA) is applied to reduce the dimensionality of gene expression data by transforming it into principal components, which are linear combinations of genes ranked by the variance they explain, with the first components capturing the most variance. Default visium_brain &lt;- runPCA(gobject = visium_brain) Using specific features my_features &lt;- head(getFeatureMetadata(visium_brain, output = &quot;data.table&quot;)$feat_ID, 1000) visium_brain &lt;- runPCA(gobject = visium_brain, feats_to_use = my_features, name = &quot;custom_pca&quot;) Visualization Screeplot screePlot(gobject = visium_brain, ncp = 30) PCA plotPCA(gobject = visium_brain) Custom PCA plotPCA(gobject = visium_brain, dim_reduction_name = &quot;custom_pca&quot;) Unlike PCA, Unifold Manifold Approximation and Projection (UMAP) and t-Stochastic Neighbor Embedding (t-SNE) do not assume linearity. After running PCA, UMAP or t-SNE follows to further reduce PCs. 7.10.2 UMAP visium_brain &lt;- runUMAP(visium_brain, dimensions_to_use = 1:10) Visualization plotUMAP(gobject = visium_brain) 7.10.3 t-SNE visium_brain &lt;- runtSNE(gobject = visium_brain, dimensions_to_use = 1:10) Visualization plotTSNE(gobject = visium_brain) UMAP generally provides a more balanced view of spatial relationships and biological context, while t-SNE can be more effective in highlighting specific clusters or spatially proximal groups. 7.11 Clustering Shared Nearest Neighbor (sNN) emphasizes local coherence by considering spots that share nearest neighbors, highlighting cohesive spatial structures in the data. k-Nearest Neighbors (kNN) defines spatial relationships based on direct proximity, focusing on the nearest neighbors of each spot without considering shared neighborhood patterns as explicitly as sNN. Create a sNN network (default) visium_brain &lt;- createNearestNetwork(gobject = visium_brain, dimensions_to_use = 1:10, k = 15) Create a kNN network visium_brain &lt;- createNearestNetwork(gobject = visium_brain, dimensions_to_use = 1:10, k = 15, type = &quot;kNN&quot;) 7.11.1 Calculate Leiden clustering visium_brain &lt;- doLeidenCluster(gobject = visium_brain, resolution = 0.4, n_iterations = 1000) Visualization plotPCA(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;) plotUMAP(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, show_NN_network = FALSE, point_size = 2.5) plotUMAP(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, show_NN_network = TRUE, point_size = 2.5) plotTSNE(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, point_size = 2.5) plotTSNE(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, point_size = 2.5, show_NN_network = TRUE) Dimension plots grouped by cluster spatPlot2D(visium_brain, cell_color = &quot;leiden_clus&quot;) 7.11.2 Calculate Louvain clustering visium_brain &lt;- doLouvainCluster(visium_brain) spatPlot2D(visium_brain, cell_color = &quot;louvain_clus&quot;) Leiden clustering is generally preferred for larger and more complex datasets, where as Louvain clustering may be suitable for more smaller datasets or scenarios where computational efficiency is a priority. 7.12 Save the object saveGiotto(visium_brain, &quot;visium_brain_object&quot;) 7.13 Session info sessionInfo() "],["visium-part-ii.html", "8 Visium Part II 8.1 Load the object 8.2 Differential expression 8.3 Enrichment &amp; Deconvolution 8.4 Spatial expression patterns 8.5 Spatially informed clusters 8.6 Spatial domains HMRF 8.7 Interactive tools 8.8 Session info", " 8 Visium Part II Joselyn Cristina Chávez Fuentes August 6th 2024 8.1 Load the object library(Giotto) visium_brain &lt;- loadGiotto(&quot;visium_brain_object&quot;) 8.2 Differential expression 8.2.1 Gini markers Calculate the top marker genes per cluster using the gini method gini_markers &lt;- findMarkers_one_vs_all(gobject = visium_brain, method = &quot;gini&quot;, expression_values = &quot;normalized&quot;, cluster_column = &quot;leiden_clus&quot;, min_feats = 10) topgenes_gini &lt;- gini_markers[, head(.SD, 2), by = &quot;cluster&quot;]$feats Visualize violinPlot(visium_brain, feats = unique(topgenes_gini), cluster_column = &quot;leiden_clus&quot;, strip_text = 6, strip_position = &quot;right&quot;, save_param = list(base_width = 5, base_height = 30)) plotMetaDataHeatmap(visium_brain, selected_feats = unique(topgenes_gini), metadata_cols = &quot;leiden_clus&quot;, x_text_size = 10, y_text_size = 10) dimFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, feats = sort(unique(topgenes_gini)), cow_n_col = 5, point_size = 1, save_param = list(base_width = 15, base_height = 20)) 8.2.2 Scran markers Calculate the top marker genes per cluster using the scran method scran_markers &lt;- findMarkers_one_vs_all(gobject = visium_brain, method = &quot;scran&quot;, expression_values = &quot;normalized&quot;, cluster_column = &quot;leiden_clus&quot;, min_feats = 10) topgenes_scran &lt;- scran_markers[, head(.SD, 2), by = &quot;cluster&quot;]$feats Visualize violinPlot(visium_brain, feats = unique(topgenes_scran), cluster_column = &quot;leiden_clus&quot;, strip_text = 6, strip_position = &quot;right&quot;, save_param = list(base_width = 5, base_height = 30)) plotMetaDataHeatmap(visium_brain, selected_feats = unique(topgenes_scran), metadata_cols = &quot;leiden_clus&quot;, x_text_size = 10, y_text_size = 10) dimFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, feats = sort(unique(topgenes_scran)), cow_n_col = 5, point_size = 1, save_param = list(base_width = 20, base_height = 20)) The Gini method is preferred when identifying genes that exhibit significant expression differences across clusters, highlighting genes with distinct expression patters between different clusters. The Scran method is preferred for robust differential expression analysis, especially when addressing technical variability or differences in sequencing depth across spatial locations. In practice, it is often beneficial to apply both methods and compare results for a more complete understanding of differential gene expression across clusters. 8.3 Enrichment &amp; Deconvolution Visium spatial transcriptomics does not provide single-cell resolution, making cell type annotation a harder problem. Giotto provides several ways to calculate enrichment of specific cell-type signature gene lists. Download the single-cell dataset GiottoData::getSpatialDataset(dataset = &quot;scRNA_mouse_brain&quot;, directory = &quot;data/&quot;) Create the single-cell object results_folder &lt;- &quot;results/&quot; python_path &lt;- NULL instructions &lt;- createGiottoInstructions( save_dir = results_folder, save_plot = TRUE, show_plot = FALSE, python_path = python_path ) sc_expression &lt;- &quot;data/brain_sc_expression_matrix.txt.gz&quot; sc_metadata &lt;- &quot;data/brain_sc_metadata.csv&quot; giotto_SC &lt;- createGiottoObject(expression = sc_expression, instructions = instructions) giotto_SC &lt;- addCellMetadata(giotto_SC, new_metadata = data.table::fread(sc_metadata)) giotto_SC &lt;- normalizeGiotto(giotto_SC) 8.3.1 PAGE/Rank Parametric Analysis of Gene Set Enrichment (PAGE) and Rank enrichment both aim to determine whether a predefined set of genes show statistically significant differences in expression compared to other genes in the dataset. Calculate the cell type markers markers_scran &lt;- findMarkers_one_vs_all(gobject = giotto_SC, method = &quot;scran&quot;, expression_values = &quot;normalized&quot;, cluster_column = &quot;Class&quot;, min_feats = 3) top_markers &lt;- markers_scran[, head(.SD, 10), by = &quot;cluster&quot;] celltypes &lt;- levels(factor(markers_scran$cluster)) Create the signature matrix sign_list &lt;- list() for (i in 1:length(celltypes)){ sign_list[[i]] = top_markers[which(top_markers$cluster == celltypes[i]),]$feats } sign_matrix &lt;- makeSignMatrixPAGE(sign_names = celltypes, sign_list = sign_list) Run the enrichment test with PAGE visium_brain &lt;- runPAGEEnrich(gobject = visium_brain, sign_matrix = sign_matrix) Visualize cell_types_PAGE &lt;- colnames(sign_matrix) plotMetaDataCellsHeatmap(gobject = visium_brain, metadata_cols = &quot;leiden_clus&quot;, value_cols = cell_types_PAGE, spat_enr_names = &quot;PAGE&quot;, x_text_size = 8, y_text_size = 8) spatCellPlot2D(gobject = visium_brain, spat_enr_names = &quot;PAGE&quot;, cell_annotation_values = cell_types_PAGE, cow_n_col = 3, coord_fix_ratio = 1, point_size = 1, show_legend = TRUE) 8.3.2 SpatialDWLS Spatial Diffusion Weighted Least Squares (DWLS) estimates the proportions of different cell types or spatial gradients of gene expression across spots in a tissue. Create the signature matrix sign_matrix &lt;- makeSignMatrixDWLSfromMatrix( matrix = getExpression(giotto_SC, values = &quot;normalized&quot;, output = &quot;matrix&quot;), cell_type = pDataDT(giotto_SC)$Class, sign_gene = top_markers$feats) Run the DWLS Deconvolution visium_brain &lt;- runDWLSDeconv(gobject = visium_brain, sign_matrix = sign_matrix) Visualize # Plot DWLS deconvolution result with Pie plots spatDeconvPlot(visium_brain, show_image = FALSE, radius = 50, save_param = list(save_name = &quot;8_spat_DWLS_pie_plot&quot;)) 8.4 Spatial expression patterns 8.4.1 Spatial variable genes Create a spatial network visium_brain &lt;- createSpatialNetwork(gobject = visium_brain, method = &quot;kNN&quot;, k = 6, maximum_distance_knn = 400, name = &quot;spatial_network&quot;) spatPlot2D(gobject = visium_brain, show_network= TRUE, network_color = &quot;blue&quot;, spatial_network_name = &quot;spatial_network&quot;) Rank binarization ranktest &lt;- binSpect(visium_brain, bin_method = &quot;rank&quot;, calc_hub = TRUE, hub_min_int = 5, spatial_network_name = &quot;spatial_network&quot;) Visualize top results spatFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, feats = ranktest$feats[1:6], cow_n_col = 2, point_size = 1) 8.4.2 Spatial co-expression modules Cluster the top 500 spatial genes into 20 clusters ext_spatial_genes &lt;- ranktest[1:500,]$feats Use detectSpatialCorGenes function to calculate pairwise distances between genes. spat_cor_netw_DT &lt;- detectSpatialCorFeats( visium_brain, method = &quot;network&quot;, spatial_network_name = &quot;spatial_network&quot;, subset_feats = ext_spatial_genes) Identify most similar spatially correlated genes for one gene top10_genes &lt;- showSpatialCorFeats(spat_cor_netw_DT, feats = &quot;Mbp&quot;, show_top_feats = 10) Visualize spatFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, feats = top10_genes$variable[1:4], point_size = 1.5) Cluster spatial genes spat_cor_netw_DT &lt;- clusterSpatialCorFeats(spat_cor_netw_DT, name = &quot;spat_netw_clus&quot;, k = 20) Visualize clusters heatmSpatialCorFeats(visium_brain, spatCorObject = spat_cor_netw_DT, use_clus_name = &quot;spat_netw_clus&quot;, heatmap_legend_param = list(title = NULL)) Rank spatial correlated clusters and show genes for selected clusters netw_ranks &lt;- rankSpatialCorGroups( visium_brain, spatCorObject = spat_cor_netw_DT, use_clus_name = &quot;spat_netw_clus&quot;) top_netw_spat_cluster &lt;- showSpatialCorFeats(spat_cor_netw_DT, use_clus_name = &quot;spat_netw_clus&quot;, selected_clusters = 6, show_top_feats = 1) Create metagene enrichment score for clusters cluster_genes_DT &lt;- showSpatialCorFeats(spat_cor_netw_DT, use_clus_name = &quot;spat_netw_clus&quot;, show_top_feats = 1) cluster_genes &lt;- cluster_genes_DT$clus names(cluster_genes) &lt;- cluster_genes_DT$feat_ID visium_brain &lt;- createMetafeats(visium_brain, feat_clusters = cluster_genes, name = &quot;cluster_metagene&quot;) spatCellPlot(visium_brain, spat_enr_names = &quot;cluster_metagene&quot;, cell_annotation_values = netw_ranks$clusters, point_size = 1, cow_n_col = 5) 8.5 Spatially informed clusters Get the top 30 genes per spatial co-expression cluster coexpr_dt &lt;- data.table::data.table( genes = names(spat_cor_netw_DT$cor_clusters$spat_netw_clus), cluster = spat_cor_netw_DT$cor_clusters$spat_netw_clus) data.table::setorder(coexpr_dt, cluster) top30_coexpr_dt &lt;- coexpr_dt[, head(.SD, 30) , by = cluster] spatial_genes &lt;- top30_coexpr_dt$genes Re-calculate the clustering visium_brain &lt;- runPCA(gobject = visium_brain, feats_to_use = spatial_genes, name = &quot;custom_pca&quot;) visium_brain &lt;- runUMAP(visium_brain, dim_reduction_name = &quot;custom_pca&quot;, dimensions_to_use = 1:20, name = &quot;custom_umap&quot;) visium_brain &lt;- createNearestNetwork(gobject = visium_brain, dim_reduction_name = &quot;custom_pca&quot;, dimensions_to_use = 1:20, k = 5, name = &quot;custom_NN&quot;) visium_brain &lt;- doLeidenCluster(gobject = visium_brain, network_name = &quot;custom_NN&quot;, resolution = 0.15, n_iterations = 1000, name = &quot;custom_leiden&quot;) Visualize spatPlot2D(visium_brain, cell_color = &quot;custom_leiden&quot;) plotUMAP(gobject = visium_brain, cell_color = &quot;custom_leiden&quot;, point_size = 1.5) 8.6 Spatial domains HMRF Hidden Markov Random Field (HMRF) models capture spatial dependencies and segment tissue regions based on shared gene expression patterns. Do HMRF with different betas on top 30 genes per spatial co-expression module HMRF_spatial_genes &lt;- doHMRF(gobject = visium_brain, expression_values = &quot;scaled&quot;, spatial_genes = spatial_genes, k = 20, spatial_network_name = &quot;spatial_network&quot;, betas = c(0, 10, 5), output_folder = &quot;11_HMRF/&quot;) visium_brain &lt;- addHMRF(gobject = visium_brain, HMRFoutput = HMRF_spatial_genes, k = 20, betas_to_add = c(0, 10, 20, 30, 40), hmrf_name = &quot;HMRF&quot;) spatPlot2D(gobject = visium_brain, cell_color = &quot;HMRF_k20_b.40&quot;) Visualize 8.7 Interactive tools Create a spatial plot brain_spatPlot &lt;- spatPlot2D(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, show_image = FALSE, return_plot = TRUE, point_size = 1) brain_spatPlot Run the Shiny app plotInteractivePolygons(brain_spatPlot) Select the regions of interest and save the coordinates polygon_coordinates &lt;- plotInteractivePolygons(brain_spatPlot) Transform the data.table or data.frame with coordinates into a Giotto polygon object giotto_polygons &lt;- createGiottoPolygonsFromDfr(polygon_coordinates, name = &quot;selections&quot;, calc_centroids = TRUE) Add the polygons (or spatial units) to the Giotto object visium_brain &lt;- addGiottoPolygons(gobject = visium_brain, gpolygons = list(giotto_polygons)) Add the corresponding polygon IDs to the cell metadata visium_brain &lt;- addPolygonCells(visium_brain, polygon_name = &quot;selections&quot;) Extract the coordinates and IDs from cells located within one or multiple regions of interest. getCellsFromPolygon(visium_brain, polygon_name = &quot;selections&quot;, polygons = &quot;polygon 1&quot;) If no polygon name is provided, the function will retrieve cells located within all polygons getCellsFromPolygon(visium_brain, polygon_name = &quot;selections&quot;) Compare the expression levels of some genes of interest between the selected regions comparePolygonExpression(visium_brain, selected_feats = c(&quot;Stmn1&quot;, &quot;Psd&quot;, &quot;Ly6h&quot;)) Calculate the top genes expressed within each region, then provide the result to compare polygons scran_results &lt;- findMarkers_one_vs_all(visium_brain, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, method = &quot;scran&quot;, expression_values = &quot;normalized&quot;, cluster_column = &quot;selections&quot;, min_feats = 2) top_genes &lt;- scran_results[, head(.SD, 2), by = &quot;cluster&quot;]$feats comparePolygonExpression(visium_brain, selected_feats = top_genes) Compare the abundance of cell types between the selected regions compareCellAbundance(visium_brain) Use other columns within the cell metadata table to compare the cell type abundances compareCellAbundance(visium_brain, cell_type_column = &quot;custom_leiden&quot;) Use the spatPlot arguments to isolate and plot each region. spatPlot2D(visium_brain, cell_color = &quot;leiden_clus&quot;, group_by = &quot;selections&quot;, cow_n_col = 3, point_size = 2, show_legend = FALSE) Color each cell by cluster, cell type or expression level. spatFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, group_by = &quot;selections&quot;, feats = &quot;Psd&quot;, point_size = 2) Plot again the polygons plotPolygons(visium_brain, polygon_name = &quot;selections&quot;, x = brain_spatPlot) 8.8 Session info sessionInfo() "],["visium-hd.html", "9 Visium HD 9.1 Objective 9.2 Background 9.3 Data Ingestion 9.4 Tiling and aggregation 9.5 Scalability and projection functions 9.6 Spatial expression patterns 9.7 Spatial co-expression modules", " 9 Visium HD Edward C. Ruiz August 6th 2024 9.1 Objective This tutorial demonstrates how to process Visium HD data at the highest 2 micron bin resolution using Giotto Suite and methods from the [dbverse] (link). 9.2 Background 9.2.1 Visium HD Technology Figure 9.1: Overview of Visium HD. Source: 10X Genomics Visium HD is a spatial transcriptomics technology recently developed by 10X Genomics. Details about this platform are discussed on the official 10X Genomics Visium HD website and the preprint by Oliveira et al. 2024 on bioRxiv. At the highest resolution, Visium HD data contains a 2 micron bin size. At the lowest resolution, Visium HD data is binned at a 16 micron bin size after running the spaceranger pipeline. 9.2.2 Colorectal Cancer Sample Figure 9.2: Colorectal Cancer Overview. Source: 10X Genomics For this tutorial we will be using the publicly available Colorectal Cancer Visium HD dataset. Details about this dataset and a link to download the raw data can be found at the 10X Genomics website. 9.3 Data Ingestion 9.3.1 Visium HD output data format Figure 9.3: File structure of Visium HD data processed with spaceranger pipeline. Visium HD data processed with the spaceranger pipeline is organized in this format containing various files associated with the sample. The files highlighted in yellow are what we will be using to read in these datasets. 9.3.2 Read in raw data # get10Xmatrix() # GiottoData:: 9.3.3 Giotto Visium HD convenience function We have also developed a convenience function to read in Visium HD data directly into Giotto. This function will read in the data and create a Giotto Object. # importVisiumHD() 9.4 Tiling and aggregation The Visium HD data is organized in a grid format. We can aggregate the data into larger bins to reduce the dimensionality of the data. Giotto Suite provides options to bin data not only with squares, but also through hexagons and triangles. Here we use a hexagon tesselation to aggregate the data into arbitrary cells. # tessellate() 9.5 Scalability and projection functions filter and normalization workflow PCA projection 9.6 Spatial expression patterns plotting 9.7 Spatial co-expression modules binspect? "],["xenium-1.html", "10 Xenium 10.1 Introduction to spatial dataset 10.2 Additional package requirements 10.3 Introduce mini object 10.4 Read in raw data 10.5 Overlap txs &amp; polygons 10.6 Transcript enrichment GSEA 10.7 Spatial location analysis 10.8 Visualizations", " 10 Xenium Jiaji George Chen August 6th 2024 10.1 Introduction to spatial dataset This is the 10X Xenium FFPE Human Lung Cancer dataset. Xenium captures individual transcript detections with a spatial resolution of 100s of nanometers, providing an extremely highly resolved subcellular spatial dataset. This particular dataset also showcases their newly released multimodal cell segmentation outputs. The Xenium Human Multi-Tissue and Cancer Panel (377) genes was used. The exported data is from their Xenium Onboard Analysis v2.0.0 pipeline. The full data for this example can be found here: here Input Files are additional files that are not part of the output bundles, usually some raw files the pipeline uses or extra info. Output Files are the directories that are exported by the Xenium pipeline that can be expected from every run. 10.2 Additional package requirements When working with this data, some additional packages must be downloaded. - arrow is needed - requires ZTSD codec to open these parquets. 10.3 Introduce mini object save_dir &lt;- &quot;~/Documents/GitHub/giotto_workshop_2024/img/02_session3&quot; 10.4 Read in raw data # 3D stack - DAPI # 2D fusion images # - DAPI # - stainings for multimodal segmentation # Maximum intensity projection (MIP) of the morphology image. # (Xenium Outputs v1.0 - 1.9. only) image mip Transcript coordinates Polygon coordinates Visualizations affine mapping? 10.5 Overlap txs &amp; polygons Typical aggregated workflow Feature/molecule specific analysis Visualizations 10.6 Transcript enrichment GSEA text 10.7 Spatial location analysis Spatial cell type co-localization analysis Spatial niche analysis Spatial niche trajectory analysis 10.8 Visualizations "],["spatial-proteomics-multiplex-if.html", "11 Spatial proteomics: multiplex IF 11.1 Read in raw data 11.2 Overlap intensity &amp; workflows", " 11 Spatial proteomics: multiplex IF Junxiang Xu August 6th 2024 11.1 Read in raw data Intensity data (IF or any other image) Polygon coordinates Visualizations 11.2 Overlap intensity &amp; workflows Typical aggregated workflow Visualizations "],["working-with-multiple-samples.html", "12 Working with multiple samples 12.1 Objective 12.2 Background 12.3 Create individual giotto objects 12.4 Join Giotto Objects 12.5 Visualizing combined datasets 12.6 Splitting combined dataset 12.7 Analyzing joined objects 12.8 Perform Harmony and default workflows", " 12 Working with multiple samples Jeff Sheridan August 7th 2024 12.1 Objective Giotto enables the grouping of multiple objects into a single object for combined analysis. Datasets can be spatially distributed across the x, y, or z axes, allowing for the creation of 3D datasets using the z-plane or the analysis of grouped datasets, such as multiple replicates or similar samples. While it’s possible to integrate multiple datasets, batch effects from samples can hinder effective integration. In such cases, more sophisticated methods may be needed to successfully integrate and cluster samples as a unified dataset. One example of an advanced integration technique is Harmony, which will be discussed in more detail later in this tutorial. This tutorial will demonstrate the integration of two Visium datasets, examining the results before and after Harmony integration. 12.2 Background 12.2.1 Dataset For this tutorial we will be using two prostate visium datasets produced by 10X Genomics, one an Adenocarcinoma with Invasive Carcinoma and the other a normal prostate sample. 12.2.2 Visium technology Figure 12.1: Overview of Visium. Source: 10X Genomics. Visium by 10x Genomics is a spatial gene expression platform that allows for the mapping of gene expression to high-resolution histology through RNA sequencing The process involves placing a tissue section on a specially prepared slide with an array of barcoded spots, which are 55 µm in diameter with a spot to spot distance of 100 µm. Each spot contains unique barcodes that capture the mRNA from the tissue section, preserving the spatial information. After the tissue is imaged and RNA is captured, the mRNA is sequenced, and the data is mapped back to the tissue’s spatial coordinates. This technology is particularly useful in understanding complex tissue environments, such as tumors, by providing insights into how gene expression varies across different regions. 12.3 Create individual giotto objects 12.3.1 Download the data You need to download the expression matrix and spatial information by running these commands: data_dir &lt;- &#39;data&#39; dir.create(file.path(data_dir, &#39;Visium_FFPE_Human_Prostate_Cancer&#39;), showWarnings = T, recursive = T) # Spatial data adenocarcinom prostate download.file(url = &#39;https://cf.10xgenomics.com/samples/spatial-exp/1.3.0/Visium_FFPE_Human_Prostate_Cancer/Visium_FFPE_Human_Prostate_Cancer_spatial.tar.gz&#39;, destfile = file.path(data_dir, &#39;Visium_FFPE_Human_Prostate_Cancer/Visium_FFPE_Human_Prostate_Cancer_spatial.tar.gz&#39;)) # Deat matrix adenocarcinoma prostate download.file(url = &#39;https://cf.10xgenomics.com/samples/spatial-exp/1.3.0/Visium_FFPE_Human_Prostate_Cancer/Visium_FFPE_Human_Prostate_Cancer_raw_feature_bc_matrix.tar.gz&#39;, destfile = file.path(data_dir, &#39;Visium_FFPE_Human_Prostate_Cancer/Visium_FFPE_Human_Prostate_Cancer_raw_feature_bc_matrix.tar.gz&#39;)) dir.create(file.path(data_dir, &#39;Visium_FFPE_Human_Normal_Prostate&#39;), showWarnings = F, recursive = T) # Spatial data normal prostate download.file(url = &#39;https://cf.10xgenomics.com/samples/spatial-exp/1.3.0/Visium_FFPE_Human_Normal_Prostate/Visium_FFPE_Human_Normal_Prostate_spatial.tar.gz&#39;, destfile = file.path(data_dir, &#39;Visium_FFPE_Human_Normal_Prostate/Visium_FFPE_Human_Normal_Prostate_spatial.tar.gz&#39;)) # Deat matrix normal prostate download.file(url = &#39;https://cf.10xgenomics.com/samples/spatial-exp/1.3.0/Visium_FFPE_Human_Normal_Prostate/Visium_FFPE_Human_Normal_Prostate_raw_feature_bc_matrix.tar.gz&#39;, destfile = file.path(data_dir, &#39;Visium_FFPE_Human_Normal_Prostate/Visium_FFPE_Human_Normal_Prostate_raw_feature_bc_matrix.tar.gz&#39;)) 12.3.2 create giotto instructions We must first create instructions for our Giotto object. This will tell the object where to save outputs, whether to shor or output plots and the python path. Specifying the python path is often not required as Giotto will identify the relevant python environment, but might be required in some instances. library(Giotto) save_dir &lt;- &quot;~/Documents/GitHub/giotto_workshop_2024/img/03_session1&quot; instrs = createGiottoInstructions(save_dir = save_dir, save_plot = TRUE, show_plot = TRUE, python_path = NULL) 12.3.3 load visium data into Giotto We next need to read in the data for the Giotto object. To do this we will use the createGiottoVisiumObject() convinience function. This requires us to specify the directory that contains the visium data output from 10X Genomics’s Spaceranger. We also specify the expression data to use (raw or filtered) as well as the image to align. Spaceranger outputs two images, a low and high resolution image. print(data_dir) print(file.path(data_dir, &#39;Visium_FFPE_Human_Normal_Prostate&#39;)) ## Healthy prostate N_pros = createGiottoVisiumObject( visium_dir = file.path(data_dir, &#39;Visium_FFPE_Human_Normal_Prostate&#39;), expr_data = &#39;raw&#39;, png_name = &#39;tissue_lowres_image.png&#39;, gene_column_index = 2, instructions = instrs ) ## Adenocarcinoma C_pros = createGiottoVisiumObject( visium_dir = file.path(data_dir, &#39;Visium_FFPE_Human_Prostate_Cancer&#39;), expr_data = &#39;raw&#39;, png_name = &#39;tissue_lowres_image.png&#39;, gene_column_index = 2, instructions = instrs ) We can see that the gobject contains information for the cells (polygon and spatial units), the RNA express (raw) and the relevant image. Figure 12.2: Structure of Giotto object containing a single dataset. 12.3.4 Healthy prostate tissue coverage Aligning the Visium spots to the tissue using the fiducials that border the capture area enables the identification of spots containing expression data from the tissue. These spots can be visualized using the spatPlot2D function by setting the cell_color parameter to ‘in_tissue’. spatPlot2D(gobject = N_pros, cell_color = &#39;in_tissue&#39;, show_image = T, point_size = 2.5,cell_color_code = c(&#39;black&#39;, &#39;red&#39;), point_alpha = 0.5, save_param = list(save_name = &quot;03_ses1_normal_prostate_tissue&quot;)) Figure 12.3: Tissue coverage for the normal prostate sample. 12.3.5 Adenocarcinoma prostate tissue coverage spatPlot2D(gobject = C_pros, cell_color = &#39;in_tissue&#39;, show_image = T, point_size = 2.5,cell_color_code = c(&#39;black&#39;, &#39;red&#39;), point_alpha = 0.5, save_param = list(save_name = &quot;03_ses1_adeno_prostate_tissue&quot;)) Figure 12.4: Tissue coverage for the adenocarcinoma prostate sample. 12.3.6 Showing the data strucutre for the inidividual objects # Printing the file structure for the individual datasets print(head(pDataDT(N_pros))) print(N_pros) 12.4 Join Giotto Objects To join objects together we can use the joinGittoObjects() function. For this we need to supply a list of objects as well as the names for each of these objects. We can also specify the x and y padding to separate the objects in space or the Z position for 3D datasets. If the x_shift is set to NULL then the total shift will be guessed from the Giotto image. combined_pros = joinGiottoObjects(gobject_list = list(N_pros, C_pros), gobject_names = c(&#39;NP&#39;, &#39;CP&#39;), join_method = &#39;shift&#39;, x_padding = 1000) # Printing the file structure for the individual datasets print(head(pDataDT(combined_pros))) print(combined_pros) From the joined data we can see the same information that was present in the single dataset objects as well as the addition of another image. The images are renamed from ‘image’ to include the object name in the image name e.g. ‘NP-image’. We can also see in the cell metadata that there is a new column ‘list_ID’ that contains the original object names. The cell_ID column also has the original object name appended to the beginnging of each cell ID e.g. ‘NP-AAACAACGAATAGTTC-1’. Figure 12.5: Structure of Giotto object containing two datasets (left) and cell metadata on the left. Note the addition of multiple images and the addition of the list_ID column to define the dataset. 12.5 Visualizing combined datasets The combined dataset can either visualized in the same space or in two separate plots through the group_by variable. To show images both the show_image variable and the image_name variable containing both image names needs to be used. 12.5.1 Vizualizing in the same plot Due to the x_padding provided when joining the objects each of the datasets can be vizualized in the same plotting area. We can see below the normal prostate sample on the left and the healthy prostate on the right. By including the show_image function and supplying both of the image names (“NP-image”, “CP-image”), we can also include the relevant images within the same plot. spatPlot2D(gobject = combined_pros, cell_color = &#39;in_tissue&#39;, cell_color_code = c(&#39;black&#39;, &#39;red&#39;), show_image = T, image_name = c(&quot;NP-image&quot;, &quot;CP-image&quot;), point_size = 1, point_alpha = 0.5, save_param = list(save_name = &quot;03_ses1_combined_tissue&quot;)) Figure 12.6: Vizualizing the visium spots that overlap tissue in normal prostate (left) and adenocarcinoma samples (right) within the same plot. 12.5.2 Vizualizing on separate plots If we want to vizualize the datasets in separate plots we can supply the ‘group_by’ variable. Below we group the data by ‘list_ID’, which corresponds to each dataset. We can specify the number of columns through the ‘cow_n_col’ variable. spatPlot2D(gobject = combined_pros, cell_color = &#39;in_tissue&#39;, cell_color_code = c(&#39;black&#39;, &#39;pink&#39;), show_image = T, image_name = c(&quot;NP-image&quot;, &quot;CP-image&quot;), group_by = &#39;list_ID&#39;, point_alpha = 0.5, point_size = 0.5, cow_n_col = 1, save_param = list(save_name = &quot;03_ses1_combined_tissue_group&quot;)) Figure 12.7: Vizualizing the visium spots that overlap tissue in normal prostate (left) and adenocarcinoma samples (right) in separate plots. 12.6 Splitting combined dataset If needed it’s possible to split the individual objects into single objects again through subsetting the cell metadata as shown below. # Getting the cell information combined_cells &lt;- pDataDT(combined_pros) np_cells &lt;- combined_cells[list_ID == &#39;NP&#39;] np_split &lt;- subsetGiotto(combined_pros, cell_ids = np_cells$cell_ID, poly_info = np_cells$cell_ID, spat_unit = &#39;cell&#39;) spatPlot2D(gobject = np_split, cell_color = &#39;in_tissue&#39;, cell_color_code = c(&#39;black&#39;, &#39;red&#39;), show_image = T, point_alpha = 0.5, point_size = 0.5, save_param = list(save_name = &quot;03_ses1_split_object&quot;)) Figure 12.8: Structure of Giotto object containing two datasets (left) and cell metadata on the left. Note the addition of multiple images and the addition of the list_ID column to define the dataset. 12.7 Analyzing joined objects 12.7.1 Normalization and adding statistics Now that the objects have been joined we can analyze the object as if it was a single object. This means all of the analyses will be performed in parallel. Therefore, all of the filtering and normalization will be identifical between datasets. # subset on in-tissue spots metadata = pDataDT(combined_pros) in_tissue_barcodes = metadata[in_tissue == 1]$cell_ID combined_pros = subsetGiotto(combined_pros, cell_ids = in_tissue_barcodes) ## filter combined_pros &lt;- filterGiotto(gobject = combined_pros, expression_threshold = 1, feat_det_in_min_cells = 50, min_det_feats_per_cell = 500, expression_values = c(&#39;raw&#39;), verbose = T) ## normalize combined_pros &lt;- normalizeGiotto(gobject = combined_pros, scalefactor = 6000) ## add gene &amp; cell statistics combined_pros &lt;- addStatistics(gobject = combined_pros, expression_values = &#39;raw&#39;) ## visualize spatPlot2D(gobject = combined_pros, cell_color = &#39;nr_feats&#39;, color_as_factor = F, point_size = 1, show_image = T, image_name = c(&quot;NP-image&quot;, &quot;CP-image&quot;), save_param = list(save_name = &quot;ses3_1_feat_expression&quot;)) After performing the addStatistics() function on both the datasets we can see the relative expression for each spot in both samples. Figure 12.9: Unique feat expression for visium spots for both prostate samples. 12.7.2 Clustering the datasets Since we shifted the objects within space the spatial networks for each dataset will remain separate, assuming that the lower limits for neighbours is smaller than the distance of each dataset. However, the individual spot clustering will be performed on all spots from both datasets as if they were a single object, meaning that the same cell types between objects should be clustered together ## PCA ## combined_pros &lt;- calculateHVF(gobject = combined_pros) combined_pros &lt;- runPCA(gobject = combined_pros, center = TRUE, scale_unit = TRUE) ## cluster and run UMAP ## # sNN network (default) combined_pros &lt;- createNearestNetwork(gobject = combined_pros, dim_reduction_to_use = &#39;pca&#39;, dim_reduction_name = &#39;pca&#39;, dimensions_to_use = 1:10, k = 15) # Leiden clustering combined_pros &lt;- doLeidenCluster(gobject = combined_pros, resolution = 0.2, n_iterations = 200) # UMAP combined_pros = runUMAP(combined_pros) 12.7.3 Vizualizing spatial location of clusters We can vizualize the clusters determined through leiden clustering on both of the datasets within the same plot. spatDimPlot2D(gobject = combined_pros, cell_color = &#39;leiden_clus&#39;, show_image = TRUE, image_name = c(&quot;NP-image&quot;, &quot;CP-image&quot;), save_param = list(save_name = &quot;ses3_1_leiden_clus&quot;)) Figure 12.10: UMAP (top) for both samples colored by Leiden clusters vizualized in a spatial plot (bottom) for the normal prostate (left) and the adenocarcinoma prostate sample (right). 12.7.4 Vizualizing tissue contribution to clusters We can also color the UMAP to vizualize the contribution from each tissue in the UMAP. To do this we color the UMAP by ‘list_ID’ rather than ‘leiden_clus’. If each of the cell types between both samples cluster together then we would expect that clusters should contain the cell color of both samples. However, we can see that the samples are clustered distinctly within the UMAP. This indicates that the cell types shared between both samples are found within different clusters indicating that more complex intergration techniques might be required for these samples. spatDimPlot2D(gobject = combined_pros, cell_color = &#39;list_ID&#39;,show_image = TRUE, image_name = c(&quot;NP-image&quot;, &quot;CP-image&quot;), save_param = list(save_name = &quot;ses3_1_tissue_contribution&quot;)) Figure 12.11: Tissue contribution for leiden clustering for the normal prostate (left) and the adenocarcinoma prostate sample (right). 12.8 Perform Harmony and default workflows We can use Harmony to integrate multiple datasets, grouping equivelent cell types between samples. Harmony is an algorithm that iteratively adjusts cell coordinates in a reduced-dimensional space to correct for dataset-specific effects. It uses fuzzy clustering to assign cells to multiple clusters, calculates dataset-specific correction factors, and applies these corrections to each cell, repeating the process until the influence of the dataset diminishes. Before running Harmony we need to run the PCA function or set ‘do_pca’ to TRUE. We ran this above so do not need to perform this step. Harmony will default to attempting 10 rounds of integration. Not all samples will need the full 10 and will finish accordingly. The follwoing dataset should converge after 5 iterations. library(harmony) ## run harmony integration combined_pros = runGiottoHarmony(combined_pros, vars_use = &#39;list_ID&#39;) After running the Harmony function successfully we can see that the outputted gobject has a new dim reduction names ‘harmony’. We dan use this for all subsequent spatial steps. Figure 12.12: Data structure of the gobject after running Harmony integration. 12.8.1 Clustering harmonized object We can now perform the same clusetering steps as before but instead using the ‘harmony’ dim reduction rather than PCA. We will also be creating new UMAP and nearest network data for the gobject that will be named differently to before to preserve the orginal analyses. If using the same name then this will overwrite the original analysis. ## sNN network (default) combined_pros &lt;- createNearestNetwork(gobject = combined_pros, dim_reduction_to_use = &#39;harmony&#39;, dim_reduction_name = &#39;harmony&#39;, name = &#39;NN.harmony&#39;, dimensions_to_use = 1:10, k = 15) ## Leiden clustering combined_pros &lt;- doLeidenCluster(gobject = combined_pros, network_name = &#39;NN.harmony&#39;, resolution = 0.2, n_iterations = 1000, name = &#39;leiden_harmony&#39;) # UMAP dimension reduction combined_pros = runUMAP(combined_pros, dim_reduction_name = &#39;harmony&#39;, dim_reduction_to_use = &#39;harmony&#39;, name = &#39;umap_harmony&#39;) spatDimPlot2D(gobject = combined_pros, dim_reduction_to_use = &#39;umap&#39;, dim_reduction_name = &#39;umap_harmony&#39;, cell_color = &#39;leiden_harmony&#39;, show_image = T, image_name = c(&quot;NP-image&quot;, &quot;CP-image&quot;), spat_point_size = 1, save_param = list(save_name = &quot;leiden_clustering_harmony&quot;)) We can see a different UMAP and clustering to that seen in the original steps above. We can again map these onto the tissue spots and see where the clusters are spatially. Figure 12.13: Leiden clustering after harmony was performed for the normal prostate (left) and the adenocarcinoma prostate sample (right). 12.8.2 Vizualizing the tissue contribution We can see that after performing harmony that the clusters from the two tissue samples are now clustered together. There is still a cluster that is unique to the adenocarcinoma sample, however this is expected as this represents the visium spots that cover the tumor regions of the tissue, which are not found in the normal tissue. spatDimPlot2D(gobject = combined_pros, dim_reduction_to_use = &#39;umap&#39;, dim_reduction_name = &#39;umap_harmony&#39;, cell_color = &#39;list_ID&#39;, save_plot = TRUE, save_param = list(save_name = &quot;leiden_clustering_harmony_contribution&quot;)) Figure 12.14: Tissue contribution for leiden clustering after harmony for the normal prostate (left) and the adenocarcinoma prostate sample (right). "],["spatial-multi-modal-analysis.html", "13 Spatial multi-modal analysis 13.1 Overview 13.2 Spatial manipulation 13.3 Examples of the simple transforms with a giottoPolygon 13.4 Affine transforms 13.5 Image transforms 13.6 Co-registration of datasets 13.7 Examples in giotto suite manuscript", " 13 Spatial multi-modal analysis Junxiang Xu August 7th 2024 13.1 Overview Spatial multimodal datasets are created when there is more than one modality available for a single piece of tissue. One way that these datasets can be assembled is by performing multiple spatial assays on closely adjacent tissue sections or ideally the same section. However, for these datasets, in addition to the usual expression space integration, we must also first spatially align them. 13.2 Spatial manipulation Performing spatial analyses across any two sections of tissue from the same block requires that data to be spatially aligned into a common coordinate space. Minute differences during the sectioning process from the cutting motion to how long an FFPE section was floated can result in even neighboring sections being distorted when compared side-by-side. These differences make it difficult to assemble multislice and/or cross platform multimodal datasets into a cohesive 3D volume. The solution for this is to perform registration across either the dataset images or expression information. Based on the registration results, both the raster images and vector feature and polygon information can be aligned into a continuous whole. Ideally this registration will be a free deformation based on sets of control points or a deformation matrix, however affine transforms already provide a good approximation. In either case, the transform or deformation applied must work in the same way across both raster and vector information. Giotto provides spatial classes and methods for easy manipulation of data with 2D affine transformations. These functionalities are all available from GiottoClass. 13.2.1 Spatial transforms: We support simple transformations and more complex affine transformations which can be used to combine and encode more than one simple transform. spatShift() - translations spin() - rotations (degrees) rescale() - scaling flip() - flip vertical or horizontal across arbitrary lines t() - transpose shear() - shear transform affine() - affine matrix transform 13.2.2 Spatial utilities: Helpful functions for use alongside these spatial transforms are ext() for finding the spatial bounding box of where your data object is, crop() for cutting out a spatial region of the data, and plot() for terra/base plots of the data. ext() - spatial extent or bounding box crop() - cut out a spatial region of the data plot() - plot a spatial object 13.2.3 Spatial classes: Giotto’s spatial subobjects respond to the above functions. The Giotto object itself can also be affine transformed. spatLocsObj - xy centroids spatialNetworkObj - spatial networks between centroids giottoPoints - xy feature point detections giottoPolygon - spatial polygons giottoImage (mostly deprecated) - magick-based images giottoLargeImage/giottoAffineImage - terra-based images affine2d - affine matrix container giotto - giotto analysis object # load in data library(Giotto) g &lt;- GiottoData::loadGiottoMini(&quot;vizgen&quot;) activeSpatUnit(g) &lt;- &quot;aggregate&quot; gpoly &lt;- getPolygonInfo(g, return_giottoPolygon = TRUE) gimg &lt;- getGiottoImage(g) 13.3 Examples of the simple transforms with a giottoPolygon rain &lt;- rainbow(nrow(gpoly)) line_width &lt;- 0.3 # par to setup the grid plotting layout p &lt;- par(no.readonly = TRUE) par(mfrow=c(3,3)) gpoly |&gt; plot(main = &quot;no transform&quot;, col = rain, lwd = line_width) gpoly |&gt; spatShift(dx = 1000) |&gt; plot(main = &quot;spatShift(dx = 1000)&quot;, col = rain, lwd = line_width) gpoly |&gt; spin(45) |&gt; plot(main = &quot;spin(45)&quot;, col = rain, lwd = line_width) gpoly |&gt; rescale(fx = 10, fy = 6) |&gt; plot(main = &quot;rescale(fx = 10, fy = 6)&quot;, col = rain, lwd = line_width) gpoly |&gt; flip(direction = &quot;vertical&quot;) |&gt; plot(main = &quot;flip()&quot;, col = rain, lwd = line_width) gpoly |&gt; t() |&gt; plot(main = &quot;t()&quot;, col = rain, lwd = line_width) gpoly |&gt; shear(fx = 0.5) |&gt; plot(main = &quot;shear(fx = 0.5)&quot;, col = rain, lwd = line_width) par(p) 13.4 Affine transforms The above transforms are all simple to understand in how they work, but you can imagine that performing them in sequence on your dataset can be computationally expensive. Luckily, the above operations are all affine transformation, and they can be condensed into a single step. Affine transforms where the x and y values undergo a linear transform. These transforms in 2D, can all be represented as a 2x2 matrix or 2x3 if the xy translation values are included. To perform the linear transform, the xy coordinates just need to be matrix multiplied by the 2x2 affine matrix. The resulting values should then be added to the translate values. Due to the nature of matrix multiplication, you can simply multiply the affine matrices with each other and when the xy coordinates are multiplied by the resulting matrix, it performs both linear transforms in the same step. Giotto provides a utility affine2d S4 class that can be created from any affine matrix and responds to the affine transform functions to simplify this accumulation of simple transforms. Once done, the affine2d can be applied to spatial objects in a single step using affine() in the same way that you would use a matrix. # create affine2d aff &lt;- affine() # when called without params, this is the same as affine(diag(c(1, 1))) The affine2d object also has an anchor spatial extent, which is used in calculations of the translation values. affine2d generates with a default extent, but a specific one matching that of the object you are manipulating (such as that of the giottoPolygon) should be set. aff@anchor &lt;- ext(gpoly) aff &lt;- initialize(aff) # append several simple transforms aff &lt;- aff |&gt; spatShift(dx = 1000) |&gt; spin(45, x0 = 0, y0 = 0) |&gt; # without the x0, y0 params, the extent center is used rescale(10, x0 = 0, y0 = 0) |&gt; # without the x0, y0 params, the extent center is used flip(direction = &quot;vertical&quot;) |&gt; t() |&gt; shear(fx = 0.5) force(aff) &lt;affine2d&gt; anchor : 6399.24384990901, 6903.24298517207, -5152.38959073896, -4694.86823300896 (xmin, xmax, ymin, ymax) rotate : -0.785398163397448 (rad) shear : 0.5, 0 (x, y) scale : 10, 10 (x, y) translate : 963.028150700062, 7071.06781186548 (x, y) The show function displays some information about the stored affine transform, including a set of decomposed simple transformations. You can then plot the affine object and see a projection of the spatial transform where blue is the starting position and red is the end. plot(aff) We can then apply the affine transforms to the giottoPolygon to see that it indeed in the location and orientation that the projection suggests. gpoly |&gt; affine(aff) |&gt; plot(main = &quot;affine()&quot;, col = rain, lwd = line_width) 13.5 Image transforms Giotto uses giottoLargeImages as the core image class which is based on terra SpatRaster. Images are not loaded into memory when the object is generated and instead an amount of regular sampling appropriate to the zoom level requested is performed at time of plotting. spatShift() and rescale() operations are supported by terra SpatRaster, and we inherit those functionalities. spin(), flip(), t(), shear(), affine() operations will coerce giottoLargeImage to giottoAffineImage, which is much the same, except it contains an affine2d object that tracks spatial manipulations performed, so that they can be applied through magick::image_distort() processing after sampled values are pulled into memory. giottoAffineImage also has alternative ext() and crop() methods so that those operations respect both the expected post-affine space and untransformed source image. # affine transform of image info matches with polygon info gimg |&gt; affine(aff) |&gt; plot() gpoly |&gt; affine(aff) |&gt; plot(add = TRUE, border = &quot;cyan&quot;, lwd = 0.3) # affine of the giotto object g |&gt; affine(aff) |&gt; spatInSituPlotPoints( show_image = TRUE, feats = list(rna = c(&quot;Adgrl1&quot;, &quot;Gfap&quot;, &quot;Ntrk3&quot;, &quot;Slc17a7&quot;)), feats_color_code = rainbow(4), polygon_color = &quot;cyan&quot;, polygon_line_size = 0.1, point_size = 0.1, use_overlap = FALSE ) Currently giotto image objects are not fully compatible with .ome.tif files. terra which relies on gdal drivers for image loading will find that the Gtiff driver opens some .ome.tif images, but fails when certain compressions (notably JP2000 as used by 10x for their single-channel stains) are used. 13.6 Co-registration of datasets text 13.7 Examples in giotto suite manuscript text sessionInfo() "],["multi-omics-integration.html", "14 Multi-omics integration 14.1 The CytAssist technology 14.2 Introduction to the spatial dataset 14.3 Download dataset 14.4 Create the Giotto object 14.5 Subset on spots that were covered by tissue 14.6 RNA processing 14.7 Protein processing 14.8 Multi-omics integration 14.9 Session info", " 14 Multi-omics integration Joselyn Cristina Chávez Fuentes August 7th 2024 14.1 The CytAssist technology The Visium CytAssist Spatial Gene and Protein Expression assay is designed to introduce simultaneous Gene Expression and Protein Expression analysis to FFPE samples processed with Visium CytAssist. The assay uses NGS to measure the abundance of oligo-tagged antibodies with spatial resolution, in addition to the whole transcriptome and a morphological image. The 10X human immune cell profiling panel features 35 antibodies from Abcam and Biolegend, and includes cell surface and intracellular targets. The rna probes hybridize to ~18,000 genes, or RNA targets, within the tissue section to achieve whole transcriptome gene expression profiling. The remaining steps, starting with probe extension, follow the standard Visium workflow outside of the instrument. 14.2 Introduction to the spatial dataset The Human Tonsil (FFPE) dataset was obtained from 10X Genomics. The tissue was sectioned as described in Visium CytAssist Spatial Gene and Protein Expression for FFPE – Tissue Preparation Guide (CG000660). 5 µm tissue sections were placed on Superfrost glass slides, deparaffinized, H&amp;E stained (CG000658) and coverslipped. Sections were imaged, decoverslipped, followed by decrosslinking per the Staining Demonstrated Protocol (CG000658). More information about this dataset can be found here. 14.3 Download dataset You need to download the expression matrix and spatial information by running these commands: dir.create(&quot;data&quot;) download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/2.1.0/CytAssist_FFPE_Protein_Expression_Human_Tonsil/CytAssist_FFPE_Protein_Expression_Human_Tonsil_raw_feature_bc_matrix.tar.gz&quot;, destfile = &quot;data/CytAssist_FFPE_Protein_Expression_Human_Tonsil_raw_feature_bc_matrix.tar.gz&quot;) download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/2.1.0/CytAssist_FFPE_Protein_Expression_Human_Tonsil/CytAssist_FFPE_Protein_Expression_Human_Tonsil_spatial.tar.gz&quot;, destfile = &quot;data/CytAssist_FFPE_Protein_Expression_Human_Tonsil_spatial.tar.gz&quot;) After downloading, unzip the gz files. You should get the “raw_feature_bc_matrix” and “spatial” folders inside “data/”. 14.4 Create the Giotto object The minimum requirements are: matrix with expression information (or the path to) x,y(,z) coordinates for cells or spots (or the path to) createGiottoVisiumObject() will automatically detect both RNA and Protein modalities in the expression matrix and will create a multi-omics Giotto object. library(Giotto) ## Set instructions results_folder &lt;- &quot;results/&quot; python_path &lt;- NULL instructions &lt;- createGiottoInstructions( save_dir = results_folder, save_plot = TRUE, show_plot = FALSE, return_plot = FALSE, python_path = python_path ) # Provide the path to the data folder data_path &lt;- &quot;data&quot; # Create object directly from the data folder visium_tonsil &lt;- createGiottoVisiumObject( visium_dir = data_path, expr_data = &quot;raw&quot;, png_name = &quot;tissue_lowres_image.png&quot;, gene_column_index = 2, instructions = instructions ) Print the information of the object, note that both rna and protein are listed in the expression slot visium_tonsil 14.5 Subset on spots that were covered by tissue spatPlot2D( gobject = visium_tonsil, cell_color = &quot;in_tissue&quot;, point_size = 2, cell_color_code = c(&quot;0&quot; = &quot;lightgrey&quot;, &quot;1&quot; = &quot;blue&quot;), show_image = TRUE, image_name = &quot;image&quot; ) metadata &lt;- getCellMetadata(gobject = visium_tonsil, output = &quot;data.table&quot;) in_tissue_barcodes &lt;- metadata[in_tissue == 1]$cell_ID visium_tonsil &lt;- subsetGiotto(visium_tonsil, cell_ids = in_tissue_barcodes) 14.6 RNA processing Filtering, normalization, and statistics visium_tonsil &lt;- filterGiotto( gobject = visium_tonsil, expression_threshold = 1, feat_det_in_min_cells = 50, min_det_feats_per_cell = 1000, expression_values = &quot;raw&quot;, verbose = TRUE) visium_tonsil &lt;- normalizeGiotto(gobject = visium_tonsil, scalefactor = 6000, verbose = TRUE) visium_tonsil &lt;- addStatistics(gobject = visium_tonsil) Dimension reduction visium_tonsil &lt;- calculateHVF(gobject = visium_tonsil) visium_tonsil &lt;- runPCA(gobject = visium_tonsil) Clustering visium_tonsil &lt;- runUMAP(visium_tonsil, dimensions_to_use = 1:10) visium_tonsil &lt;- runtSNE(visium_tonsil, dimensions_to_use = 1:10) visium_tonsil &lt;- createNearestNetwork(gobject = visium_tonsil, dimensions_to_use = 1:10, k = 30) visium_tonsil &lt;- doLeidenCluster(gobject = visium_tonsil, resolution = 1, n_iterations = 1000) Visualization plotUMAP(gobject = visium_tonsil, cell_color = &quot;leiden_clus&quot;, show_NN_network = TRUE, point_size = 2) spatPlot2D(gobject = visium_tonsil, show_image = TRUE, cell_color = &quot;leiden_clus&quot;, point_size = 3) 14.7 Protein processing Filtering, normalization, and statistics visium_tonsil &lt;- filterGiotto(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, expression_threshold = 1, feat_det_in_min_cells = 50, min_det_feats_per_cell = 1, expression_values = &quot;raw&quot;, verbose = TRUE) visium_tonsil &lt;- normalizeGiotto(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, scalefactor = 6000, verbose = TRUE) visium_tonsil &lt;- addStatistics(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;) Dimension reduction visium_tonsil &lt;- runPCA(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;) Clustering visium_tonsil &lt;- runUMAP(visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, dimensions_to_use = 1:10) visium_tonsil &lt;- runtSNE(visium_tonsil, spat_unit = &#39;cell&#39;, feat_type = &#39;protein&#39;, dimensions_to_use = 1:10) visium_tonsil &lt;- createNearestNetwork(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, dimensions_to_use = 1:10, k = 30) visium_tonsil &lt;- doLeidenCluster(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, resolution = 1, n_iterations = 1000) Visualization plotUMAP(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, cell_color = &quot;leiden_clus&quot;, show_NN_network = TRUE, point_size = 2) spatPlot2D(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, show_image = TRUE, cell_color = &quot;leiden_clus&quot;, point_size = 3) 14.8 Multi-omics integration Calculate kNN ## RNA modality visium_tonsil &lt;- createNearestNetwork(gobject = visium_tonsil, type = &quot;kNN&quot;, dimensions_to_use = 1:10, k = 20) ## Protein modality visium_tonsil &lt;- createNearestNetwork(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, type = &quot;kNN&quot;, dimensions_to_use = 1:10, k = 20) Run WNN visium_tonsil &lt;- runWNN(visium_tonsil, spat_unit = &quot;cell&quot;, modality_1 = &quot;rna&quot;, modality_2 = &quot;protein&quot;, pca_name_modality_1 = &quot;pca&quot;, pca_name_modality_2 = &quot;protein.pca&quot;, k = 20, integrated_feat_type = NULL, matrix_result_name = NULL, w_name_modality_1 = NULL, w_name_modality_2 = NULL, verbose = TRUE) Run Integrated umap visium_tonsil &lt;- runIntegratedUMAP(visium_tonsil, modality1 = &quot;rna&quot;, modality2 = &quot;protein&quot;, spread = 7, min_dist = 1, force = FALSE) Calculate integrated clusters visium_tonsil &lt;- doLeidenCluster(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, nn_network_to_use = &quot;kNN&quot;, network_name = &quot;integrated_kNN&quot;, name = &quot;integrated_leiden_clus&quot;, resolution = 1) Visualize the integrated umap plotUMAP(gobject = visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, cell_color = &quot;integrated_leiden_clus&quot;, dim_reduction_name = &quot;integrated.umap&quot;, point_size = 2, title = &quot;Integrated UMAP using Integrated Leiden clusters&quot;) Visualize spatial plot with integrated clusters spatPlot2D(visium_tonsil, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, cell_color = &quot;integrated_leiden_clus&quot;, point_size = 3, show_image = TRUE, title = &quot;Integrated Leiden clustering&quot;) 14.9 Session info sessionInfo() R version 4.4.1 (2024-06-14) Platform: aarch64-apple-darwin20 Running under: macOS Sonoma 14.5 Matrix products: default BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib; LAPACK version 3.12.0 locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 time zone: America/New_York tzcode source: internal attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] Giotto_4.1.0 GiottoClass_0.3.3 loaded via a namespace (and not attached): [1] colorRamp2_0.1.0 deldir_2.0-4 [3] rlang_1.1.4 magrittr_2.0.3 [5] RcppAnnoy_0.0.22 GiottoUtils_0.1.10 [7] matrixStats_1.3.0 compiler_4.4.1 [9] png_0.1-8 systemfonts_1.1.0 [11] vctrs_0.6.5 reshape2_1.4.4 [13] stringr_1.5.1 pkgconfig_2.0.3 [15] SpatialExperiment_1.14.0 crayon_1.5.3 [17] fastmap_1.2.0 backports_1.5.0 [19] magick_2.8.4 XVector_0.44.0 [21] labeling_0.4.3 utf8_1.2.4 [23] rmarkdown_2.27 UCSC.utils_1.0.0 [25] ragg_1.3.2 purrr_1.0.2 [27] xfun_0.46 beachmat_2.20.0 [29] zlibbioc_1.50.0 GenomeInfoDb_1.40.1 [31] jsonlite_1.8.8 DelayedArray_0.30.1 [33] BiocParallel_1.38.0 terra_1.7-78 [35] irlba_2.3.5.1 parallel_4.4.1 [37] R6_2.5.1 stringi_1.8.4 [39] RColorBrewer_1.1-3 reticulate_1.38.0 [41] parallelly_1.37.1 GenomicRanges_1.56.1 [43] scattermore_1.2 Rcpp_1.0.13 [45] bookdown_0.40 SummarizedExperiment_1.34.0 [47] knitr_1.48 future.apply_1.11.2 [49] R.utils_2.12.3 IRanges_2.38.1 [51] Matrix_1.7-0 igraph_2.0.3 [53] tidyselect_1.2.1 rstudioapi_0.16.0 [55] abind_1.4-5 yaml_2.3.9 [57] codetools_0.2-20 listenv_0.9.1 [59] lattice_0.22-6 tibble_3.2.1 [61] plyr_1.8.9 Biobase_2.64.0 [63] withr_3.0.0 Rtsne_0.17 [65] evaluate_0.24.0 future_1.33.2 [67] pillar_1.9.0 MatrixGenerics_1.16.0 [69] checkmate_2.3.1 stats4_4.4.1 [71] plotly_4.10.4 generics_0.1.3 [73] dbscan_1.2-0 sp_2.1-4 [75] S4Vectors_0.42.1 ggplot2_3.5.1 [77] munsell_0.5.1 scales_1.3.0 [79] globals_0.16.3 gtools_3.9.5 [81] glue_1.7.0 lazyeval_0.2.2 [83] tools_4.4.1 GiottoVisuals_0.2.4 [85] data.table_1.15.4 ScaledMatrix_1.12.0 [87] cowplot_1.1.3 grid_4.4.1 [89] tidyr_1.3.1 colorspace_2.1-0 [91] SingleCellExperiment_1.26.0 GenomeInfoDbData_1.2.12 [93] BiocSingular_1.20.0 rsvd_1.0.5 [95] cli_3.6.3 textshaping_0.4.0 [97] fansi_1.0.6 S4Arrays_1.4.1 [99] viridisLite_0.4.2 dplyr_1.1.4 [101] uwot_0.2.2 gtable_0.3.5 [103] R.methodsS3_1.8.2 digest_0.6.36 [105] BiocGenerics_0.50.0 SparseArray_1.4.8 [107] ggrepel_0.9.5 farver_2.1.2 [109] rjson_0.2.21 htmlwidgets_1.6.4 [111] htmltools_0.5.8.1 R.oo_1.26.0 [113] lifecycle_1.0.4 httr_1.4.7 "],["interoperability-with-other-frameworks.html", "15 Interoperability with other frameworks 15.1 Load Giotto object 15.2 Seurat 15.3 SpatialExperiment 15.4 AnnData 15.5 Create mini Vizgen object", " 15 Interoperability with other frameworks Iqra August 7th 2024 Giotto facilitates seamless interoperability with various tools, including Seurat, AnnData, and SpatialExperiment. Below is a comprehensive tutorial on how Giotto interoperates with these other tools. 15.1 Load Giotto object To begin demonstrating the interoperability of a Giotto object with other frameworks, we first load the required libraries and a Giotto mini object. We then proceed with the conversion process: library(Giotto) library(GiottoData) gobject &lt;- GiottoData::loadGiottoMini(&quot;visium&quot;) Load a Giotto mini Visium object, which will be used for demonstrating interoperability. 15.2 Seurat Giotto Suite provides interoperability between Seurat and Giotto, supporting both older and newer versions of Seurat objects. The four tailored functions are giottoToSeuratV4(), seuratToGiottoV4() for older versions, and giottoToSeuratV5(), seuratToGiottoV5() for Seurat v5, which includes subcellular and image information. These functions map Giotto’s metadata, dimension reductions, spatial locations, and images to the corresponding slots in Seurat. 15.2.1 Conversion of Giotto Object to Seurat Object To convert Giotto object to Seurat V5 object, we first load required libraries and use the function giottoToSeuratV5() function library(Seurat) library(SeuratData) library(ggplot2) library(patchwork) library(dplyr) Now we convert the Giotto object to a Seurat V5 object and create violin and spatial feature plots to visualize the RNA count data. gToS &lt;- giottoToSeuratV5(gobject = gobject, spat_unit = &quot;cell&quot;) plot1 &lt;- VlnPlot(gToS, features = &quot;nCount_rna&quot;, pt.size = 0.1) + NoLegend() plot2 &lt;- SpatialFeaturePlot(gToS, features = &quot;nCount_rna&quot;, pt.size.factor = 2) + theme(legend.position = &quot;right&quot;) wrap_plots(plot1, plot2) 15.2.1.1 Apply SCTransform We apply SCTransform to perform data transformation on the RNA assay: SCTransform() function. gToS &lt;- SCTransform(gToS, assay = &quot;rna&quot;, verbose = FALSE) 15.2.1.2 Dimension Reduction We perform Principal Component Analysis (PCA), find neighbors, and run UMAP for dimensionality reduction and clustering on the transformed Seurat object: gToS &lt;- RunPCA(gToS, assay = &quot;SCT&quot;) gToS &lt;- FindNeighbors(gToS, reduction = &quot;pca&quot;, dims = 1:30) gToS &lt;- RunUMAP(gToS, reduction = &quot;pca&quot;, dims = 1:30) 15.2.2 Conversion of Seurat object Back to Giotto Object To Convert the Seurat Object back to Giotto object, we use the funcion seuratToGiottoV5(), specifying the spatial assay, dimensionality reduction techniques, and spatial and nearest neighbor networks. giottoFromSeurat &lt;- seuratToGiottoV5(sobject = gToS, spatial_assay = &quot;rna&quot;, dim_reduction = c(&quot;pca&quot;, &quot;umap&quot;), sp_network = &quot;Delaunay_network&quot;, nn_network = c(&quot;sNN.pca&quot;, &quot;custom_NN&quot; )) 15.2.2.1 Clustering and Plotting UMAP Here we perform K-means clustering on the UMAP results obtained from the Seurat object: ## k-means clustering giottoFromSeurat &lt;- doKmeans(gobject = giottoFromSeurat, dim_reduction_to_use = &#39;pca&#39;) #Plot UMAP post-clustering to visualize kmeans graph2 &lt;- Giotto::plotUMAP( gobject = giottoFromSeurat, cell_color = &#39;kmeans&#39;, show_NN_network = T, point_size = 2.5 ) 15.2.2.2 Spatial CoExpression We can also use the binSpect function to analyze spatial co-expression using the spatial network (Delaunay network) from the Seurat object and then visualize the spatial co-expression using the heatmSpatialCorFeat() function: ranktest = binSpect(giottoFromSeurat, bin_method = &#39;rank&#39;, calc_hub = T, hub_min_int = 5, spatial_network_name = &#39;Delaunay_network&#39;) ext_spatial_genes = ranktest[1:300,]$feats spat_cor_netw_DT = detectSpatialCorFeats(giottoFromSeurat, method = &#39;network&#39;, spatial_network_name = &#39;Delaunay_network&#39;, subset_feats = ext_spatial_genes) top10_genes = showSpatialCorFeats(spat_cor_netw_DT, feats = &#39;Dsp&#39;, show_top_feats = 10) spat_cor_netw_DT = clusterSpatialCorFeats(spat_cor_netw_DT, name = &#39;spat_netw_clus&#39;, k = 7) heatmSpatialCorFeats( giottoFromSeurat, spatCorObject = spat_cor_netw_DT, use_clus_name = &#39;spat_netw_clus&#39;, heatmap_legend_param = list(title = NULL), save_plot = TRUE, show_plot = TRUE, return_plot = FALSE, save_param = list(base_height = 6, base_width = 8, units = &#39;cm&#39;)) 15.3 SpatialExperiment For the Bioconductor group of packages, the SpatialExperiment data container handles data from spatial-omics experiments, including spatial coordinates, images, and metadata. Giotto Suite provides giottoToSpatialExperiment() and spatialExperimentToGiotto(), mapping Giotto’s slots to the corresponding SpatialExperiment slots. Since SpatialExperiment can only store one spatial unit at a time, giottoToSpatialExperiment() returns a list of SpatialExperiment objects, each representing a distinct spatial unit. To start the conversion of a Giotto mini Visium object to a SpatialExperiment object, we first load the required libraries. library(SpatialExperiment) library(ggspavis) library(pheatmap) library(scater) library(scran) library(nnSVG) 15.3.1 Convert Giotto Object to SpatialExperiment Object To convert the Giotto object to a SpatialExperiment object, we use the giottoToSpatialExperiment() function. gspe &lt;- giottoToSpatialExperiment(gobject) The conversion function returns a separate SpatialExperiment object for each spatial unit. We select the first object for downstream use: spe &lt;- gspe[[1]] 15.3.1.1 Identify top spatially variable genes with nnSVG We employ the nnSVG package to identify the top spatially variable genes in our SpatialExperiment object. Covariates can be added to our model; in this example, we use Leiden clustering labels as a covariate: # One of the assays should be &quot;logcounts&quot; # We rename the normalized assay to &quot;logcounts&quot; assayNames(spe)[[2]] &lt;- &quot;logcounts&quot; # Create model matrix for leiden clustering labels X &lt;- model.matrix(~ colData(spe)$leiden_clus) dim(X) # Run nnSVG spe &lt;- nnSVG(spe, X = X) # Show top 10 features rowData(spe)[order(rowData(spe)$rank)[1:10], ]$feat_ID 15.3.2 Conversion of SpatialExperiment object back to Giotto We then convert the processed SpatialExperiment object back into a Giotto object for further downstream analysis using the Giotto suite. This is done using the spatialExperimentToGiotto function, where we explicitly specify the spatial network from the SpatialExperiment object. giottoFromSPE &lt;- spatialExperimentToGiotto(spe = spe, python_path = &quot;/share/pkg.7/python3/3.8.3/install/bin/python&quot;, sp_network = &quot;Delaunay_network&quot;) giottoFromSPE &lt;- spatialExperimentToGiotto(spe = spe, python_path = NULL, sp_network = &quot;Delaunay_network&quot;) print(giottoFromSPE) 15.3.2.1 Plotting top genes from nnSVG in Giotto Now, we visualize the genes previously identified in the SpatialExperiment object using the nnSVG package within the Giotto toolkit, leveraging the converted Giotto object. ext_spatial_genes &lt;- getFeatureMetadata(giottoFromSPE, output = &quot;data.table&quot;) ext_spatial_genes &lt;- ext_spatial_genes[order(ext_spatial_genes$rank)[1:10], ]$feat_ID spatFeatPlot2D(giottoFromSPE, expression_values = &#39;scaled_rna_cell&#39;, feats = ext_spatial_genes[1:4], point_size = 2) 15.4 AnnData The anndataToGiotto() and giottoToAnnData() functions map the slots of the Giotto object to the corresponding locations in a Squidpy-flavored AnnData object. Specifically, Giotto’s expression slot maps to adata.X, spatial_locs to adata.obsm, cell_metadata to adata.obs, feat_metadata to adata.var, dimension_reduction to adata.obsm, and nn_network and spat_network to adata.obsp. Images are currently not mapped between both classes. Notably, Giotto stores expression matrices within separate spatial units and feature types, while AnnData does not support this hierarchical data storage. Consequently, multiple AnnData objects are created from a Giotto object when there are multiple spatial unit and feature type pairs. 15.4.1 Load Required Libraries To start, we need to load the necessary libraries, including reticulate for interfacing with Python. library(reticulate) 15.4.2 Specify Path for Results First, we specify the directory where the results will be saved. Additionally, we retrieve and update Giotto instructions. # Specify path to which results may be saved results_directory = paste0(getwd(),&#39;/giotto_anndata_conversion/&#39;) instrs = showGiottoInstructions(gobject) mini_gobject = replaceGiottoInstructions(gobject = gobject, instructions = instrs) 15.4.2.1 Create Default kNN Network We will create a k-nearest neighbor (kNN) network using mostly default parameters. gobject = createNearestNetwork(gobject = gobject, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, type = &quot;kNN&quot;, dim_reduction_to_use = &quot;umap&quot;, dim_reduction_name = &quot;umap&quot;, k = 15, name = &quot;kNN.umap&quot;) 15.4.3 Giotto To AnnData To convert the giotto object to AnnData, we use the Giotto’s function giottoToAnnData() gToAnnData &lt;- giottoToAnnData(gobject = gobject, save_directory = results_directory) Next, we import scanpy and perform a series of preprocessing steps on the AnnData object. scanpy &lt;- import(&quot;scanpy&quot;) adata &lt;- scanpy$read_h5ad(&quot;/projectnb/rd-spat/HOME/iamin1/RProjects/Giotto_workshop/Giotto/cell_rna_converted_gobject.h5ad&quot;) # Normalize total counts per cell scanpy$pp$normalize_total(adata, target_sum=1e4) # Log-transform the data scanpy$pp$log1p(adata) # Perform PCA scanpy$pp$pca(adata, n_comps=50L) # Compute the neighborhood graph scanpy$pp$neighbors(adata, n_neighbors=10L, n_pcs=40L) # Run UMAP scanpy$tl$umap(adata) # Save the processed AnnData object adata$write(&quot;/projectnb/rd-spat/HOME/iamin1/RProjects/Giotto_workshop/Giotto/cell_rna_converted_gobject2.h5ad&quot;) processed_file_path &lt;- &quot;/projectnb/rd-spat/HOME/iamin1/RProjects/Giotto_workshop/Giotto/cell_rna_converted_gobject2.h5ad&quot; 15.4.4 Convert AnnData to Giotto Finally, we convert the processed AnnData object back into a Giotto object for further analysis using Giotto. giottoFromAnndata &lt;- anndataToGiotto(anndata_path = processed_file_path) 15.4.4.1 UMAP Visualization Now we plot the UMAP using the GiottoVisuals::plotUMAP() function that was calculated using Scanpy on the AnnData object. plotUMAP( gobject = giottoFromAnndata, dim_reduction_name = &quot;umap.ad&quot;, cell_color = &quot;leiden_clus&quot;, point_size = 3 ) 15.5 Create mini Vizgen object mini_gobject = loadGiottoMini(dataset = &#39;vizgen&#39;, python_path = my_python_path) mini_gobject = replaceGiottoInstructions(gobject = mini_gobject, instructions = instrs) mini_gobject = createNearestNetwork(gobject = mini_gobject, spat_unit = &quot;aggregate&quot;, feat_type = &quot;rna&quot;, type = &quot;kNN&quot;, dim_reduction_to_use = &quot;umap&quot;, dim_reduction_name = &quot;umap&quot;, k = 6, name = &quot;new_network&quot;) Since we have multiple spat_unit and feat_type pairs, this function will create multiple .h5ad files, with their names returned. Non-default nearest or spatial network names will have their key_added terms recorded and saved in corresponding .txt files; refer to the documentation for details. anndata_conversions = giottoToAnnData(gobject = mini_gobject, save_directory = results_directory, python_path = my_python_path) "],["interoperability-with-isolated-tools.html", "16 Interoperability with isolated tools 16.1 Spatial niche trajectory analysis", " 16 Interoperability with isolated tools Wen Wang August 7th 2024 16.1 Spatial niche trajectory analysis 16.1.1 Dataset download The MERFISH mouse motor cortex data to run this tutorial can be found here You need to download the processed expression, metadata, and cell segmentation information by running these commands: Notes: there are 61 slices here, we run on two of them to save the time. data_path &lt;- &quot;data&quot; dir.create(data_path) download.file(url = &quot;https://download.brainimagelibrary.org/cf/1c/cf1c1a431ef8d021/processed_data/counts.h5ad&quot;, destfile = file.path(data_path,&quot;counts.h5ad&quot;)) download.file(url = &quot;https://download.brainimagelibrary.org/cf/1c/cf1c1a431ef8d021/processed_data/cell_labels.csv&quot;, destfile = file.path(data_path,&quot;cell_labels.csv&quot;)) download.file(url = &quot;https://download.brainimagelibrary.org/cf/1c/cf1c1a431ef8d021/processed_data/segmented_cells_mouse2sample1.csv&quot;, destfile = file.path(data_path,&quot;segmented_cells_mouse2sample1.csv&quot;)) download.file(url = &quot;https://download.brainimagelibrary.org/cf/1c/cf1c1a431ef8d021/processed_data/segmented_cells_mouse2sample6.csv&quot;, destfile = file.path(data_path,&quot;segmented_cells_mouse2sample6.csv&quot;)) 16.1.2 Create the Giotto object library(Giotto) library(reticulate) ## Set instructions results_folder &lt;- &quot;results&quot; dir.create(results_folder) python_path &lt;- NULL instructions &lt;- createGiottoInstructions( save_dir = results_folder, save_plot = TRUE, show_plot = FALSE, return_plot = FALSE, python_path = python_path ) ## load data ### meta data meta_df &lt;- read.csv(file.path(data_path, &quot;cell_labels.csv&quot;), colClasses = &quot;character&quot;) # as the cell IDs are 30 digit numbers, set the type as character to avoid the limitation of R in handling larger integers colnames(meta_df)[[1]] &lt;- &quot;cell_ID&quot; slice1_meta_df &lt;- meta_df[meta_df$slice_id == &quot;mouse2_slice229&quot;,] # subset selected slice meta info slice2_meta_df &lt;- meta_df[meta_df$slice_id == &quot;mouse2_slice300&quot;,] # subset selected slice meta info ### counts matrix scanpy_installed &lt;- GiottoClass:::checkPythonPackage(&quot;scanpy&quot;, env_to_use = &quot;giotto_env&quot;) ad2g_path &lt;- system.file(&quot;python&quot;, &quot;ad2g.py&quot;, package = &quot;Giotto&quot;) reticulate::source_python(ad2g_path) adata &lt;- read_anndata_from_path(file.path(data_path, &quot;counts.h5ad&quot;)) X &lt;- extract_expression(adata) cID &lt;- extract_cell_IDs(adata) fID &lt;- extract_feat_IDs(adata) rownames(X) &lt;- fID colnames(X) &lt;- cID slice1_filter &lt;- cID %in% slice1_meta_df$cell_ID slice2_filter &lt;- cID %in% slice2_meta_df$cell_ID slice1_exp &lt;- X[,slice1_filter] slice2_exp &lt;- X[,slice2_filter] ### cell segmentation to cell location segments_1_df &lt;- read.csv(file.path(data_path, &quot;segmented_cells_mouse2sample1.csv&quot;), row.names=1, colClasses = &quot;character&quot;) # as the cell IDs are 30 digit numbers, set the type as character to avoid the limitation of R in handling larger integers segments_2_df &lt;- read.csv(file.path(data_path, &quot;segmented_cells_mouse2sample6.csv&quot;), row.names=1, colClasses = &quot;character&quot;) # as the cell IDs are 30 digit numbers, set the type as character to avoid the limitation of R in handling larger integers segments_df &lt;- rbind(segments_1_df, segments_2_df) loc.use &lt;- segments_df[c(slice1_meta_df$cell_ID, slice2_meta_df$cell_ID),] loc.x &lt;- grep(&#39;boundaryX_&#39;,colnames(loc.use),value = T) loc.y &lt;- grep(&#39;boundaryY_&#39;,colnames(loc.use),value = T) centr.x &lt;- apply(loc.use[,loc.x],1,function(x){ temp &lt;- lapply(x,function(y){ as.numeric(unlist(strsplit(y,&#39;, &#39;))) }) return (median(unname(unlist(temp)))) }) centr.y &lt;- apply(loc.use[,loc.y],1,function(x){ temp &lt;- lapply(x,function(y){ as.numeric(unlist(strsplit(y,&#39;, &#39;))) }) return (median(unname(unlist(temp)))) }) spatial_locs_df &lt;- data.frame(sdimx = centr.x,sdimy = centr.y) slice1_spatial_locs_df &lt;- spatial_locs_df[slice1_meta_df$cell_ID,] slice2_spatial_locs_df &lt;- spatial_locs_df[slice2_meta_df$cell_ID,] ## giotto obj giotto_obj_1 &lt;- createGiottoObject(expression = slice1_exp, spatial_locs = slice1_spatial_locs_df, cell_metadata = slice1_meta_df) giotto_obj_2 &lt;- createGiottoObject(expression = slice2_exp, spatial_locs = slice2_spatial_locs_df, cell_metadata = slice2_meta_df) giotto_obj = joinGiottoObjects(gobject_list = list(giotto_obj_1, giotto_obj_2), gobject_names = c(&#39;mouse2_slice229&#39;, &#39;mouse2_slice300&#39;), # name for each samples join_method = &#39;z_stack&#39;) # We skip the processing process here to save time and use the given cell type # annotation directly ONTraC_input &lt;- getONTraCv1Input(gobject = giotto_obj, cell_type = &quot;subclass&quot;, output_path = data_path, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, verbose = TRUE) head(ONTraC_input) # Cell_ID Sample x y Cell_Type # &lt;char&gt; &lt;char&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;char&gt; # mouse2_slice229-100101435705986292663283283043431511315 mouse2_slice229 -4828.728 -2203.4502 L6 CT # mouse2_slice229-100104370212612969023746137269354247741 mouse2_slice229 -5405.400 -995.6467 OPC # mouse2_slice229-100128078183217482733448056590230529739 mouse2_slice229 -5731.403 -1071.1735 L2/3 IT # mouse2_slice229-100209662400867003194056898065587980841 mouse2_slice229 -5468.113 -1286.2465 Oligo # mouse2_slice229-100218038012295593766653119076639444055 mouse2_slice229 -6399.986 -959.7440 L2/3 IT # mouse2_slice229-100252992997994275968450436343196667192 mouse2_slice229 -6637.847 -1659.6237 Astro Spatial cell type distributions spatPlot2D(giotto_obj, group_by = &quot;slice_id&quot;, cell_color = &quot;subclass&quot;, point_size = 1, point_border_stroke = NA, legend_text = 6) 16.1.2.1 Installation ONTraC You could run ONTraC on your own laptop or on an HPC with an NVIDIA GPU node. It will run for less than 10 minutes on this example dataset. For larger datasets, running on an NVIDIA GPU is recommended, otherwise it will take a long time. source ~/.bash_profile conda create -y -n ONTraC python=3.11 conda activate ONTraC pip install git+https://github.com/gyuanlab/ONTraC.git@V2 # Retrieving notices: ...working... done # Channels: # - conda-forge # - bioconda # - r # - pytorch # - defaults # Platform: osx-arm64 # Collecting package metadata (repodata.json): ...working... done # Solving environment: ...working... done # # ## Package Plan ## # # environment location: /Users/wwang/miniconda3/envs/ONTraC # # added / updated specs: # - python=3.11 # # # The following packages will be downloaded: # # package | build # ---------------------------|----------------- # bzip2-1.0.8 | h99b78c6_7 120 KB conda-forge # openssl-3.3.1 | hfb2fe0b_2 2.8 MB conda-forge # setuptools-71.0.4 | pyhd8ed1ab_0 1.4 MB conda-forge # ------------------------------------------------------------ # Total: 4.3 MB # # The following NEW packages will be INSTALLED: # # bzip2 conda-forge/osx-arm64::bzip2-1.0.8-h99b78c6_7 # ca-certificates conda-forge/osx-arm64::ca-certificates-2024.7.4-hf0a4a13_0 # libexpat conda-forge/osx-arm64::libexpat-2.6.2-hebf3989_0 # libffi conda-forge/osx-arm64::libffi-3.4.2-h3422bc3_5 # libsqlite conda-forge/osx-arm64::libsqlite-3.46.0-hfb93653_0 # libzlib conda-forge/osx-arm64::libzlib-1.3.1-hfb2fe0b_1 # ncurses conda-forge/osx-arm64::ncurses-6.5-hb89a1cb_0 # openssl conda-forge/osx-arm64::openssl-3.3.1-hfb2fe0b_2 # pip conda-forge/noarch::pip-24.0-pyhd8ed1ab_0 # python conda-forge/osx-arm64::python-3.11.9-h932a869_0_cpython # readline conda-forge/osx-arm64::readline-8.2-h92ec313_1 # setuptools conda-forge/noarch::setuptools-71.0.4-pyhd8ed1ab_0 # tk conda-forge/osx-arm64::tk-8.6.13-h5083fa2_1 # tzdata conda-forge/noarch::tzdata-2024a-h0c530f3_0 # wheel conda-forge/noarch::wheel-0.43.0-pyhd8ed1ab_1 # xz conda-forge/osx-arm64::xz-5.2.6-h57fd34a_0 # # # # Downloading and Extracting Packages: ...working... done # Preparing transaction: ...working... done # Verifying transaction: ...working... done # Executing transaction: ...working... done # # # # To activate this environment, use # # # # $ conda activate ONTraC # # # # To deactivate an active environment, use # # # # $ conda deactivate # # Collecting git+https://github.com/gyuanlab/ONTraC.git@V2 # Cloning https://github.com/gyuanlab/ONTraC.git (to revision V2) to /private/var/ folders/4z/75w3m8r57jj3bkbbyx6shx7c0000gn/T/pip-req-build-g2zbeni3 # Running command git clone --filter=blob:none --quiet https://github.com/gyuanlab/ ONTraC.git /private/var/folders/4z/75w3m8r57jj3bkbbyx6shx7c0000gn/T/ pip-req-build-g2zbeni3 # Running command git checkout -b V2 --track origin/V2 # Resolved https://github.com/gyuanlab/ONTraC.git to commit c2cf2355da9fd5dd580ad3d9d15321f0e3a92b9d # Installing build dependencies: started # Switched to a new branch &#39;V2&#39; # branch &#39;V2&#39; set up to track &#39;origin/V2&#39;. # Installing build dependencies: finished with status &#39;done&#39; # Getting requirements to build wheel: started # Getting requirements to build wheel: finished with status &#39;done&#39; # Preparing metadata (pyproject.toml): started # Preparing metadata (pyproject.toml): finished with status &#39;done&#39; # Collecting pyyaml==6.0.1 (from ONTraC==2.0a9.dev7) # Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB) # Collecting pandas==2.2.1 (from ONTraC==2.0a9.dev7) # Using cached pandas-2.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB) # Collecting torch==2.2.1 (from ONTraC==2.0a9.dev7) # Using cached torch-2.2.1-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB) # Collecting torch-geometric==2.5.0 (from ONTraC==2.0a9.dev7) # Using cached torch_geometric-2.5.0-py3-none-any.whl.metadata (64 kB) # Collecting umap-learn==0.5.6 (from ONTraC==2.0a9.dev7) # Using cached umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB) # Collecting harmonypy==0.0.10 (from ONTraC==2.0a9.dev7) # Using cached harmonypy-0.0.10-py3-none-any.whl.metadata (3.9 kB) # Collecting leidenalg==0.10.2 (from ONTraC==2.0a9.dev7) # Using cached leidenalg-0.10.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (10 kB) # Collecting session-info (from ONTraC==2.0a9.dev7) # Using cached session_info-1.0.0-py3-none-any.whl # Collecting numpy (from harmonypy==0.0.10-&gt;ONTraC==2.0a9.dev7) # Downloading numpy-2.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (60 kB) # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.9/60.9 kB 1.7 MB/s eta 0:00:00 # Collecting scikit-learn (from harmonypy==0.0.10-&gt;ONTraC==2.0a9.dev7) # Using cached scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (12 kB) # Collecting scipy (from harmonypy==0.0.10-&gt;ONTraC==2.0a9.dev7) # Using cached scipy-1.14.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (60 kB) # Collecting igraph&lt;0.12,&gt;=0.10.0 (from leidenalg==0.10.2-&gt;ONTraC==2.0a9.dev7) # Using cached igraph-0.11.6-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.9 kB) # Collecting numpy (from harmonypy==0.0.10-&gt;ONTraC==2.0a9.dev7) # Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB) # Collecting python-dateutil&gt;=2.8.2 (from pandas==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB) # Collecting pytz&gt;=2020.1 (from pandas==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB) # Collecting tzdata&gt;=2022.7 (from pandas==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB) # Collecting filelock (from torch==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB) # Collecting typing-extensions&gt;=4.8.0 (from torch==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB) # Collecting sympy (from torch==2.2.1-&gt;ONTraC==2.0a9.dev7) # Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB) # Collecting networkx (from torch==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB) # Collecting jinja2 (from torch==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB) # Collecting fsspec (from torch==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB) # Collecting tqdm (from torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB) # Collecting aiohttp (from torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.5 kB) # Collecting requests (from torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB) # Collecting pyparsing (from torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB) # Collecting psutil&gt;=5.8.0 (from torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached psutil-6.0.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (21 kB) # Collecting numba&gt;=0.51.2 (from umap-learn==0.5.6-&gt;ONTraC==2.0a9.dev7) # Using cached numba-0.60.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.7 kB) # Collecting pynndescent&gt;=0.5 (from umap-learn==0.5.6-&gt;ONTraC==2.0a9.dev7) # Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB) # Collecting stdlib-list (from session-info-&gt;ONTraC==2.0a9.dev7) # Using cached stdlib_list-0.10.0-py3-none-any.whl.metadata (3.3 kB) # Collecting texttable&gt;=1.6.2 (from igraph&lt; 0.12,&gt;=0.10.0-&gt;leidenalg==0.10.2-&gt;ONTraC==2.0a9.dev7) # Using cached texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB) # Collecting llvmlite&lt;0.44,&gt;=0.43.0dev0 (from numba&gt;=0.51.2-&gt;umap-learn==0.5.6-&gt;ONTraC==2.0a9.dev7) # Using cached llvmlite-0.43.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB) # Collecting joblib&gt;=0.11 (from pynndescent&gt;=0.5-&gt;umap-learn==0.5.6-&gt;ONTraC==2.0a9.dev7) # Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB) # Collecting six&gt;=1.5 (from python-dateutil&gt;=2.8.2-&gt;pandas==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB) # Collecting threadpoolctl&gt;=3.1.0 (from scikit-learn-&gt;harmonypy==0.0.10-&gt;ONTraC==2.0a9.dev7) # Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB) # Collecting aiosignal&gt;=1.1.2 (from aiohttp-&gt;torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB) # Collecting attrs&gt;=17.3.0 (from aiohttp-&gt;torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB) # Collecting frozenlist&gt;=1.1.1 (from aiohttp-&gt;torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB) # Collecting multidict&lt;7.0,&gt;=4.5 (from aiohttp-&gt;torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB) # Collecting yarl&lt;2.0,&gt;=1.0 (from aiohttp-&gt;torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB) # Collecting MarkupSafe&gt;=2.0 (from jinja2-&gt;torch==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.0 kB) # Collecting charset-normalizer&lt;4,&gt;=2 (from requests-&gt;torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata ( 33 kB) # Collecting idna&lt;4,&gt;=2.5 (from requests-&gt;torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB) # Collecting urllib3&lt;3,&gt;=1.21.1 (from requests-&gt;torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB) # Collecting certifi&gt;=2017.4.17 (from requests-&gt;torch-geometric==2.5.0-&gt;ONTraC==2.0a9.dev7) # Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB) # Collecting mpmath&lt;1.4,&gt;=1.1.0 (from sympy-&gt;torch==2.2.1-&gt;ONTraC==2.0a9.dev7) # Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB) # Using cached harmonypy-0.0.10-py3-none-any.whl (20 kB) # Using cached leidenalg-0.10.2-cp38-abi3-macosx_11_0_arm64.whl (1.4 MB) # Using cached pandas-2.2.1-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB) # Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB) # Using cached torch-2.2.1-cp311-none-macosx_11_0_arm64.whl (59.7 MB) # Using cached torch_geometric-2.5.0-py3-none-any.whl (1.1 MB) # Using cached umap_learn-0.5.6-py3-none-any.whl (85 kB) # Using cached igraph-0.11.6-cp39-abi3-macosx_11_0_arm64.whl (1.8 MB) # Using cached numba-0.60.0-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB) # Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB) # Using cached psutil-6.0.0-cp38-abi3-macosx_11_0_arm64.whl (251 kB) # Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB) # Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB) # Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB) # Using cached scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB) # Using cached scipy-1.14.0-cp311-cp311-macosx_12_0_arm64.whl (29.9 MB) # Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB) # Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB) # Using cached aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl (390 kB) # Using cached filelock-3.15.4-py3-none-any.whl (16 kB) # Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB) # Using cached jinja2-3.1.4-py3-none-any.whl (133 kB) # Using cached networkx-3.3-py3-none-any.whl (1.7 MB) # Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB) # Using cached requests-2.32.3-py3-none-any.whl (64 kB) # Using cached stdlib_list-0.10.0-py3-none-any.whl (79 kB) # Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB) # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 9.3 MB/s eta 0:00:00 # Using cached tqdm-4.66.4-py3-none-any.whl (78 kB) # Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB) # Using cached attrs-23.2.0-py3-none-any.whl (60 kB) # Using cached certifi-2024.7.4-py3-none-any.whl (162 kB) # Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB) # Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB) # Using cached idna-3.7-py3-none-any.whl (66 kB) # Using cached joblib-1.4.2-py3-none-any.whl (301 kB) # Using cached llvmlite-0.43.0-cp311-cp311-macosx_11_0_arm64.whl (28.8 MB) # Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl (18 kB) # Using cached mpmath-1.3.0-py3-none-any.whl (536 kB) # Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB) # Using cached six-1.16.0-py2.py3-none-any.whl (11 kB) # Using cached texttable-1.7.0-py2.py3-none-any.whl (10 kB) # Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB) # Using cached urllib3-2.2.2-py3-none-any.whl (121 kB) # Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB) # Building wheels for collected packages: ONTraC # Building wheel for ONTraC (pyproject.toml): started # Building wheel for ONTraC (pyproject.toml): finished with status &#39;done&#39; # Created wheel for ONTraC: filename=ONTraC-2.0a9.dev7-py3-none-any.whl size=56945 sha256=cc16ceec51ea66cf0036a568db4e43d052c2d41747e31f99c17fc4665d713179 # Stored in directory: /private/var/folders/4z/75w3m8r57jj3bkbbyx6shx7c0000gn/T/ pip-ephem-wheel-cache-7kgwlhji/wheels/88/64/83/ e8e4dfd8000c8e81e9724db9f092231791d3bcb083502fe37a # Successfully built ONTraC # Installing collected packages: texttable, pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, stdlib-list, six, pyyaml, pyparsing, psutil, numpy, networkx, multidict, MarkupSafe, llvmlite, joblib, igraph, idna, fsspec, frozenlist, filelock, charset-normalizer, certifi, attrs, yarl, session-info, scipy, requests, python-dateutil, numba, leidenalg, jinja2, aiosignal, torch, scikit-learn, pandas, aiohttp, torch-geometric, pynndescent, harmonypy, umap-learn, ONTraC # Successfully installed MarkupSafe-2.1.5 ONTraC-2.0a9.dev7 aiohttp-3.9.5 aiosignal-1.3.1 attrs-23.2.0 certifi-2024.7.4 charset-normalizer-3.3.2 filelock-3.15.4 frozenlist-1.4.1 fsspec-2024.6.1 harmonypy-0.0.10 idna-3.7 igraph-0.11.6 jinja2-3.1.4 joblib-1.4.2 leidenalg-0.10.2 llvmlite-0.43.0 mpmath-1.3.0 multidict-6.0.5 networkx-3.3 numba-0.60.0 numpy-1.26.4 pandas-2.2.1 psutil-6.0.0 pynndescent-0.5.13 pyparsing-3.1.2 python-dateutil-2.9.0.post0 pytz-2024.1 pyyaml-6.0.1 requests-2.32.3 scikit-learn-1.5.1 scipy-1.14.0 session-info-1.0.0 six-1.16.0 stdlib-list-0.10.0 sympy-1.13.1 texttable-1.7.0 threadpoolctl-3.5.0 torch-2.2.1 torch-geometric-2.5.0 tqdm-4.66.4 typing-extensions-4.12.2 tzdata-2024.1 umap-learn-0.5.6 urllib3-2.2.2 yarl-1.9.4 16.1.2.2 Running ONTraC source ~/.bash_profile conda activate ONTraC_v2_py311 ONTraC -d data/ONTraC_dataset_input.csv --preprocessing-dir data/preprocessing_dir --GNN-dir data/GNN_dir --NTScore-dir data/NTScore_dir --device cuda --epochs 1000 -s 42 --patience 100 --min-delta 0.001 --min-epochs 50 --lr 0.03 --hidden-feats 4 -k 6 --modularity-loss-weight 1 --regularization-loss-weight 0.1 --purity-loss-weight 100 --beta 0.3 --equal-space 2&gt;&amp;1 | tee data/merfish_subset.log # ################################################################################## # # ▄▄█▀▀██ ▀█▄ ▀█▀ █▀▀██▀▀█ ▄▄█▀▀▀▄█ # ▄█▀ ██ █▀█ █ ██ ▄▄▄ ▄▄ ▄▄▄▄ ▄█▀ ▀ # ██ ██ █ ▀█▄ █ ██ ██▀ ▀▀ ▀▀ ▄██ ██ # ▀█▄ ██ █ ███ ██ ██ ▄█▀ ██ ▀█▄ ▄ # ▀▀█▄▄▄█▀ ▄█▄ ▀█ ▄██▄ ▄██▄ ▀█▄▄▀█▀ ▀▀█▄▄▄▄▀ # # version: 2.0a11 # # ################################################################################## # 11:33:23 --- WARNING: The directory (data/preprocessing_dir) you given already exists. It will be overwritten. # 11:33:23 --- WARNING: The directory (data/GNN_dir) you given already exists. It will be overwritten. # 11:33:23 --- WARNING: The directory (data/NTScore_dir) you given already exists. It will be overwritten. # 11:33:23 --- WARNING: CUDA is not available, use CPU instead. # 11:33:23 --- INFO: ------------------ RUN params memo ------------------ # 11:33:23 --- INFO: -------- I/O options ------- # 11:33:23 --- INFO: meta data file: data/ONTraC_dataset_input.csv # 11:33:23 --- INFO: preprocessing output directory: data/preprocessing_dir # 11:33:23 --- INFO: GNN output directory: data/GNN_dir # 11:33:23 --- INFO: NTScore output directory: data/NTScore_dir # 11:33:23 --- INFO: -------- preprocessing options ------- # 11:33:23 --- INFO: resolution: 10.0 # 11:33:23 --- INFO: -------- niche net constr options ------- # 11:33:23 --- INFO: n_cpu: 4 # 11:33:23 --- INFO: n_neighbors: 50 # 11:33:23 --- INFO: n_local: 20 # 11:33:23 --- INFO: embedding_adjust: False # 11:33:23 --- INFO: sigma: 1 # 11:33:23 --- INFO: -------- train options ------- # 11:33:23 --- INFO: device: cpu # 11:33:23 --- INFO: epochs: 1000 # 11:33:23 --- INFO: batch_size: 0 # 11:33:23 --- INFO: patience: 100 # 11:33:23 --- INFO: min_delta: 0.001 # 11:33:23 --- INFO: min_epochs: 50 # 11:33:23 --- INFO: seed: 42 # 11:33:23 --- INFO: lr: 0.03 # 11:33:23 --- INFO: hidden_feats: 4 # 11:33:23 --- INFO: k: 6 # 11:33:23 --- INFO: modularity_loss_weight: 1.0 # 11:33:23 --- INFO: purity_loss_weight: 100.0 # 11:33:23 --- INFO: regularization_loss_weight: 0.1 # 11:33:23 --- INFO: beta: 0.3 # 11:33:23 --- INFO: ---------------- Niche trajectory options ---------------- # 11:33:23 --- INFO: Equally spaced niche cluster scores: True # 11:33:23 --- INFO: --------------- RUN params memo end ----------------- # 11:33:23 --- INFO: ------------- Niche network construct --------------- # 11:33:23 --- INFO: Constructing niche network for sample: mouse2_slice229. # 11:33:26 --- INFO: Constructing niche network for sample: mouse2_slice300. # 11:33:28 --- INFO: Generating samples.yaml file. # 11:33:28 --- INFO: ------------ Niche network construct end ------------ # 11:33:28 --- INFO: ------------------------ GNN ------------------------ # 11:33:28 --- INFO: Loading dataset. # 11:33:28 --- INFO: Maximum number of cell in one sample is: 5100. # Processing... # 11:33:28 --- INFO: Processing sample 1 of 2: mouse2_slice229 # 11:33:28 --- INFO: Processing sample 2 of 2: mouse2_slice300 # Done! # 11:33:28 --- INFO: Processing sample 1 of 2: mouse2_slice229 # 11:33:28 --- INFO: Processing sample 2 of 2: mouse2_slice300 # 11:33:28 --- INFO: epoch: 1, batch: 1, loss: 23.001523971557617, modularity_loss: -0.0023897262290120125, purity_loss: 22.934659957885742, regularization_loss: 0.06925322115421295 # 11:33:29 --- INFO: epoch: 2, batch: 1, loss: 22.768497467041016, modularity_loss: -0.005293438211083412, purity_loss: 22.704635620117188, regularization_loss: 0.06915470957756042 # 11:33:29 --- INFO: epoch: 3, batch: 1, loss: 22.37835121154785, modularity_loss: -0.010112201794981956, purity_loss: 22.319320678710938, regularization_loss: 0.06914201378822327 # 11:33:29 --- INFO: epoch: 4, batch: 1, loss: 21.823326110839844, modularity_loss: -0.016986437141895294, purity_loss: 21.77100944519043, regularization_loss: 0.06930312514305115 # 11:33:30 --- INFO: epoch: 5, batch: 1, loss: 21.139827728271484, modularity_loss: -0.025495745241642, purity_loss: 21.095653533935547, regularization_loss: 0.0696694627404213 # 11:33:30 --- INFO: epoch: 6, batch: 1, loss: 20.39137077331543, modularity_loss: -0.03495821729302406, purity_loss: 20.356155395507812, regularization_loss: 0.0701739713549614 # 11:33:30 --- INFO: epoch: 7, batch: 1, loss: 19.641571044921875, modularity_loss: -0.045391954481601715, purity_loss: 19.616260528564453, regularization_loss: 0.07070285081863403 # 11:33:31 --- INFO: epoch: 8, batch: 1, loss: 18.925037384033203, modularity_loss: -0.05757240578532219, purity_loss: 18.911428451538086, regularization_loss: 0.0711822658777237 # 11:33:31 --- INFO: epoch: 9, batch: 1, loss: 18.263259887695312, modularity_loss: -0.0717809870839119, purity_loss: 18.263416290283203, regularization_loss: 0.07162471860647202 # 11:33:31 --- INFO: epoch: 10, batch: 1, loss: 17.685840606689453, modularity_loss: -0.08731567114591599, purity_loss: 17.701066970825195, regularization_loss: 0.07208941131830215 # 11:33:31 --- INFO: epoch: 11, batch: 1, loss: 17.217161178588867, modularity_loss: -0.10291540622711182, purity_loss: 17.247447967529297, regularization_loss: 0.07262824475765228 # 11:33:32 --- INFO: epoch: 12, batch: 1, loss: 16.85984230041504, modularity_loss: -0.11742901802062988, purity_loss: 16.904020309448242, regularization_loss: 0.07325152307748795 # 11:33:32 --- INFO: epoch: 13, batch: 1, loss: 16.59726905822754, modularity_loss: -0.13028934597969055, purity_loss: 16.653614044189453, regularization_loss: 0.07394523918628693 # 11:33:32 --- INFO: epoch: 14, batch: 1, loss: 16.409076690673828, modularity_loss: -0.14140018820762634, purity_loss: 16.47577476501465, regularization_loss: 0.07470250874757767 # 11:33:33 --- INFO: epoch: 15, batch: 1, loss: 16.27598762512207, modularity_loss: -0.15096718072891235, purity_loss: 16.351421356201172, regularization_loss: 0.07553426176309586 # 11:33:33 --- INFO: epoch: 16, batch: 1, loss: 16.18242645263672, modularity_loss: -0.15935572981834412, purity_loss: 16.26532745361328, regularization_loss: 0.07645474374294281 # 11:33:33 --- INFO: epoch: 17, batch: 1, loss: 16.117395401000977, modularity_loss: -0.16692203283309937, purity_loss: 16.20685577392578, regularization_loss: 0.07746140658855438 # 11:33:33 --- INFO: epoch: 18, batch: 1, loss: 16.072946548461914, modularity_loss: -0.17391526699066162, purity_loss: 16.168333053588867, regularization_loss: 0.07852821052074432 # 11:33:34 --- INFO: epoch: 19, batch: 1, loss: 16.042552947998047, modularity_loss: -0.18049469590187073, purity_loss: 16.143430709838867, regularization_loss: 0.07961639761924744 # 11:33:34 --- INFO: epoch: 20, batch: 1, loss: 16.020952224731445, modularity_loss: -0.18679285049438477, purity_loss: 16.12704849243164, regularization_loss: 0.08069746196269989 # 11:33:34 --- INFO: epoch: 21, batch: 1, loss: 16.004188537597656, modularity_loss: -0.19300395250320435, purity_loss: 16.11542510986328, regularization_loss: 0.08176703751087189 # 11:33:35 --- INFO: epoch: 22, batch: 1, loss: 15.989411354064941, modularity_loss: -0.19940897822380066, purity_loss: 16.105968475341797, regularization_loss: 0.0828515961766243 # 11:33:35 --- INFO: epoch: 23, batch: 1, loss: 15.974446296691895, modularity_loss: -0.20637741684913635, purity_loss: 16.096820831298828, regularization_loss: 0.08400280028581619 # 11:33:35 --- INFO: epoch: 24, batch: 1, loss: 15.957433700561523, modularity_loss: -0.2143288552761078, purity_loss: 16.08647346496582, regularization_loss: 0.08528861403465271 # 11:33:35 --- INFO: epoch: 25, batch: 1, loss: 15.936773300170898, modularity_loss: -0.2236764132976532, purity_loss: 16.073673248291016, regularization_loss: 0.08677610009908676 # 11:33:36 --- INFO: epoch: 26, batch: 1, loss: 15.911301612854004, modularity_loss: -0.23471668362617493, purity_loss: 16.057510375976562, regularization_loss: 0.08850813657045364 # 11:33:36 --- INFO: epoch: 27, batch: 1, loss: 15.880578994750977, modularity_loss: -0.24747242033481598, purity_loss: 16.037572860717773, regularization_loss: 0.09047902375459671 # 11:33:36 --- INFO: epoch: 28, batch: 1, loss: 15.845392227172852, modularity_loss: -0.26156920194625854, purity_loss: 16.014341354370117, regularization_loss: 0.09261994063854218 # 11:33:37 --- INFO: epoch: 29, batch: 1, loss: 15.807584762573242, modularity_loss: -0.27627527713775635, purity_loss: 15.989053726196289, regularization_loss: 0.09480661898851395 # 11:33:37 --- INFO: epoch: 30, batch: 1, loss: 15.769493103027344, modularity_loss: -0.2906855046749115, purity_loss: 15.963276863098145, regularization_loss: 0.09690161794424057 # 11:33:37 --- INFO: epoch: 31, batch: 1, loss: 15.733196258544922, modularity_loss: -0.3040352165699005, purity_loss: 15.938435554504395, regularization_loss: 0.09879627078771591 # 11:33:37 --- INFO: epoch: 32, batch: 1, loss: 15.699841499328613, modularity_loss: -0.31587138772010803, purity_loss: 15.915274620056152, regularization_loss: 0.10043793171644211 # 11:33:38 --- INFO: epoch: 33, batch: 1, loss: 15.669454574584961, modularity_loss: -0.32608187198638916, purity_loss: 15.89371109008789, regularization_loss: 0.1018255203962326 # 11:33:38 --- INFO: epoch: 34, batch: 1, loss: 15.641484260559082, modularity_loss: -0.33480289578437805, purity_loss: 15.873299598693848, regularization_loss: 0.10298792272806168 # 11:33:38 --- INFO: epoch: 35, batch: 1, loss: 15.614999771118164, modularity_loss: -0.34228256344795227, purity_loss: 15.853317260742188, regularization_loss: 0.10396471619606018 # 11:33:39 --- INFO: epoch: 36, batch: 1, loss: 15.589118003845215, modularity_loss: -0.3488248586654663, purity_loss: 15.833154678344727, regularization_loss: 0.10478848218917847 # 11:33:39 --- INFO: epoch: 37, batch: 1, loss: 15.56322193145752, modularity_loss: -0.35469937324523926, purity_loss: 15.812437057495117, regularization_loss: 0.1054840087890625 # 11:33:39 --- INFO: epoch: 38, batch: 1, loss: 15.536772727966309, modularity_loss: -0.3601019084453583, purity_loss: 15.790804862976074, regularization_loss: 0.10606933385133743 # 11:33:39 --- INFO: epoch: 39, batch: 1, loss: 15.508807182312012, modularity_loss: -0.36518266797065735, purity_loss: 15.767438888549805, regularization_loss: 0.10655105113983154 # 11:33:40 --- INFO: epoch: 40, batch: 1, loss: 15.478368759155273, modularity_loss: -0.3700413703918457, purity_loss: 15.741480827331543, regularization_loss: 0.10692881792783737 # 11:33:40 --- INFO: epoch: 41, batch: 1, loss: 15.44459342956543, modularity_loss: -0.37471112608909607, purity_loss: 15.712104797363281, regularization_loss: 0.10719987750053406 # 11:33:40 --- INFO: epoch: 42, batch: 1, loss: 15.40697956085205, modularity_loss: -0.37914952635765076, purity_loss: 15.678765296936035, regularization_loss: 0.10736335813999176 # 11:33:41 --- INFO: epoch: 43, batch: 1, loss: 15.364958763122559, modularity_loss: -0.38326019048690796, purity_loss: 15.640804290771484, regularization_loss: 0.10741502791643143 # 11:33:41 --- INFO: epoch: 44, batch: 1, loss: 15.317839622497559, modularity_loss: -0.38691914081573486, purity_loss: 15.597410202026367, regularization_loss: 0.10734901577234268 # 11:33:41 --- INFO: epoch: 45, batch: 1, loss: 15.265110969543457, modularity_loss: -0.38995009660720825, purity_loss: 15.547901153564453, regularization_loss: 0.10716016590595245 # 11:33:41 --- INFO: epoch: 46, batch: 1, loss: 15.20550537109375, modularity_loss: -0.3921312093734741, purity_loss: 15.490798950195312, regularization_loss: 0.10683741420507431 # 11:33:42 --- INFO: epoch: 47, batch: 1, loss: 15.136863708496094, modularity_loss: -0.39331942796707153, purity_loss: 15.423828125, regularization_loss: 0.10635543614625931 # 11:33:42 --- INFO: epoch: 48, batch: 1, loss: 15.056995391845703, modularity_loss: -0.3934229612350464, purity_loss: 15.34473705291748, regularization_loss: 0.10568106919527054 # 11:33:42 --- INFO: epoch: 49, batch: 1, loss: 14.964367866516113, modularity_loss: -0.392358660697937, purity_loss: 15.251948356628418, regularization_loss: 0.10477815568447113 # 11:33:43 --- INFO: epoch: 50, batch: 1, loss: 14.857380867004395, modularity_loss: -0.39002490043640137, purity_loss: 15.143804550170898, regularization_loss: 0.10360138863325119 # 11:33:43 --- INFO: epoch: 51, batch: 1, loss: 14.736187934875488, modularity_loss: -0.3862961530685425, purity_loss: 15.02037525177002, regularization_loss: 0.10210883617401123 # 11:33:43 --- INFO: epoch: 52, batch: 1, loss: 14.603105545043945, modularity_loss: -0.38095587491989136, purity_loss: 14.883785247802734, regularization_loss: 0.10027574747800827 # 11:33:43 --- INFO: epoch: 53, batch: 1, loss: 14.458536148071289, modularity_loss: -0.3737679719924927, purity_loss: 14.734207153320312, regularization_loss: 0.09809701144695282 # 11:33:44 --- INFO: epoch: 54, batch: 1, loss: 14.297077178955078, modularity_loss: -0.36470723152160645, purity_loss: 14.566164016723633, regularization_loss: 0.09562009572982788 # 11:33:44 --- INFO: epoch: 55, batch: 1, loss: 14.101924896240234, modularity_loss: -0.35435616970062256, purity_loss: 14.36331558227539, regularization_loss: 0.09296524524688721 # 11:33:44 --- INFO: epoch: 56, batch: 1, loss: 13.850761413574219, modularity_loss: -0.3440517783164978, purity_loss: 14.104469299316406, regularization_loss: 0.09034416824579239 # 11:33:45 --- INFO: epoch: 57, batch: 1, loss: 13.542003631591797, modularity_loss: -0.33538782596588135, purity_loss: 13.789325714111328, regularization_loss: 0.08806595206260681 # 11:33:45 --- INFO: epoch: 58, batch: 1, loss: 13.19692611694336, modularity_loss: -0.3292675316333771, purity_loss: 13.43971061706543, regularization_loss: 0.08648291230201721 # 11:33:45 --- INFO: epoch: 59, batch: 1, loss: 12.85534954071045, modularity_loss: -0.3257511854171753, purity_loss: 13.095155715942383, regularization_loss: 0.08594459295272827 # 11:33:45 --- INFO: epoch: 60, batch: 1, loss: 12.5657958984375, modularity_loss: -0.32381701469421387, purity_loss: 12.803165435791016, regularization_loss: 0.08644744753837585 # 11:33:46 --- INFO: epoch: 61, batch: 1, loss: 12.347742080688477, modularity_loss: -0.3218806982040405, purity_loss: 12.58204460144043, regularization_loss: 0.08757861703634262 # 11:33:46 --- INFO: epoch: 62, batch: 1, loss: 12.205147743225098, modularity_loss: -0.31888464093208313, purity_loss: 12.435131072998047, regularization_loss: 0.08890123665332794 # 11:33:46 --- INFO: epoch: 63, batch: 1, loss: 12.128698348999023, modularity_loss: -0.31569480895996094, purity_loss: 12.35433292388916, regularization_loss: 0.09006011486053467 # 11:33:47 --- INFO: epoch: 64, batch: 1, loss: 12.073147773742676, modularity_loss: -0.3147158622741699, purity_loss: 12.297168731689453, regularization_loss: 0.09069512784481049 # 11:33:47 --- INFO: epoch: 65, batch: 1, loss: 11.988947868347168, modularity_loss: -0.3177931010723114, purity_loss: 12.216124534606934, regularization_loss: 0.09061658382415771 # 11:33:47 --- INFO: epoch: 66, batch: 1, loss: 11.866996765136719, modularity_loss: -0.32488876581192017, purity_loss: 12.101926803588867, regularization_loss: 0.08995886892080307 # 11:33:48 --- INFO: epoch: 67, batch: 1, loss: 11.727216720581055, modularity_loss: -0.33459246158599854, purity_loss: 11.972763061523438, regularization_loss: 0.0890461802482605 # 11:33:48 --- INFO: epoch: 68, batch: 1, loss: 11.589557647705078, modularity_loss: -0.3454422354698181, purity_loss: 11.846831321716309, regularization_loss: 0.08816889673471451 # 11:33:48 --- INFO: epoch: 69, batch: 1, loss: 11.461546897888184, modularity_loss: -0.3565739095211029, purity_loss: 11.730629920959473, regularization_loss: 0.0874905213713646 # 11:33:48 --- INFO: epoch: 70, batch: 1, loss: 11.341334342956543, modularity_loss: -0.3676247000694275, purity_loss: 11.621889114379883, regularization_loss: 0.08707026392221451 # 11:33:49 --- INFO: epoch: 71, batch: 1, loss: 11.220848083496094, modularity_loss: -0.37854552268981934, purity_loss: 11.512494087219238, regularization_loss: 0.08689992129802704 # 11:33:49 --- INFO: epoch: 72, batch: 1, loss: 11.089977264404297, modularity_loss: -0.38959217071533203, purity_loss: 11.392634391784668, regularization_loss: 0.08693493902683258 # 11:33:49 --- INFO: epoch: 73, batch: 1, loss: 10.936225891113281, modularity_loss: -0.40123844146728516, purity_loss: 11.250344276428223, regularization_loss: 0.08711998164653778 # 11:33:50 --- INFO: epoch: 74, batch: 1, loss: 10.774359703063965, modularity_loss: -0.412983775138855, purity_loss: 11.099967956542969, regularization_loss: 0.0873752236366272 # 11:33:50 --- INFO: epoch: 75, batch: 1, loss: 10.597075462341309, modularity_loss: -0.4235861301422119, purity_loss: 10.933009147644043, regularization_loss: 0.08765210211277008 # 11:33:50 --- INFO: epoch: 76, batch: 1, loss: 10.376021385192871, modularity_loss: -0.43360933661460876, purity_loss: 10.721734046936035, regularization_loss: 0.08789674937725067 # 11:33:51 --- INFO: epoch: 77, batch: 1, loss: 10.101761817932129, modularity_loss: -0.44318681955337524, purity_loss: 10.456952095031738, regularization_loss: 0.08799697458744049 # 11:33:51 --- INFO: epoch: 78, batch: 1, loss: 9.784876823425293, modularity_loss: -0.4515224099159241, purity_loss: 10.148638725280762, regularization_loss: 0.08776087313890457 # 11:33:51 --- INFO: epoch: 79, batch: 1, loss: 9.458683013916016, modularity_loss: -0.4569146931171417, purity_loss: 9.828640937805176, regularization_loss: 0.08695651590824127 # 11:33:52 --- INFO: epoch: 80, batch: 1, loss: 9.178531646728516, modularity_loss: -0.45679569244384766, purity_loss: 9.549927711486816, regularization_loss: 0.08539916574954987 # 11:33:52 --- INFO: epoch: 81, batch: 1, loss: 9.000457763671875, modularity_loss: -0.4497307538986206, purity_loss: 9.366915702819824, regularization_loss: 0.08327241241931915 # 11:33:52 --- INFO: epoch: 82, batch: 1, loss: 8.898308753967285, modularity_loss: -0.4418599605560303, purity_loss: 9.258613586425781, regularization_loss: 0.08155520260334015 # 11:33:52 --- INFO: epoch: 83, batch: 1, loss: 8.760506629943848, modularity_loss: -0.44438159465789795, purity_loss: 9.123655319213867, regularization_loss: 0.08123327046632767 # 11:33:53 --- INFO: epoch: 84, batch: 1, loss: 8.54394245147705, modularity_loss: -0.45904988050460815, purity_loss: 8.920684814453125, regularization_loss: 0.08230743557214737 # 11:33:53 --- INFO: epoch: 85, batch: 1, loss: 8.314882278442383, modularity_loss: -0.4775947332382202, purity_loss: 8.708457946777344, regularization_loss: 0.08401863276958466 # 11:33:53 --- INFO: epoch: 86, batch: 1, loss: 8.135581970214844, modularity_loss: -0.492197185754776, purity_loss: 8.542383193969727, regularization_loss: 0.08539611101150513 # 11:33:54 --- INFO: epoch: 87, batch: 1, loss: 7.994486331939697, modularity_loss: -0.5015395879745483, purity_loss: 8.410036087036133, regularization_loss: 0.08598977327346802 # 11:33:54 --- INFO: epoch: 88, batch: 1, loss: 7.859262943267822, modularity_loss: -0.5070834159851074, purity_loss: 8.280491828918457, regularization_loss: 0.08585438132286072 # 11:33:54 --- INFO: epoch: 89, batch: 1, loss: 7.714503765106201, modularity_loss: -0.5096077919006348, purity_loss: 8.138916969299316, regularization_loss: 0.08519440144300461 # 11:33:55 --- INFO: epoch: 90, batch: 1, loss: 7.556613445281982, modularity_loss: -0.5087662935256958, purity_loss: 7.981185436248779, regularization_loss: 0.08419422060251236 # 11:33:55 --- INFO: epoch: 91, batch: 1, loss: 7.387192249298096, modularity_loss: -0.5037617683410645, purity_loss: 7.807967662811279, regularization_loss: 0.08298640698194504 # 11:33:55 --- INFO: epoch: 92, batch: 1, loss: 7.229267597198486, modularity_loss: -0.4948621988296509, purity_loss: 7.642430782318115, regularization_loss: 0.08169892430305481 # 11:33:56 --- INFO: epoch: 93, batch: 1, loss: 7.137825012207031, modularity_loss: -0.48517730832099915, purity_loss: 7.542435169219971, regularization_loss: 0.08056731522083282 # 11:33:56 --- INFO: epoch: 94, batch: 1, loss: 7.1067352294921875, modularity_loss: -0.47995471954345703, purity_loss: 7.5068511962890625, regularization_loss: 0.079838827252388 # 11:33:56 --- INFO: epoch: 95, batch: 1, loss: 7.045711994171143, modularity_loss: -0.48180586099624634, purity_loss: 7.448028087615967, regularization_loss: 0.0794895812869072 # 11:33:57 --- INFO: epoch: 96, batch: 1, loss: 6.957595348358154, modularity_loss: -0.48858559131622314, purity_loss: 7.366804122924805, regularization_loss: 0.07937701046466827 # 11:33:57 --- INFO: epoch: 97, batch: 1, loss: 6.891050815582275, modularity_loss: -0.49676376581192017, purity_loss: 7.308403968811035, regularization_loss: 0.0794105976819992 # 11:33:57 --- INFO: epoch: 98, batch: 1, loss: 6.855169773101807, modularity_loss: -0.5040184855461121, purity_loss: 7.279667377471924, regularization_loss: 0.07952070236206055 # 11:33:57 --- INFO: epoch: 99, batch: 1, loss: 6.834170818328857, modularity_loss: -0.509428858757019, purity_loss: 7.263950347900391, regularization_loss: 0.07964947819709778 # 11:33:58 --- INFO: epoch: 100, batch: 1, loss: 6.814302921295166, modularity_loss: -0.5128939151763916, purity_loss: 7.247436046600342, regularization_loss: 0.07976070791482925 # 11:33:58 --- INFO: epoch: 101, batch: 1, loss: 6.791234493255615, modularity_loss: -0.5147401094436646, purity_loss: 7.226131916046143, regularization_loss: 0.07984252274036407 # 11:33:58 --- INFO: epoch: 102, batch: 1, loss: 6.767107963562012, modularity_loss: -0.5154187679290771, purity_loss: 7.202628135681152, regularization_loss: 0.07989867776632309 # 11:33:59 --- INFO: epoch: 103, batch: 1, loss: 6.745961666107178, modularity_loss: -0.5153516530990601, purity_loss: 7.1813764572143555, regularization_loss: 0.07993695139884949 # 11:33:59 --- INFO: epoch: 104, batch: 1, loss: 6.73048734664917, modularity_loss: -0.5148610472679138, purity_loss: 7.165385723114014, regularization_loss: 0.07996267825365067 # 11:33:59 --- INFO: epoch: 105, batch: 1, loss: 6.7206220626831055, modularity_loss: -0.5141782760620117, purity_loss: 7.154825210571289, regularization_loss: 0.07997535914182663 # 11:34:00 --- INFO: epoch: 106, batch: 1, loss: 6.713866233825684, modularity_loss: -0.5134555101394653, purity_loss: 7.147350788116455, regularization_loss: 0.07997094839811325 # 11:34:00 --- INFO: epoch: 107, batch: 1, loss: 6.707263469696045, modularity_loss: -0.5127870440483093, purity_loss: 7.140103816986084, regularization_loss: 0.07994650304317474 # 11:34:00 --- INFO: epoch: 108, batch: 1, loss: 6.698901176452637, modularity_loss: -0.5122053027153015, purity_loss: 7.13120698928833, regularization_loss: 0.07989972829818726 # 11:34:01 --- INFO: epoch: 109, batch: 1, loss: 6.688510417938232, modularity_loss: -0.5117073059082031, purity_loss: 7.120386600494385, regularization_loss: 0.07983095198869705 # 11:34:01 --- INFO: epoch: 110, batch: 1, loss: 6.6772356033325195, modularity_loss: -0.5112631320953369, purity_loss: 7.1087541580200195, regularization_loss: 0.07974453270435333 # 11:34:01 --- INFO: epoch: 111, batch: 1, loss: 6.666220188140869, modularity_loss: -0.510830283164978, purity_loss: 7.097405433654785, regularization_loss: 0.07964499294757843 # 11:34:01 --- INFO: epoch: 112, batch: 1, loss: 6.656651496887207, modularity_loss: -0.5103691816329956, purity_loss: 7.087483882904053, regularization_loss: 0.07953672111034393 # 11:34:02 --- INFO: epoch: 113, batch: 1, loss: 6.649173736572266, modularity_loss: -0.5098740458488464, purity_loss: 7.079622745513916, regularization_loss: 0.07942516356706619 # 11:34:02 --- INFO: epoch: 114, batch: 1, loss: 6.643716812133789, modularity_loss: -0.5093961358070374, purity_loss: 7.073794364929199, regularization_loss: 0.07931867986917496 # 11:34:02 --- INFO: epoch: 115, batch: 1, loss: 6.639582633972168, modularity_loss: -0.509020209312439, purity_loss: 7.0693769454956055, regularization_loss: 0.07922565191984177 # 11:34:03 --- INFO: epoch: 116, batch: 1, loss: 6.635583400726318, modularity_loss: -0.5088145732879639, purity_loss: 7.065243244171143, regularization_loss: 0.07915476709604263 # 11:34:03 --- INFO: epoch: 117, batch: 1, loss: 6.630502700805664, modularity_loss: -0.5087877511978149, purity_loss: 7.060179233551025, regularization_loss: 0.07911141961812973 # 11:34:03 --- INFO: epoch: 118, batch: 1, loss: 6.623572826385498, modularity_loss: -0.5089311599731445, purity_loss: 7.05340576171875, regularization_loss: 0.07909806072711945 # 11:34:04 --- INFO: epoch: 119, batch: 1, loss: 6.614688396453857, modularity_loss: -0.5092304944992065, purity_loss: 7.04480504989624, regularization_loss: 0.07911382615566254 # 11:34:04 --- INFO: epoch: 120, batch: 1, loss: 6.6042094230651855, modularity_loss: -0.5096694231033325, purity_loss: 7.034723281860352, regularization_loss: 0.07915548980236053 # 11:34:04 --- INFO: epoch: 121, batch: 1, loss: 6.592793941497803, modularity_loss: -0.5102277398109436, purity_loss: 7.0238037109375, regularization_loss: 0.07921795547008514 # 11:34:05 --- INFO: epoch: 122, batch: 1, loss: 6.581190586090088, modularity_loss: -0.5108745098114014, purity_loss: 7.012771129608154, regularization_loss: 0.07929384708404541 # 11:34:05 --- INFO: epoch: 123, batch: 1, loss: 6.56988000869751, modularity_loss: -0.5115731954574585, purity_loss: 7.002078533172607, regularization_loss: 0.07937465608119965 # 11:34:05 --- INFO: epoch: 124, batch: 1, loss: 6.55911111831665, modularity_loss: -0.5122793912887573, purity_loss: 6.991938591003418, regularization_loss: 0.07945197075605392 # 11:34:06 --- INFO: epoch: 125, batch: 1, loss: 6.548907279968262, modularity_loss: -0.5129407644271851, purity_loss: 6.9823317527771, regularization_loss: 0.07951626181602478 # 11:34:06 --- INFO: epoch: 126, batch: 1, loss: 6.539026260375977, modularity_loss: -0.513504147529602, purity_loss: 6.972971439361572, regularization_loss: 0.0795588493347168 # 11:34:06 --- INFO: epoch: 127, batch: 1, loss: 6.529170036315918, modularity_loss: -0.5139155387878418, purity_loss: 6.963512897491455, regularization_loss: 0.07957267761230469 # 11:34:06 --- INFO: epoch: 128, batch: 1, loss: 6.51899528503418, modularity_loss: -0.5141267776489258, purity_loss: 6.953570365905762, regularization_loss: 0.07955189049243927 # 11:34:07 --- INFO: epoch: 129, batch: 1, loss: 6.508218288421631, modularity_loss: -0.5141019225120544, purity_loss: 6.942827224731445, regularization_loss: 0.07949298620223999 # 11:34:07 --- INFO: epoch: 130, batch: 1, loss: 6.496604919433594, modularity_loss: -0.5138121247291565, purity_loss: 6.931023120880127, regularization_loss: 0.0793939158320427 # 11:34:07 --- INFO: epoch: 131, batch: 1, loss: 6.483977317810059, modularity_loss: -0.5132466554641724, purity_loss: 6.917969226837158, regularization_loss: 0.07925453782081604 # 11:34:08 --- INFO: epoch: 132, batch: 1, loss: 6.47015905380249, modularity_loss: -0.5124086141586304, purity_loss: 6.903491020202637, regularization_loss: 0.07907651364803314 # 11:34:08 --- INFO: epoch: 133, batch: 1, loss: 6.455018043518066, modularity_loss: -0.5113234519958496, purity_loss: 6.887477874755859, regularization_loss: 0.07886337488889694 # 11:34:08 --- INFO: epoch: 134, batch: 1, loss: 6.438426494598389, modularity_loss: -0.5100424289703369, purity_loss: 6.869848728179932, regularization_loss: 0.07862036675214767 # 11:34:08 --- INFO: epoch: 135, batch: 1, loss: 6.420292377471924, modularity_loss: -0.5086501240730286, purity_loss: 6.850588321685791, regularization_loss: 0.07835423201322556 # 11:34:09 --- INFO: epoch: 136, batch: 1, loss: 6.400551795959473, modularity_loss: -0.5072620511054993, purity_loss: 6.829740047454834, regularization_loss: 0.07807356864213943 # 11:34:09 --- INFO: epoch: 137, batch: 1, loss: 6.379120826721191, modularity_loss: -0.5060297250747681, purity_loss: 6.807362079620361, regularization_loss: 0.07778850197792053 # 11:34:09 --- INFO: epoch: 138, batch: 1, loss: 6.355955600738525, modularity_loss: -0.5051349401473999, purity_loss: 6.783579349517822, regularization_loss: 0.07751131057739258 # 11:34:10 --- INFO: epoch: 139, batch: 1, loss: 6.33098030090332, modularity_loss: -0.5047597289085388, purity_loss: 6.758484363555908, regularization_loss: 0.07725586742162704 # 11:34:10 --- INFO: epoch: 140, batch: 1, loss: 6.304221153259277, modularity_loss: -0.5050544738769531, purity_loss: 6.732240200042725, regularization_loss: 0.07703562825918198 # 11:34:10 --- INFO: epoch: 141, batch: 1, loss: 6.275861740112305, modularity_loss: -0.5061154961585999, purity_loss: 6.705114364624023, regularization_loss: 0.07686273753643036 # 11:34:11 --- INFO: epoch: 142, batch: 1, loss: 6.2462382316589355, modularity_loss: -0.5079628229141235, purity_loss: 6.677453994750977, regularization_loss: 0.0767468735575676 # 11:34:11 --- INFO: epoch: 143, batch: 1, loss: 6.215826034545898, modularity_loss: -0.510533332824707, purity_loss: 6.6496663093566895, regularization_loss: 0.07669306546449661 # 11:34:11 --- INFO: epoch: 144, batch: 1, loss: 6.185096740722656, modularity_loss: -0.5137086510658264, purity_loss: 6.622103691101074, regularization_loss: 0.0767018273472786 # 11:34:11 --- INFO: epoch: 145, batch: 1, loss: 6.154420852661133, modularity_loss: -0.517345666885376, purity_loss: 6.594995975494385, regularization_loss: 0.0767703503370285 # 11:34:12 --- INFO: epoch: 146, batch: 1, loss: 6.123962879180908, modularity_loss: -0.5213078856468201, purity_loss: 6.568376541137695, regularization_loss: 0.07689441740512848 # 11:34:12 --- INFO: epoch: 147, batch: 1, loss: 6.093730926513672, modularity_loss: -0.5254709124565125, purity_loss: 6.542133331298828, regularization_loss: 0.07706832140684128 # 11:34:12 --- INFO: epoch: 148, batch: 1, loss: 6.063621997833252, modularity_loss: -0.5297391414642334, purity_loss: 6.516074180603027, regularization_loss: 0.07728695869445801 # 11:34:13 --- INFO: epoch: 149, batch: 1, loss: 6.033446788787842, modularity_loss: -0.5340426564216614, purity_loss: 6.4899444580078125, regularization_loss: 0.07754483073949814 # 11:34:13 --- INFO: epoch: 150, batch: 1, loss: 6.002956867218018, modularity_loss: -0.538323163986206, purity_loss: 6.463444232940674, regularization_loss: 0.07783565670251846 # 11:34:13 --- INFO: epoch: 151, batch: 1, loss: 5.972036361694336, modularity_loss: -0.5425262451171875, purity_loss: 6.4364118576049805, regularization_loss: 0.07815083116292953 # 11:34:14 --- INFO: epoch: 152, batch: 1, loss: 5.940959453582764, modularity_loss: -0.5465943813323975, purity_loss: 6.4090752601623535, regularization_loss: 0.07847876101732254 # 11:34:14 --- INFO: epoch: 153, batch: 1, loss: 5.9103312492370605, modularity_loss: -0.5504608154296875, purity_loss: 6.381987571716309, regularization_loss: 0.07880452275276184 # 11:34:14 --- INFO: epoch: 154, batch: 1, loss: 5.881166458129883, modularity_loss: -0.5540558099746704, purity_loss: 6.356110572814941, regularization_loss: 0.07911158353090286 # 11:34:15 --- INFO: epoch: 155, batch: 1, loss: 5.85463285446167, modularity_loss: -0.5573135018348694, purity_loss: 6.33256196975708, regularization_loss: 0.0793842300772667 # 11:34:15 --- INFO: epoch: 156, batch: 1, loss: 5.831521987915039, modularity_loss: -0.560212254524231, purity_loss: 6.312124252319336, regularization_loss: 0.07961011677980423 # 11:34:15 --- INFO: epoch: 157, batch: 1, loss: 5.811868667602539, modularity_loss: -0.5627795457839966, purity_loss: 6.29486608505249, regularization_loss: 0.07978202402591705 # 11:34:15 --- INFO: epoch: 158, batch: 1, loss: 5.794981479644775, modularity_loss: -0.565090537071228, purity_loss: 6.280172824859619, regularization_loss: 0.07989932596683502 # 11:34:16 --- INFO: epoch: 159, batch: 1, loss: 5.779794216156006, modularity_loss: -0.5672242641448975, purity_loss: 6.267052173614502, regularization_loss: 0.07996627688407898 # 11:34:16 --- INFO: epoch: 160, batch: 1, loss: 5.7654242515563965, modularity_loss: -0.5692388415336609, purity_loss: 6.254673957824707, regularization_loss: 0.07998917996883392 # 11:34:16 --- INFO: epoch: 161, batch: 1, loss: 5.7513813972473145, modularity_loss: -0.5711544752120972, purity_loss: 6.242560386657715, regularization_loss: 0.07997548580169678 # 11:34:17 --- INFO: epoch: 162, batch: 1, loss: 5.737612247467041, modularity_loss: -0.572961688041687, purity_loss: 6.2306413650512695, regularization_loss: 0.07993237674236298 # 11:34:17 --- INFO: epoch: 163, batch: 1, loss: 5.724398612976074, modularity_loss: -0.5746380090713501, purity_loss: 6.219170093536377, regularization_loss: 0.07986671477556229 # 11:34:17 --- INFO: epoch: 164, batch: 1, loss: 5.712135314941406, modularity_loss: -0.5761581063270569, purity_loss: 6.2085089683532715, regularization_loss: 0.07978463917970657 # 11:34:18 --- INFO: epoch: 165, batch: 1, loss: 5.701193809509277, modularity_loss: -0.5775059461593628, purity_loss: 6.199007987976074, regularization_loss: 0.07969188690185547 # 11:34:18 --- INFO: epoch: 166, batch: 1, loss: 5.691784858703613, modularity_loss: -0.5786791443824768, purity_loss: 6.19087028503418, regularization_loss: 0.07959389686584473 # 11:34:18 --- INFO: epoch: 167, batch: 1, loss: 5.683870792388916, modularity_loss: -0.5796903371810913, purity_loss: 6.184064865112305, regularization_loss: 0.07949628680944443 # 11:34:18 --- INFO: epoch: 168, batch: 1, loss: 5.677199840545654, modularity_loss: -0.5805683732032776, purity_loss: 6.17836332321167, regularization_loss: 0.07940486073493958 # 11:34:19 --- INFO: epoch: 169, batch: 1, loss: 5.671406269073486, modularity_loss: -0.581353485584259, purity_loss: 6.173434734344482, regularization_loss: 0.07932505756616592 # 11:34:19 --- INFO: epoch: 170, batch: 1, loss: 5.666098594665527, modularity_loss: -0.5820875763893127, purity_loss: 6.168924808502197, regularization_loss: 0.07926131784915924 # 11:34:19 --- INFO: epoch: 171, batch: 1, loss: 5.66102933883667, modularity_loss: -0.58280348777771, purity_loss: 6.164616584777832, regularization_loss: 0.07921629399061203 # 11:34:20 --- INFO: epoch: 172, batch: 1, loss: 5.656072616577148, modularity_loss: -0.5835205316543579, purity_loss: 6.160402774810791, regularization_loss: 0.07919053733348846 # 11:34:20 --- INFO: epoch: 173, batch: 1, loss: 5.651222229003906, modularity_loss: -0.584238588809967, purity_loss: 6.156278610229492, regularization_loss: 0.07918201386928558 # 11:34:20 --- INFO: epoch: 174, batch: 1, loss: 5.64654541015625, modularity_loss: -0.5849401950836182, purity_loss: 6.152298450469971, regularization_loss: 0.07918698340654373 # 11:34:20 --- INFO: epoch: 175, batch: 1, loss: 5.642035007476807, modularity_loss: -0.585598349571228, purity_loss: 6.148432731628418, regularization_loss: 0.07920046895742416 # 11:34:21 --- INFO: epoch: 176, batch: 1, loss: 5.637692451477051, modularity_loss: -0.5861896276473999, purity_loss: 6.144664287567139, regularization_loss: 0.07921770215034485 # 11:34:21 --- INFO: epoch: 177, batch: 1, loss: 5.633500576019287, modularity_loss: -0.5866942405700684, purity_loss: 6.140960216522217, regularization_loss: 0.07923442870378494 # 11:34:21 --- INFO: epoch: 178, batch: 1, loss: 5.629417419433594, modularity_loss: -0.5871046781539917, purity_loss: 6.137274265289307, regularization_loss: 0.07924770563840866 # 11:34:22 --- INFO: epoch: 179, batch: 1, loss: 5.625455379486084, modularity_loss: -0.5874236822128296, purity_loss: 6.133623123168945, regularization_loss: 0.07925577461719513 # 11:34:22 --- INFO: epoch: 180, batch: 1, loss: 5.621650695800781, modularity_loss: -0.5876610279083252, purity_loss: 6.130053997039795, regularization_loss: 0.07925787568092346 # 11:34:22 --- INFO: epoch: 181, batch: 1, loss: 5.618027687072754, modularity_loss: -0.5878323316574097, purity_loss: 6.12660551071167, regularization_loss: 0.07925451546907425 # 11:34:23 --- INFO: epoch: 182, batch: 1, loss: 5.614570617675781, modularity_loss: -0.5879559516906738, purity_loss: 6.123280048370361, regularization_loss: 0.07924628257751465 # 11:34:23 --- INFO: epoch: 183, batch: 1, loss: 5.611252784729004, modularity_loss: -0.5880507826805115, purity_loss: 6.120069980621338, regularization_loss: 0.07923364639282227 # 11:34:23 --- INFO: epoch: 184, batch: 1, loss: 5.608041286468506, modularity_loss: -0.588132381439209, purity_loss: 6.1169562339782715, regularization_loss: 0.0792175903916359 # 11:34:24 --- INFO: epoch: 185, batch: 1, loss: 5.60488224029541, modularity_loss: -0.5882136225700378, purity_loss: 6.11389684677124, regularization_loss: 0.07919879257678986 # 11:34:24 --- INFO: epoch: 186, batch: 1, loss: 5.601746559143066, modularity_loss: -0.588301420211792, purity_loss: 6.110869884490967, regularization_loss: 0.07917796820402145 # 11:34:24 --- INFO: epoch: 187, batch: 1, loss: 5.598642349243164, modularity_loss: -0.5883959531784058, purity_loss: 6.107882976531982, regularization_loss: 0.07915551215410233 # 11:34:24 --- INFO: epoch: 188, batch: 1, loss: 5.5955986976623535, modularity_loss: -0.5884933471679688, purity_loss: 6.104959964752197, regularization_loss: 0.07913202047348022 # 11:34:25 --- INFO: epoch: 189, batch: 1, loss: 5.592626571655273, modularity_loss: -0.5885871052742004, purity_loss: 6.102105617523193, regularization_loss: 0.079107865691185 # 11:34:25 --- INFO: epoch: 190, batch: 1, loss: 5.589748382568359, modularity_loss: -0.5886681079864502, purity_loss: 6.0993332862854, regularization_loss: 0.07908322662115097 # 11:34:25 --- INFO: epoch: 191, batch: 1, loss: 5.5869646072387695, modularity_loss: -0.5887271165847778, purity_loss: 6.096633434295654, regularization_loss: 0.0790582224726677 # 11:34:26 --- INFO: epoch: 192, batch: 1, loss: 5.584257125854492, modularity_loss: -0.5887588262557983, purity_loss: 6.093983173370361, regularization_loss: 0.0790330022573471 # 11:34:26 --- INFO: epoch: 193, batch: 1, loss: 5.581605911254883, modularity_loss: -0.5887577533721924, purity_loss: 6.091355800628662, regularization_loss: 0.07900787144899368 # 11:34:26 --- INFO: epoch: 194, batch: 1, loss: 5.5789899826049805, modularity_loss: -0.5887237787246704, purity_loss: 6.088730812072754, regularization_loss: 0.07898299396038055 # 11:34:26 --- INFO: epoch: 195, batch: 1, loss: 5.576402187347412, modularity_loss: -0.5886590480804443, purity_loss: 6.086102485656738, regularization_loss: 0.07895872741937637 # 11:34:27 --- INFO: epoch: 196, batch: 1, loss: 5.573841571807861, modularity_loss: -0.5885686874389648, purity_loss: 6.083475112915039, regularization_loss: 0.07893519103527069 # 11:34:27 --- INFO: epoch: 197, batch: 1, loss: 5.571301460266113, modularity_loss: -0.5884584188461304, purity_loss: 6.08084774017334, regularization_loss: 0.07891237735748291 # 11:34:27 --- INFO: epoch: 198, batch: 1, loss: 5.568774223327637, modularity_loss: -0.588334321975708, purity_loss: 6.078218460083008, regularization_loss: 0.07889007031917572 # 11:34:28 --- INFO: epoch: 199, batch: 1, loss: 5.566244602203369, modularity_loss: -0.5882014036178589, purity_loss: 6.075578212738037, regularization_loss: 0.07886788249015808 # 11:34:28 --- INFO: epoch: 200, batch: 1, loss: 5.56368350982666, modularity_loss: -0.5880600214004517, purity_loss: 6.0728983879089355, regularization_loss: 0.0788450688123703 # 11:34:28 --- INFO: epoch: 201, batch: 1, loss: 5.561061382293701, modularity_loss: -0.587909460067749, purity_loss: 6.070149898529053, regularization_loss: 0.07882075756788254 # 11:34:29 --- INFO: epoch: 202, batch: 1, loss: 5.558346748352051, modularity_loss: -0.5877419710159302, purity_loss: 6.067295074462891, regularization_loss: 0.07879365235567093 # 11:34:29 --- INFO: epoch: 203, batch: 1, loss: 5.555512428283691, modularity_loss: -0.587546706199646, purity_loss: 6.064297199249268, regularization_loss: 0.07876210659742355 # 11:34:29 --- INFO: epoch: 204, batch: 1, loss: 5.5525221824646, modularity_loss: -0.5873087644577026, purity_loss: 6.0611066818237305, regularization_loss: 0.07872425019741058 # 11:34:29 --- INFO: epoch: 205, batch: 1, loss: 5.549304485321045, modularity_loss: -0.5870083570480347, purity_loss: 6.057635307312012, regularization_loss: 0.07867764681577682 # 11:34:30 --- INFO: epoch: 206, batch: 1, loss: 5.5457539558410645, modularity_loss: -0.5866184234619141, purity_loss: 6.05375337600708, regularization_loss: 0.07861891388893127 # 11:34:30 --- INFO: epoch: 207, batch: 1, loss: 5.541679382324219, modularity_loss: -0.5861009359359741, purity_loss: 6.04923677444458, regularization_loss: 0.07854343950748444 # 11:34:30 --- INFO: epoch: 208, batch: 1, loss: 5.536744594573975, modularity_loss: -0.5853960514068604, purity_loss: 6.043696880340576, regularization_loss: 0.07844388484954834 # 11:34:31 --- INFO: epoch: 209, batch: 1, loss: 5.530306339263916, modularity_loss: -0.5844054222106934, purity_loss: 6.036403656005859, regularization_loss: 0.07830830663442612 # 11:34:31 --- INFO: epoch: 210, batch: 1, loss: 5.52103328704834, modularity_loss: -0.5829585790634155, purity_loss: 6.025876998901367, regularization_loss: 0.07811501622200012 # 11:34:31 --- INFO: epoch: 211, batch: 1, loss: 5.505935192108154, modularity_loss: -0.5807530283927917, purity_loss: 6.008862495422363, regularization_loss: 0.07782554626464844 # 11:34:32 --- INFO: epoch: 212, batch: 1, loss: 5.4772233963012695, modularity_loss: -0.5772725343704224, purity_loss: 5.977132797241211, regularization_loss: 0.07736289501190186 # 11:34:32 --- INFO: epoch: 213, batch: 1, loss: 5.413817405700684, modularity_loss: -0.5718346238136292, purity_loss: 5.909071445465088, regularization_loss: 0.07658044248819351 # 11:34:32 --- INFO: epoch: 214, batch: 1, loss: 5.278060436248779, modularity_loss: -0.5637491941452026, purity_loss: 5.7665181159973145, regularization_loss: 0.07529158145189285 # 11:34:33 --- INFO: epoch: 215, batch: 1, loss: 5.112178802490234, modularity_loss: -0.5511707067489624, purity_loss: 5.589661121368408, regularization_loss: 0.0736885741353035 # 11:34:33 --- INFO: epoch: 216, batch: 1, loss: 5.020716190338135, modularity_loss: -0.5436804890632629, purity_loss: 5.491448879241943, regularization_loss: 0.07294774800539017 # 11:34:33 --- INFO: epoch: 217, batch: 1, loss: 4.824301242828369, modularity_loss: -0.5564278364181519, purity_loss: 5.307650089263916, regularization_loss: 0.07307903468608856 # 11:34:34 --- INFO: epoch: 218, batch: 1, loss: 4.668924808502197, modularity_loss: -0.5727019906044006, purity_loss: 5.168076992034912, regularization_loss: 0.07354971766471863 # 11:34:34 --- INFO: epoch: 219, batch: 1, loss: 4.594281196594238, modularity_loss: -0.5816538333892822, purity_loss: 5.102120876312256, regularization_loss: 0.07381407916545868 # 11:34:34 --- INFO: epoch: 220, batch: 1, loss: 4.531461238861084, modularity_loss: -0.5858439207077026, purity_loss: 5.0435357093811035, regularization_loss: 0.07376935333013535 # 11:34:35 --- INFO: epoch: 221, batch: 1, loss: 4.473836898803711, modularity_loss: -0.5879661440849304, purity_loss: 4.988247871398926, regularization_loss: 0.07355508208274841 # 11:34:35 --- INFO: epoch: 222, batch: 1, loss: 4.4354376792907715, modularity_loss: -0.5892443060874939, purity_loss: 4.951365947723389, regularization_loss: 0.07331585139036179 # 11:34:35 --- INFO: epoch: 223, batch: 1, loss: 4.4204607009887695, modularity_loss: -0.5902235507965088, purity_loss: 4.9375386238098145, regularization_loss: 0.07314546406269073 # 11:34:35 --- INFO: epoch: 224, batch: 1, loss: 4.420561790466309, modularity_loss: -0.5913387537002563, purity_loss: 4.938831329345703, regularization_loss: 0.07306916266679764 # 11:34:36 --- INFO: epoch: 225, batch: 1, loss: 4.423811435699463, modularity_loss: -0.5928112268447876, purity_loss: 4.943551063537598, regularization_loss: 0.07307147234678268 # 11:34:36 --- INFO: epoch: 226, batch: 1, loss: 4.422661304473877, modularity_loss: -0.5944815874099731, purity_loss: 4.944013595581055, regularization_loss: 0.07312919944524765 # 11:34:36 --- INFO: epoch: 227, batch: 1, loss: 4.4168314933776855, modularity_loss: -0.596046507358551, purity_loss: 4.939652442932129, regularization_loss: 0.0732254907488823 # 11:34:37 --- INFO: epoch: 228, batch: 1, loss: 4.410677433013916, modularity_loss: -0.5972778797149658, purity_loss: 4.934606075286865, regularization_loss: 0.07334909588098526 # 11:34:37 --- INFO: epoch: 229, batch: 1, loss: 4.408371448516846, modularity_loss: -0.5980930328369141, purity_loss: 4.932977676391602, regularization_loss: 0.07348683476448059 # 11:34:37 --- INFO: epoch: 230, batch: 1, loss: 4.409975528717041, modularity_loss: -0.5985338687896729, purity_loss: 4.934889793395996, regularization_loss: 0.07361973822116852 # 11:34:38 --- INFO: epoch: 231, batch: 1, loss: 4.411879539489746, modularity_loss: -0.5987254977226257, purity_loss: 4.936878204345703, regularization_loss: 0.07372687011957169 # 11:34:38 --- INFO: epoch: 232, batch: 1, loss: 4.411393165588379, modularity_loss: -0.598797082901001, purity_loss: 4.936393737792969, regularization_loss: 0.0737965852022171 # 11:34:38 --- INFO: epoch: 233, batch: 1, loss: 4.409461975097656, modularity_loss: -0.598831295967102, purity_loss: 4.93446159362793, regularization_loss: 0.07383144646883011 # 11:34:39 --- INFO: epoch: 234, batch: 1, loss: 4.408030986785889, modularity_loss: -0.5988819599151611, purity_loss: 4.933070659637451, regularization_loss: 0.07384243607521057 # 11:34:39 --- INFO: epoch: 235, batch: 1, loss: 4.40681266784668, modularity_loss: -0.5990049242973328, purity_loss: 4.931978225708008, regularization_loss: 0.07383940368890762 # 11:34:39 --- INFO: epoch: 236, batch: 1, loss: 4.404171466827393, modularity_loss: -0.5992487668991089, purity_loss: 4.929592609405518, regularization_loss: 0.07382772862911224 # 11:34:40 --- INFO: epoch: 237, batch: 1, loss: 4.39953088760376, modularity_loss: -0.5996174812316895, purity_loss: 4.9253387451171875, regularization_loss: 0.07380976527929306 # 11:34:40 --- INFO: epoch: 238, batch: 1, loss: 4.394030570983887, modularity_loss: -0.6000624895095825, purity_loss: 4.92030668258667, regularization_loss: 0.0737866461277008 # 11:34:40 --- INFO: epoch: 239, batch: 1, loss: 4.389148712158203, modularity_loss: -0.6005113124847412, purity_loss: 4.915902614593506, regularization_loss: 0.07375739514827728 # 11:34:41 --- INFO: epoch: 240, batch: 1, loss: 4.385226249694824, modularity_loss: -0.6008815765380859, purity_loss: 4.912387371063232, regularization_loss: 0.07372060418128967 # 11:34:41 --- INFO: epoch: 241, batch: 1, loss: 4.381584167480469, modularity_loss: -0.60111004114151, purity_loss: 4.9090189933776855, regularization_loss: 0.07367543876171112 # 11:34:41 --- INFO: epoch: 242, batch: 1, loss: 4.377500057220459, modularity_loss: -0.601157546043396, purity_loss: 4.905034065246582, regularization_loss: 0.07362337410449982 # 11:34:42 --- INFO: epoch: 243, batch: 1, loss: 4.3730010986328125, modularity_loss: -0.6010140180587769, purity_loss: 4.900446891784668, regularization_loss: 0.07356845587491989 # 11:34:42 --- INFO: epoch: 244, batch: 1, loss: 4.368607521057129, modularity_loss: -0.6007052659988403, purity_loss: 4.895796298980713, regularization_loss: 0.07351662963628769 # 11:34:42 --- INFO: epoch: 245, batch: 1, loss: 4.364609718322754, modularity_loss: -0.6002802848815918, purity_loss: 4.891416549682617, regularization_loss: 0.07347341626882553 # 11:34:42 --- INFO: epoch: 246, batch: 1, loss: 4.360860824584961, modularity_loss: -0.5997978448867798, purity_loss: 4.887216567993164, regularization_loss: 0.07344198226928711 # 11:34:43 --- INFO: epoch: 247, batch: 1, loss: 4.356934070587158, modularity_loss: -0.5993043184280396, purity_loss: 4.882814884185791, regularization_loss: 0.07342366874217987 # 11:34:43 --- INFO: epoch: 248, batch: 1, loss: 4.35261869430542, modularity_loss: -0.5988279581069946, purity_loss: 4.87802791595459, regularization_loss: 0.07341862469911575 # 11:34:43 --- INFO: epoch: 249, batch: 1, loss: 4.348060131072998, modularity_loss: -0.5983699560165405, purity_loss: 4.87300443649292, regularization_loss: 0.07342550158500671 # 11:34:44 --- INFO: epoch: 250, batch: 1, loss: 4.343605041503906, modularity_loss: -0.5979124307632446, purity_loss: 4.868075847625732, regularization_loss: 0.07344188541173935 # 11:34:44 --- INFO: epoch: 251, batch: 1, loss: 4.339545726776123, modularity_loss: -0.5974299907684326, purity_loss: 4.863511562347412, regularization_loss: 0.07346434146165848 # 11:34:44 --- INFO: epoch: 252, batch: 1, loss: 4.33583402633667, modularity_loss: -0.5968954563140869, purity_loss: 4.859240531921387, regularization_loss: 0.07348891347646713 # 11:34:45 --- INFO: epoch: 253, batch: 1, loss: 4.332301139831543, modularity_loss: -0.5962988138198853, purity_loss: 4.855088233947754, regularization_loss: 0.07351180166006088 # 11:34:45 --- INFO: epoch: 254, batch: 1, loss: 4.328784942626953, modularity_loss: -0.5956467390060425, purity_loss: 4.8509016036987305, regularization_loss: 0.0735301673412323 # 11:34:45 --- INFO: epoch: 255, batch: 1, loss: 4.325329780578613, modularity_loss: -0.5949624180793762, purity_loss: 4.846749782562256, regularization_loss: 0.07354238629341125 # 11:34:45 --- INFO: epoch: 256, batch: 1, loss: 4.322075843811035, modularity_loss: -0.5942855477333069, purity_loss: 4.842813491821289, regularization_loss: 0.07354779541492462 # 11:34:46 --- INFO: epoch: 257, batch: 1, loss: 4.319091320037842, modularity_loss: -0.5936647653579712, purity_loss: 4.839209079742432, regularization_loss: 0.0735468715429306 # 11:34:46 --- INFO: epoch: 258, batch: 1, loss: 4.316356658935547, modularity_loss: -0.5931333303451538, purity_loss: 4.835948944091797, regularization_loss: 0.07354124635457993 # 11:34:46 --- INFO: epoch: 259, batch: 1, loss: 4.313860893249512, modularity_loss: -0.5927048921585083, purity_loss: 4.833033084869385, regularization_loss: 0.07353287190198898 # 11:34:47 --- INFO: epoch: 260, batch: 1, loss: 4.311649799346924, modularity_loss: -0.5923765897750854, purity_loss: 4.830502510070801, regularization_loss: 0.07352384179830551 # 11:34:47 --- INFO: epoch: 261, batch: 1, loss: 4.309781074523926, modularity_loss: -0.5921224355697632, purity_loss: 4.828387260437012, regularization_loss: 0.07351619750261307 # 11:34:47 --- INFO: epoch: 262, batch: 1, loss: 4.30827522277832, modularity_loss: -0.5919064283370972, purity_loss: 4.8266706466674805, regularization_loss: 0.07351125776767731 # 11:34:48 --- INFO: epoch: 263, batch: 1, loss: 4.307024955749512, modularity_loss: -0.5916910171508789, purity_loss: 4.825206279754639, regularization_loss: 0.07350989431142807 # 11:34:48 --- INFO: epoch: 264, batch: 1, loss: 4.305865287780762, modularity_loss: -0.5914521217346191, purity_loss: 4.82380485534668, regularization_loss: 0.07351233810186386 # 11:34:48 --- INFO: epoch: 265, batch: 1, loss: 4.304628849029541, modularity_loss: -0.5911808013916016, purity_loss: 4.822291374206543, regularization_loss: 0.07351834326982498 # 11:34:49 --- INFO: epoch: 266, batch: 1, loss: 4.303272724151611, modularity_loss: -0.5908845663070679, purity_loss: 4.820630073547363, regularization_loss: 0.07352729886770248 # 11:34:49 --- INFO: epoch: 267, batch: 1, loss: 4.301836967468262, modularity_loss: -0.5905880331993103, purity_loss: 4.818886756896973, regularization_loss: 0.07353837788105011 # 11:34:49 --- INFO: epoch: 268, batch: 1, loss: 4.3003973960876465, modularity_loss: -0.5903263688087463, purity_loss: 4.817173480987549, regularization_loss: 0.07355019450187683 # 11:34:49 --- INFO: epoch: 269, batch: 1, loss: 4.298980712890625, modularity_loss: -0.5901319980621338, purity_loss: 4.8155517578125, regularization_loss: 0.07356119155883789 # 11:34:50 --- INFO: epoch: 270, batch: 1, loss: 4.297562122344971, modularity_loss: -0.5900236368179321, purity_loss: 4.814016342163086, regularization_loss: 0.07356960326433182 # 11:34:50 --- INFO: epoch: 271, batch: 1, loss: 4.2961015701293945, modularity_loss: -0.5900083780288696, purity_loss: 4.812536239624023, regularization_loss: 0.07357395440340042 # 11:34:50 --- INFO: epoch: 272, batch: 1, loss: 4.294596195220947, modularity_loss: -0.5900752544403076, purity_loss: 4.811098098754883, regularization_loss: 0.07357331365346909 # 11:34:51 --- INFO: epoch: 273, batch: 1, loss: 4.293078422546387, modularity_loss: -0.5902026891708374, purity_loss: 4.809713840484619, regularization_loss: 0.07356734573841095 # 11:34:51 --- INFO: epoch: 274, batch: 1, loss: 4.291578769683838, modularity_loss: -0.5903612375259399, purity_loss: 4.808383464813232, regularization_loss: 0.07355649024248123 # 11:34:51 --- INFO: epoch: 275, batch: 1, loss: 4.290128231048584, modularity_loss: -0.5905221700668335, purity_loss: 4.8071088790893555, regularization_loss: 0.07354172319173813 # 11:34:52 --- INFO: epoch: 276, batch: 1, loss: 4.2887420654296875, modularity_loss: -0.5906651616096497, purity_loss: 4.805882930755615, regularization_loss: 0.07352451980113983 # 11:34:52 --- INFO: epoch: 277, batch: 1, loss: 4.287437438964844, modularity_loss: -0.5907781720161438, purity_loss: 4.804708957672119, regularization_loss: 0.07350655645132065 # 11:34:52 --- INFO: epoch: 278, batch: 1, loss: 4.286211967468262, modularity_loss: -0.5908651351928711, purity_loss: 4.803586959838867, regularization_loss: 0.07348987460136414 # 11:34:52 --- INFO: epoch: 279, batch: 1, loss: 4.28505802154541, modularity_loss: -0.5909320116043091, purity_loss: 4.80251407623291, regularization_loss: 0.07347596436738968 # 11:34:53 --- INFO: epoch: 280, batch: 1, loss: 4.283960342407227, modularity_loss: -0.5909901857376099, purity_loss: 4.80148458480835, regularization_loss: 0.07346581667661667 # 11:34:53 --- INFO: epoch: 281, batch: 1, loss: 4.282896518707275, modularity_loss: -0.5910468101501465, purity_loss: 4.800483703613281, regularization_loss: 0.0734596699476242 # 11:34:53 --- INFO: epoch: 282, batch: 1, loss: 4.281870365142822, modularity_loss: -0.5911058783531189, purity_loss: 4.799519062042236, regularization_loss: 0.07345734536647797 # 11:34:54 --- INFO: epoch: 283, batch: 1, loss: 4.280886650085449, modularity_loss: -0.5911659002304077, purity_loss: 4.7985944747924805, regularization_loss: 0.07345793396234512 # 11:34:54 --- INFO: epoch: 284, batch: 1, loss: 4.279959678649902, modularity_loss: -0.591220498085022, purity_loss: 4.797719955444336, regularization_loss: 0.07346030324697495 # 11:34:54 --- INFO: epoch: 285, batch: 1, loss: 4.279078006744385, modularity_loss: -0.5912607908248901, purity_loss: 4.796875476837158, regularization_loss: 0.07346325367689133 # 11:34:55 --- INFO: epoch: 286, batch: 1, loss: 4.278225421905518, modularity_loss: -0.5912783741950989, purity_loss: 4.7960381507873535, regularization_loss: 0.07346563786268234 # 11:34:55 --- INFO: epoch: 287, batch: 1, loss: 4.277387619018555, modularity_loss: -0.5912687182426453, purity_loss: 4.795189380645752, regularization_loss: 0.07346677035093307 # 11:34:55 --- INFO: epoch: 288, batch: 1, loss: 4.276552677154541, modularity_loss: -0.5912315845489502, purity_loss: 4.794317722320557, regularization_loss: 0.073466457426548 # 11:34:56 --- INFO: epoch: 289, batch: 1, loss: 4.2757248878479, modularity_loss: -0.5911734104156494, purity_loss: 4.79343318939209, regularization_loss: 0.0734650120139122 # 11:34:56 --- INFO: epoch: 290, batch: 1, loss: 4.274920463562012, modularity_loss: -0.5911019444465637, purity_loss: 4.7925591468811035, regularization_loss: 0.07346304506063461 # 11:34:56 --- INFO: epoch: 291, batch: 1, loss: 4.274134635925293, modularity_loss: -0.5910259485244751, purity_loss: 4.791699409484863, regularization_loss: 0.07346127927303314 # 11:34:57 --- INFO: epoch: 292, batch: 1, loss: 4.2733635902404785, modularity_loss: -0.5909523963928223, purity_loss: 4.790855407714844, regularization_loss: 0.07346054166555405 # 11:34:57 --- INFO: epoch: 293, batch: 1, loss: 4.272598743438721, modularity_loss: -0.5908820629119873, purity_loss: 4.790019512176514, regularization_loss: 0.07346116006374359 # 11:34:57 --- INFO: epoch: 294, batch: 1, loss: 4.271836757659912, modularity_loss: -0.5908104181289673, purity_loss: 4.789184093475342, regularization_loss: 0.07346310466527939 # 11:34:57 --- INFO: epoch: 295, batch: 1, loss: 4.2710700035095215, modularity_loss: -0.5907310247421265, purity_loss: 4.788334846496582, regularization_loss: 0.07346601039171219 # 11:34:58 --- INFO: epoch: 296, batch: 1, loss: 4.270299434661865, modularity_loss: -0.5906384587287903, purity_loss: 4.787468433380127, regularization_loss: 0.07346942275762558 # 11:34:58 --- INFO: epoch: 297, batch: 1, loss: 4.269519805908203, modularity_loss: -0.5905280113220215, purity_loss: 4.7865753173828125, regularization_loss: 0.07347261905670166 # 11:34:58 --- INFO: epoch: 298, batch: 1, loss: 4.268729209899902, modularity_loss: -0.5903987288475037, purity_loss: 4.785653114318848, regularization_loss: 0.07347502559423447 # 11:34:59 --- INFO: epoch: 299, batch: 1, loss: 4.267923831939697, modularity_loss: -0.590255618095398, purity_loss: 4.784703254699707, regularization_loss: 0.07347619533538818 # 11:34:59 --- INFO: epoch: 300, batch: 1, loss: 4.2671027183532715, modularity_loss: -0.5901046991348267, purity_loss: 4.783731460571289, regularization_loss: 0.0734758973121643 # 11:34:59 --- INFO: epoch: 301, batch: 1, loss: 4.266260147094727, modularity_loss: -0.589952826499939, purity_loss: 4.78273868560791, regularization_loss: 0.07347415387630463 # 11:35:00 --- INFO: epoch: 302, batch: 1, loss: 4.265389442443848, modularity_loss: -0.5898054838180542, purity_loss: 4.781723976135254, regularization_loss: 0.07347114384174347 # 11:35:00 --- INFO: epoch: 303, batch: 1, loss: 4.264482021331787, modularity_loss: -0.5896624326705933, purity_loss: 4.780677318572998, regularization_loss: 0.07346729934215546 # 11:35:00 --- INFO: epoch: 304, batch: 1, loss: 4.263533115386963, modularity_loss: -0.589518666267395, purity_loss: 4.77958869934082, regularization_loss: 0.07346303761005402 # 11:35:01 --- INFO: epoch: 305, batch: 1, loss: 4.262538909912109, modularity_loss: -0.5893668532371521, purity_loss: 4.778447151184082, regularization_loss: 0.07345866411924362 # 11:35:01 --- INFO: epoch: 306, batch: 1, loss: 4.261477470397949, modularity_loss: -0.589195966720581, purity_loss: 4.777218818664551, regularization_loss: 0.07345455139875412 # 11:35:02 --- INFO: epoch: 307, batch: 1, loss: 4.260337829589844, modularity_loss: -0.5889950394630432, purity_loss: 4.775881767272949, regularization_loss: 0.07345087826251984 # 11:35:02 --- INFO: epoch: 308, batch: 1, loss: 4.259085655212402, modularity_loss: -0.5887542963027954, purity_loss: 4.774392127990723, regularization_loss: 0.0734478235244751 # 11:35:02 --- INFO: epoch: 309, batch: 1, loss: 4.257706165313721, modularity_loss: -0.5884677767753601, purity_loss: 4.772728443145752, regularization_loss: 0.07344553619623184 # 11:35:02 --- INFO: epoch: 310, batch: 1, loss: 4.256180286407471, modularity_loss: -0.5881308913230896, purity_loss: 4.770867347717285, regularization_loss: 0.0734439268708229 # 11:35:03 --- INFO: epoch: 311, batch: 1, loss: 4.254464149475098, modularity_loss: -0.5877430438995361, purity_loss: 4.768764019012451, regularization_loss: 0.07344336062669754 # 11:35:03 --- INFO: epoch: 312, batch: 1, loss: 4.252506256103516, modularity_loss: -0.5872955918312073, purity_loss: 4.766357898712158, regularization_loss: 0.07344380021095276 # 11:35:04 --- INFO: epoch: 313, batch: 1, loss: 4.250242710113525, modularity_loss: -0.5867732167243958, purity_loss: 4.763570785522461, regularization_loss: 0.07344522327184677 # 11:35:04 --- INFO: epoch: 314, batch: 1, loss: 4.247618675231934, modularity_loss: -0.5861533284187317, purity_loss: 4.760324001312256, regularization_loss: 0.07344774156808853 # 11:35:04 --- INFO: epoch: 315, batch: 1, loss: 4.2445502281188965, modularity_loss: -0.5854088068008423, purity_loss: 4.75650691986084, regularization_loss: 0.07345198094844818 # 11:35:04 --- INFO: epoch: 316, batch: 1, loss: 4.240986347198486, modularity_loss: -0.5845093727111816, purity_loss: 4.752037048339844, regularization_loss: 0.07345881313085556 # 11:35:05 --- INFO: epoch: 317, batch: 1, loss: 4.236891269683838, modularity_loss: -0.5834317207336426, purity_loss: 4.746853351593018, regularization_loss: 0.07346955686807632 # 11:35:05 --- INFO: epoch: 318, batch: 1, loss: 4.232332706451416, modularity_loss: -0.5821704864501953, purity_loss: 4.7410173416137695, regularization_loss: 0.07348573207855225 # 11:35:05 --- INFO: epoch: 319, batch: 1, loss: 4.227492332458496, modularity_loss: -0.5807698965072632, purity_loss: 4.734753131866455, regularization_loss: 0.07350895553827286 # 11:35:06 --- INFO: epoch: 320, batch: 1, loss: 4.222650051116943, modularity_loss: -0.5793299674987793, purity_loss: 4.728439807891846, regularization_loss: 0.07354001700878143 # 11:35:06 --- INFO: epoch: 321, batch: 1, loss: 4.218080997467041, modularity_loss: -0.5780047178268433, purity_loss: 4.722506999969482, regularization_loss: 0.07357867062091827 # 11:35:06 --- INFO: epoch: 322, batch: 1, loss: 4.213959217071533, modularity_loss: -0.5769439935684204, purity_loss: 4.71727991104126, regularization_loss: 0.0736234113574028 # 11:35:07 --- INFO: epoch: 323, batch: 1, loss: 4.210313320159912, modularity_loss: -0.5762346982955933, purity_loss: 4.712876796722412, regularization_loss: 0.07367132604122162 # 11:35:07 --- INFO: epoch: 324, batch: 1, loss: 4.207118511199951, modularity_loss: -0.5758606791496277, purity_loss: 4.709259033203125, regularization_loss: 0.07372003048658371 # 11:35:07 --- INFO: epoch: 325, batch: 1, loss: 4.204360485076904, modularity_loss: -0.575730562210083, purity_loss: 4.70632266998291, regularization_loss: 0.07376838475465775 # 11:35:08 --- INFO: epoch: 326, batch: 1, loss: 4.201966762542725, modularity_loss: -0.5757330656051636, purity_loss: 4.703883647918701, regularization_loss: 0.07381632924079895 # 11:35:08 --- INFO: epoch: 327, batch: 1, loss: 4.199801445007324, modularity_loss: -0.5757776498794556, purity_loss: 4.701714515686035, regularization_loss: 0.07386460900306702 # 11:35:08 --- INFO: epoch: 328, batch: 1, loss: 4.197755813598633, modularity_loss: -0.5758078098297119, purity_loss: 4.699650287628174, regularization_loss: 0.07391347736120224 # 11:35:09 --- INFO: epoch: 329, batch: 1, loss: 4.195771217346191, modularity_loss: -0.5758171081542969, purity_loss: 4.697626113891602, regularization_loss: 0.07396231591701508 # 11:35:09 --- INFO: epoch: 330, batch: 1, loss: 4.193813323974609, modularity_loss: -0.5758206248283386, purity_loss: 4.695624351501465, regularization_loss: 0.07400976866483688 # 11:35:09 --- INFO: epoch: 331, batch: 1, loss: 4.191867351531982, modularity_loss: -0.5758447647094727, purity_loss: 4.693657875061035, regularization_loss: 0.07405406981706619 # 11:35:10 --- INFO: epoch: 332, batch: 1, loss: 4.189898490905762, modularity_loss: -0.5759114027023315, purity_loss: 4.691716194152832, regularization_loss: 0.07409362494945526 # 11:35:10 --- INFO: epoch: 333, batch: 1, loss: 4.187904357910156, modularity_loss: -0.5760267972946167, purity_loss: 4.689803600311279, regularization_loss: 0.07412758469581604 # 11:35:10 --- INFO: epoch: 334, batch: 1, loss: 4.185907363891602, modularity_loss: -0.5761787295341492, purity_loss: 4.687930107116699, regularization_loss: 0.07415594160556793 # 11:35:11 --- INFO: epoch: 335, batch: 1, loss: 4.183969974517822, modularity_loss: -0.5763427019119263, purity_loss: 4.68613338470459, regularization_loss: 0.07417944818735123 # 11:35:11 --- INFO: epoch: 336, batch: 1, loss: 4.182136535644531, modularity_loss: -0.5764858722686768, purity_loss: 4.684423446655273, regularization_loss: 0.07419916987419128 # 11:35:11 --- INFO: epoch: 337, batch: 1, loss: 4.180404186248779, modularity_loss: -0.576573371887207, purity_loss: 4.682761192321777, regularization_loss: 0.07421652227640152 # 11:35:12 --- INFO: epoch: 338, batch: 1, loss: 4.178768157958984, modularity_loss: -0.5765821933746338, purity_loss: 4.681118011474609, regularization_loss: 0.07423239946365356 # 11:35:12 --- INFO: epoch: 339, batch: 1, loss: 4.177211284637451, modularity_loss: -0.576517641544342, purity_loss: 4.679482460021973, regularization_loss: 0.07424658536911011 # 11:35:12 --- INFO: epoch: 340, batch: 1, loss: 4.175746440887451, modularity_loss: -0.5763891339302063, purity_loss: 4.677876949310303, regularization_loss: 0.0742587149143219 # 11:35:12 --- INFO: epoch: 341, batch: 1, loss: 4.174374580383301, modularity_loss: -0.5762315392494202, purity_loss: 4.6763386726379395, regularization_loss: 0.07426769286394119 # 11:35:13 --- INFO: epoch: 342, batch: 1, loss: 4.17310094833374, modularity_loss: -0.5760815739631653, purity_loss: 4.674910068511963, regularization_loss: 0.07427257299423218 # 11:35:13 --- INFO: epoch: 343, batch: 1, loss: 4.171891689300537, modularity_loss: -0.5759718418121338, purity_loss: 4.673590660095215, regularization_loss: 0.07427293807268143 # 11:35:13 --- INFO: epoch: 344, batch: 1, loss: 4.170742511749268, modularity_loss: -0.5759111642837524, purity_loss: 4.672384262084961, regularization_loss: 0.07426943629980087 # 11:35:14 --- INFO: epoch: 345, batch: 1, loss: 4.169649600982666, modularity_loss: -0.5758869647979736, purity_loss: 4.6712727546691895, regularization_loss: 0.07426375895738602 # 11:35:14 --- INFO: epoch: 346, batch: 1, loss: 4.168609142303467, modularity_loss: -0.5758694410324097, purity_loss: 4.670220375061035, regularization_loss: 0.0742582380771637 # 11:35:14 --- INFO: epoch: 347, batch: 1, loss: 4.167614936828613, modularity_loss: -0.5758272409439087, purity_loss: 4.669187068939209, regularization_loss: 0.0742550790309906 # 11:35:15 --- INFO: epoch: 348, batch: 1, loss: 4.166640281677246, modularity_loss: -0.5757341980934143, purity_loss: 4.668118476867676, regularization_loss: 0.07425595074892044 # 11:35:15 --- INFO: epoch: 349, batch: 1, loss: 4.165668964385986, modularity_loss: -0.5755927562713623, purity_loss: 4.6670002937316895, regularization_loss: 0.07426134496927261 # 11:35:15 --- INFO: epoch: 350, batch: 1, loss: 4.164701461791992, modularity_loss: -0.5754252672195435, purity_loss: 4.665855884552002, regularization_loss: 0.07427066564559937 # 11:35:16 --- INFO: epoch: 351, batch: 1, loss: 4.163743019104004, modularity_loss: -0.5752644538879395, purity_loss: 4.664724826812744, regularization_loss: 0.07428259402513504 # 11:35:16 --- INFO: epoch: 352, batch: 1, loss: 4.162790775299072, modularity_loss: -0.5751410722732544, purity_loss: 4.663636207580566, regularization_loss: 0.07429562509059906 # 11:35:16 --- INFO: epoch: 353, batch: 1, loss: 4.161850929260254, modularity_loss: -0.5750676393508911, purity_loss: 4.662610054016113, regularization_loss: 0.07430870085954666 # 11:35:17 --- INFO: epoch: 354, batch: 1, loss: 4.160918712615967, modularity_loss: -0.5750381946563721, purity_loss: 4.661635398864746, regularization_loss: 0.074321448802948 # 11:35:17 --- INFO: epoch: 355, batch: 1, loss: 4.160010814666748, modularity_loss: -0.5750309228897095, purity_loss: 4.660707473754883, regularization_loss: 0.07433409243822098 # 11:35:17 --- INFO: epoch: 356, batch: 1, loss: 4.159125328063965, modularity_loss: -0.5750200748443604, purity_loss: 4.6597981452941895, regularization_loss: 0.07434719800949097 # 11:35:18 --- INFO: epoch: 357, batch: 1, loss: 4.158264636993408, modularity_loss: -0.5749863982200623, purity_loss: 4.6588897705078125, regularization_loss: 0.07436109334230423 # 11:35:18 --- INFO: epoch: 358, batch: 1, loss: 4.157419204711914, modularity_loss: -0.5749261379241943, purity_loss: 4.6579694747924805, regularization_loss: 0.07437564432621002 # 11:35:18 --- INFO: epoch: 359, batch: 1, loss: 4.1566033363342285, modularity_loss: -0.5748509168624878, purity_loss: 4.657063961029053, regularization_loss: 0.0743902176618576 # 11:35:18 --- INFO: epoch: 360, batch: 1, loss: 4.155808448791504, modularity_loss: -0.5747811794281006, purity_loss: 4.656185626983643, regularization_loss: 0.07440382242202759 # 11:35:19 --- INFO: epoch: 361, batch: 1, loss: 4.1550397872924805, modularity_loss: -0.5747342109680176, purity_loss: 4.65535831451416, regularization_loss: 0.0744156464934349 # 11:35:19 --- INFO: epoch: 362, batch: 1, loss: 4.154287815093994, modularity_loss: -0.57471764087677, purity_loss: 4.654580116271973, regularization_loss: 0.0744253620505333 # 11:35:19 --- INFO: epoch: 363, batch: 1, loss: 4.1535539627075195, modularity_loss: -0.574722945690155, purity_loss: 4.653843402862549, regularization_loss: 0.0744333267211914 # 11:35:20 --- INFO: epoch: 364, batch: 1, loss: 4.152837753295898, modularity_loss: -0.5747337937355042, purity_loss: 4.653131484985352, regularization_loss: 0.07444030791521072 # 11:35:20 --- INFO: epoch: 365, batch: 1, loss: 4.152139663696289, modularity_loss: -0.5747319459915161, purity_loss: 4.6524248123168945, regularization_loss: 0.07444706559181213 # 11:35:20 --- INFO: epoch: 366, batch: 1, loss: 4.151451110839844, modularity_loss: -0.5747050046920776, purity_loss: 4.651701927185059, regularization_loss: 0.07445415109395981 # 11:35:21 --- INFO: epoch: 367, batch: 1, loss: 4.1507697105407715, modularity_loss: -0.5746498107910156, purity_loss: 4.650958061218262, regularization_loss: 0.07446164637804031 # 11:35:21 --- INFO: epoch: 368, batch: 1, loss: 4.1500959396362305, modularity_loss: -0.5745770931243896, purity_loss: 4.650203704833984, regularization_loss: 0.07446911931037903 # 11:35:21 --- INFO: epoch: 369, batch: 1, loss: 4.149426460266113, modularity_loss: -0.574503481388092, purity_loss: 4.649454116821289, regularization_loss: 0.07447592914104462 # 11:35:21 --- INFO: epoch: 370, batch: 1, loss: 4.148763179779053, modularity_loss: -0.5744418501853943, purity_loss: 4.648723602294922, regularization_loss: 0.07448150962591171 # 11:35:22 --- INFO: epoch: 371, batch: 1, loss: 4.148103713989258, modularity_loss: -0.5743969678878784, purity_loss: 4.648015022277832, regularization_loss: 0.07448570430278778 # 11:35:22 --- INFO: epoch: 372, batch: 1, loss: 4.14744758605957, modularity_loss: -0.5743646025657654, purity_loss: 4.647323131561279, regularization_loss: 0.07448887079954147 # 11:35:22 --- INFO: epoch: 373, batch: 1, loss: 4.1468000411987305, modularity_loss: -0.5743318796157837, purity_loss: 4.646640300750732, regularization_loss: 0.07449159026145935 # 11:35:23 --- INFO: epoch: 374, batch: 1, loss: 4.146157264709473, modularity_loss: -0.5742868185043335, purity_loss: 4.645949363708496, regularization_loss: 0.07449451833963394 # 11:35:23 --- INFO: epoch: 375, batch: 1, loss: 4.145514011383057, modularity_loss: -0.5742236971855164, purity_loss: 4.64523983001709, regularization_loss: 0.07449795305728912 # 11:35:23 --- INFO: epoch: 376, batch: 1, loss: 4.144867897033691, modularity_loss: -0.5741462111473083, purity_loss: 4.644512176513672, regularization_loss: 0.0745018869638443 # 11:35:24 --- INFO: epoch: 377, batch: 1, loss: 4.144218921661377, modularity_loss: -0.5740619897842407, purity_loss: 4.64377498626709, regularization_loss: 0.07450602948665619 # 11:35:24 --- INFO: epoch: 378, batch: 1, loss: 4.1435675621032715, modularity_loss: -0.5739832520484924, purity_loss: 4.643040657043457, regularization_loss: 0.07450997829437256 # 11:35:24 --- INFO: epoch: 379, batch: 1, loss: 4.14290714263916, modularity_loss: -0.5739157795906067, purity_loss: 4.642309188842773, regularization_loss: 0.07451354712247849 # 11:35:25 --- INFO: epoch: 380, batch: 1, loss: 4.142237663269043, modularity_loss: -0.5738581418991089, purity_loss: 4.641578674316406, regularization_loss: 0.07451687753200531 # 11:35:25 --- INFO: epoch: 381, batch: 1, loss: 4.141550064086914, modularity_loss: -0.5738012194633484, purity_loss: 4.6408305168151855, regularization_loss: 0.0745205283164978 # 11:35:25 --- INFO: epoch: 382, batch: 1, loss: 4.140843868255615, modularity_loss: -0.5737334489822388, purity_loss: 4.640052318572998, regularization_loss: 0.07452511042356491 # 11:35:26 --- INFO: epoch: 383, batch: 1, loss: 4.140113353729248, modularity_loss: -0.5736440420150757, purity_loss: 4.63922643661499, regularization_loss: 0.07453113049268723 # 11:35:26 --- INFO: epoch: 384, batch: 1, loss: 4.139350414276123, modularity_loss: -0.5735290050506592, purity_loss: 4.638340473175049, regularization_loss: 0.07453881949186325 # 11:35:26 --- INFO: epoch: 385, batch: 1, loss: 4.13855504989624, modularity_loss: -0.5733901858329773, purity_loss: 4.637397289276123, regularization_loss: 0.07454805821180344 # 11:35:27 --- INFO: epoch: 386, batch: 1, loss: 4.137716293334961, modularity_loss: -0.5732322931289673, purity_loss: 4.63638973236084, regularization_loss: 0.07455860078334808 # 11:35:27 --- INFO: epoch: 387, batch: 1, loss: 4.136832237243652, modularity_loss: -0.5730576515197754, purity_loss: 4.635319709777832, regularization_loss: 0.0745701938867569 # 11:35:27 --- INFO: epoch: 388, batch: 1, loss: 4.135908603668213, modularity_loss: -0.5728645920753479, purity_loss: 4.634190559387207, regularization_loss: 0.07458268105983734 # 11:35:27 --- INFO: epoch: 389, batch: 1, loss: 4.134945869445801, modularity_loss: -0.5726447105407715, purity_loss: 4.632994174957275, regularization_loss: 0.07459626346826553 # 11:35:28 --- INFO: epoch: 390, batch: 1, loss: 4.133967876434326, modularity_loss: -0.572390079498291, purity_loss: 4.631746768951416, regularization_loss: 0.07461108267307281 # 11:35:28 --- INFO: epoch: 391, batch: 1, loss: 4.133007526397705, modularity_loss: -0.5721008777618408, purity_loss: 4.630481243133545, regularization_loss: 0.07462704181671143 # 11:35:28 --- INFO: epoch: 392, batch: 1, loss: 4.132107734680176, modularity_loss: -0.5717844367027283, purity_loss: 4.62924861907959, regularization_loss: 0.07464379072189331 # 11:35:29 --- INFO: epoch: 393, batch: 1, loss: 4.131323337554932, modularity_loss: -0.5714603066444397, purity_loss: 4.6281232833862305, regularization_loss: 0.0746605396270752 # 11:35:29 --- INFO: epoch: 394, batch: 1, loss: 4.13068962097168, modularity_loss: -0.5711579322814941, purity_loss: 4.627171516418457, regularization_loss: 0.07467612624168396 # 11:35:29 --- INFO: epoch: 395, batch: 1, loss: 4.130197048187256, modularity_loss: -0.5709084272384644, purity_loss: 4.626416206359863, regularization_loss: 0.07468926906585693 # 11:35:30 --- INFO: epoch: 396, batch: 1, loss: 4.129792213439941, modularity_loss: -0.5707371234893799, purity_loss: 4.625830173492432, regularization_loss: 0.07469898462295532 # 11:35:30 --- INFO: epoch: 397, batch: 1, loss: 4.129382610321045, modularity_loss: -0.5706547498703003, purity_loss: 4.625332355499268, regularization_loss: 0.0747048631310463 # 11:35:30 --- INFO: epoch: 398, batch: 1, loss: 4.128902912139893, modularity_loss: -0.5706552267074585, purity_loss: 4.624850749969482, regularization_loss: 0.0747072622179985 # 11:35:30 --- INFO: epoch: 399, batch: 1, loss: 4.128324508666992, modularity_loss: -0.5707212686538696, purity_loss: 4.624338626861572, regularization_loss: 0.0747070461511612 # 11:35:31 --- INFO: epoch: 400, batch: 1, loss: 4.1276631355285645, modularity_loss: -0.5708315968513489, purity_loss: 4.623789310455322, regularization_loss: 0.0747053474187851 # 11:35:31 --- INFO: epoch: 401, batch: 1, loss: 4.126969337463379, modularity_loss: -0.5709680914878845, purity_loss: 4.623234272003174, regularization_loss: 0.07470308244228363 # 11:35:31 --- INFO: epoch: 402, batch: 1, loss: 4.126283645629883, modularity_loss: -0.5711159706115723, purity_loss: 4.622698783874512, regularization_loss: 0.07470092922449112 # 11:35:32 --- INFO: epoch: 403, batch: 1, loss: 4.1256422996521, modularity_loss: -0.5712635517120361, purity_loss: 4.622206687927246, regularization_loss: 0.07469936460256577 # 11:35:32 --- INFO: epoch: 404, batch: 1, loss: 4.125051975250244, modularity_loss: -0.5714000463485718, purity_loss: 4.621753215789795, regularization_loss: 0.07469869405031204 # 11:35:32 --- INFO: epoch: 405, batch: 1, loss: 4.124507427215576, modularity_loss: -0.5715119242668152, purity_loss: 4.6213202476501465, regularization_loss: 0.07469917833805084 # 11:35:33 --- INFO: epoch: 406, batch: 1, loss: 4.124002933502197, modularity_loss: -0.5715882778167725, purity_loss: 4.620890140533447, regularization_loss: 0.07470102608203888 # 11:35:33 --- INFO: epoch: 407, batch: 1, loss: 4.123523235321045, modularity_loss: -0.5716185569763184, purity_loss: 4.6204376220703125, regularization_loss: 0.07470432668924332 # 11:35:33 --- INFO: epoch: 408, batch: 1, loss: 4.123054504394531, modularity_loss: -0.5715982913970947, purity_loss: 4.619944095611572, regularization_loss: 0.07470885664224625 # 11:35:34 --- INFO: epoch: 409, batch: 1, loss: 4.122582912445068, modularity_loss: -0.5715360641479492, purity_loss: 4.619405269622803, regularization_loss: 0.07471392303705215 # 11:35:34 --- INFO: epoch: 410, batch: 1, loss: 4.122095108032227, modularity_loss: -0.5714465975761414, purity_loss: 4.618823051452637, regularization_loss: 0.0747184306383133 # 11:35:34 --- INFO: epoch: 411, batch: 1, loss: 4.12158727645874, modularity_loss: -0.5713443160057068, purity_loss: 4.6182098388671875, regularization_loss: 0.07472154498100281 # 11:35:34 --- INFO: epoch: 412, batch: 1, loss: 4.121058464050293, modularity_loss: -0.5712381601333618, purity_loss: 4.6175737380981445, regularization_loss: 0.0747227892279625 # 11:35:35 --- INFO: epoch: 413, batch: 1, loss: 4.120516300201416, modularity_loss: -0.5711333751678467, purity_loss: 4.616927623748779, regularization_loss: 0.07472220808267593 # 11:35:35 --- INFO: epoch: 414, batch: 1, loss: 4.119972229003906, modularity_loss: -0.5710283517837524, purity_loss: 4.6162800788879395, regularization_loss: 0.07472027093172073 # 11:35:35 --- INFO: epoch: 415, batch: 1, loss: 4.1194376945495605, modularity_loss: -0.5709209442138672, purity_loss: 4.615641117095947, regularization_loss: 0.07471771538257599 # 11:35:36 --- INFO: epoch: 416, batch: 1, loss: 4.118921279907227, modularity_loss: -0.5708101391792297, purity_loss: 4.615016460418701, regularization_loss: 0.07471514493227005 # 11:35:36 --- INFO: epoch: 417, batch: 1, loss: 4.1184210777282715, modularity_loss: -0.5706971883773804, purity_loss: 4.614405155181885, regularization_loss: 0.07471306622028351 # 11:35:36 --- INFO: epoch: 418, batch: 1, loss: 4.117928504943848, modularity_loss: -0.5705853700637817, purity_loss: 4.613802433013916, regularization_loss: 0.07471168786287308 # 11:35:37 --- INFO: epoch: 419, batch: 1, loss: 4.117438793182373, modularity_loss: -0.5704784393310547, purity_loss: 4.613206386566162, regularization_loss: 0.07471103221178055 # 11:35:37 --- INFO: epoch: 420, batch: 1, loss: 4.116943359375, modularity_loss: -0.5703818202018738, purity_loss: 4.612614154815674, regularization_loss: 0.0747108981013298 # 11:35:37 --- INFO: epoch: 421, batch: 1, loss: 4.116428375244141, modularity_loss: -0.5702944993972778, purity_loss: 4.612011432647705, regularization_loss: 0.07471119612455368 # 11:35:37 --- INFO: epoch: 422, batch: 1, loss: 4.1158976554870605, modularity_loss: -0.5702118873596191, purity_loss: 4.611397743225098, regularization_loss: 0.07471181452274323 # 11:35:38 --- INFO: epoch: 423, batch: 1, loss: 4.11535120010376, modularity_loss: -0.57012939453125, purity_loss: 4.610767841339111, regularization_loss: 0.07471265643835068 # 11:35:38 --- INFO: epoch: 424, batch: 1, loss: 4.114794731140137, modularity_loss: -0.5700443387031555, purity_loss: 4.610125541687012, regularization_loss: 0.0747133120894432 # 11:35:38 --- INFO: epoch: 425, batch: 1, loss: 4.114228248596191, modularity_loss: -0.5699565410614014, purity_loss: 4.609471321105957, regularization_loss: 0.07471322268247604 # 11:35:39 --- INFO: epoch: 426, batch: 1, loss: 4.1136474609375, modularity_loss: -0.5698621273040771, purity_loss: 4.608797550201416, regularization_loss: 0.07471185177564621 # 11:35:39 --- INFO: epoch: 427, batch: 1, loss: 4.113059043884277, modularity_loss: -0.5697620511054993, purity_loss: 4.608112335205078, regularization_loss: 0.07470874488353729 # 11:35:39 --- INFO: epoch: 428, batch: 1, loss: 4.112453460693359, modularity_loss: -0.5696607232093811, purity_loss: 4.607410907745361, regularization_loss: 0.07470352947711945 # 11:35:40 --- INFO: epoch: 429, batch: 1, loss: 4.111816883087158, modularity_loss: -0.5695497989654541, purity_loss: 4.60667085647583, regularization_loss: 0.07469603419303894 # 11:35:40 --- INFO: epoch: 430, batch: 1, loss: 4.111144542694092, modularity_loss: -0.5694237947463989, purity_loss: 4.605882167816162, regularization_loss: 0.07468615472316742 # 11:35:40 --- INFO: epoch: 431, batch: 1, loss: 4.110429763793945, modularity_loss: -0.5692689418792725, purity_loss: 4.605024814605713, regularization_loss: 0.0746741071343422 # 11:35:40 --- INFO: epoch: 432, batch: 1, loss: 4.109653949737549, modularity_loss: -0.5690774917602539, purity_loss: 4.604071140289307, regularization_loss: 0.07466008514165878 # 11:35:41 --- INFO: epoch: 433, batch: 1, loss: 4.1088104248046875, modularity_loss: -0.5688424110412598, purity_loss: 4.60300874710083, regularization_loss: 0.07464385777711868 # 11:35:41 --- INFO: epoch: 434, batch: 1, loss: 4.107895851135254, modularity_loss: -0.5685737133026123, purity_loss: 4.601844787597656, regularization_loss: 0.07462464272975922 # 11:35:41 --- INFO: epoch: 435, batch: 1, loss: 4.106884479522705, modularity_loss: -0.5682656168937683, purity_loss: 4.600548267364502, regularization_loss: 0.07460162043571472 # 11:35:42 --- INFO: epoch: 436, batch: 1, loss: 4.105752468109131, modularity_loss: -0.5679073333740234, purity_loss: 4.599085807800293, regularization_loss: 0.07457396388053894 # 11:35:42 --- INFO: epoch: 437, batch: 1, loss: 4.10446834564209, modularity_loss: -0.5674849152565002, purity_loss: 4.597412109375, regularization_loss: 0.0745411366224289 # 11:35:42 --- INFO: epoch: 438, batch: 1, loss: 4.102963924407959, modularity_loss: -0.5669894218444824, purity_loss: 4.595451831817627, regularization_loss: 0.07450137287378311 # 11:35:43 --- INFO: epoch: 439, batch: 1, loss: 4.101215839385986, modularity_loss: -0.5664106607437134, purity_loss: 4.593174457550049, regularization_loss: 0.07445225864648819 # 11:35:43 --- INFO: epoch: 440, batch: 1, loss: 4.099147319793701, modularity_loss: -0.5657711029052734, purity_loss: 4.590527057647705, regularization_loss: 0.07439125329256058 # 11:35:43 --- INFO: epoch: 441, batch: 1, loss: 4.096593856811523, modularity_loss: -0.5650631189346313, purity_loss: 4.587341785430908, regularization_loss: 0.07431499660015106 # 11:35:43 --- INFO: epoch: 442, batch: 1, loss: 4.093234539031982, modularity_loss: -0.5642626285552979, purity_loss: 4.583278656005859, regularization_loss: 0.07421834021806717 # 11:35:44 --- INFO: epoch: 443, batch: 1, loss: 4.088987827301025, modularity_loss: -0.5634028911590576, purity_loss: 4.578296661376953, regularization_loss: 0.0740942433476448 # 11:35:44 --- INFO: epoch: 444, batch: 1, loss: 4.083475112915039, modularity_loss: -0.5625929236412048, purity_loss: 4.57213020324707, regularization_loss: 0.07393770664930344 # 11:35:44 --- INFO: epoch: 445, batch: 1, loss: 4.076183795928955, modularity_loss: -0.5620026588439941, purity_loss: 4.564441204071045, regularization_loss: 0.07374510914087296 # 11:35:45 --- INFO: epoch: 446, batch: 1, loss: 4.066742420196533, modularity_loss: -0.5619003176689148, purity_loss: 4.555125713348389, regularization_loss: 0.07351697236299515 # 11:35:45 --- INFO: epoch: 447, batch: 1, loss: 4.055968761444092, modularity_loss: -0.5626815557479858, purity_loss: 4.545380115509033, regularization_loss: 0.07327021658420563 # 11:35:45 --- INFO: epoch: 448, batch: 1, loss: 4.045150279998779, modularity_loss: -0.5646786689758301, purity_loss: 4.536784648895264, regularization_loss: 0.07304443418979645 # 11:35:46 --- INFO: epoch: 449, batch: 1, loss: 4.0336594581604, modularity_loss: -0.5677903890609741, purity_loss: 4.528567314147949, regularization_loss: 0.07288264483213425 # 11:35:46 --- INFO: epoch: 450, batch: 1, loss: 4.018993854522705, modularity_loss: -0.5715136528015137, purity_loss: 4.517703056335449, regularization_loss: 0.0728045403957367 # 11:35:46 --- INFO: epoch: 451, batch: 1, loss: 4.001464366912842, modularity_loss: -0.5752850770950317, purity_loss: 4.503946304321289, regularization_loss: 0.07280334085226059 # 11:35:47 --- INFO: epoch: 452, batch: 1, loss: 3.9833433628082275, modularity_loss: -0.5787436962127686, purity_loss: 4.489232063293457, regularization_loss: 0.07285504788160324 # 11:35:47 --- INFO: epoch: 453, batch: 1, loss: 3.965441942214966, modularity_loss: -0.5816754698753357, purity_loss: 4.474185943603516, regularization_loss: 0.07293146103620529 # 11:35:47 --- INFO: epoch: 454, batch: 1, loss: 3.9478325843811035, modularity_loss: -0.5840556621551514, purity_loss: 4.458881378173828, regularization_loss: 0.07300682365894318 # 11:35:47 --- INFO: epoch: 455, batch: 1, loss: 3.929542064666748, modularity_loss: -0.5858882665634155, purity_loss: 4.442365646362305, regularization_loss: 0.07306475937366486 # 11:35:48 --- INFO: epoch: 456, batch: 1, loss: 3.910885810852051, modularity_loss: -0.5873255729675293, purity_loss: 4.425100803375244, regularization_loss: 0.0731106549501419 # 11:35:48 --- INFO: epoch: 457, batch: 1, loss: 3.8936257362365723, modularity_loss: -0.5885381698608398, purity_loss: 4.409008979797363, regularization_loss: 0.07315487414598465 # 11:35:48 --- INFO: epoch: 458, batch: 1, loss: 3.878166437149048, modularity_loss: -0.5897192358970642, purity_loss: 4.394680500030518, regularization_loss: 0.07320515811443329 # 11:35:49 --- INFO: epoch: 459, batch: 1, loss: 3.8634755611419678, modularity_loss: -0.5910282135009766, purity_loss: 4.381239414215088, regularization_loss: 0.07326427847146988 # 11:35:49 --- INFO: epoch: 460, batch: 1, loss: 3.848785638809204, modularity_loss: -0.5925470590591431, purity_loss: 4.368001461029053, regularization_loss: 0.07333125919103622 # 11:35:49 --- INFO: epoch: 461, batch: 1, loss: 3.8346896171569824, modularity_loss: -0.5942522287368774, purity_loss: 4.355537414550781, regularization_loss: 0.073404461145401 # 11:35:50 --- INFO: epoch: 462, batch: 1, loss: 3.8222479820251465, modularity_loss: -0.5959993600845337, purity_loss: 4.344768524169922, regularization_loss: 0.07347877323627472 # 11:35:50 --- INFO: epoch: 463, batch: 1, loss: 3.810962438583374, modularity_loss: -0.5976624488830566, purity_loss: 4.3350725173950195, regularization_loss: 0.07355231046676636 # 11:35:50 --- INFO: epoch: 464, batch: 1, loss: 3.800318717956543, modularity_loss: -0.599134624004364, purity_loss: 4.325829982757568, regularization_loss: 0.07362334430217743 # 11:35:50 --- INFO: epoch: 465, batch: 1, loss: 3.789701461791992, modularity_loss: -0.6004000902175903, purity_loss: 4.316411018371582, regularization_loss: 0.0736904889345169 # 11:35:51 --- INFO: epoch: 466, batch: 1, loss: 3.779043436050415, modularity_loss: -0.6014965772628784, purity_loss: 4.306787014007568, regularization_loss: 0.07375302165746689 # 11:35:51 --- INFO: epoch: 467, batch: 1, loss: 3.7683043479919434, modularity_loss: -0.6024739742279053, purity_loss: 4.29696798324585, regularization_loss: 0.07381034642457962 # 11:35:51 --- INFO: epoch: 468, batch: 1, loss: 3.7576615810394287, modularity_loss: -0.6033977270126343, purity_loss: 4.287195205688477, regularization_loss: 0.07386408746242523 # 11:35:52 --- INFO: epoch: 469, batch: 1, loss: 3.7471375465393066, modularity_loss: -0.6043241024017334, purity_loss: 4.277544021606445, regularization_loss: 0.07391761988401413 # 11:35:52 --- INFO: epoch: 470, batch: 1, loss: 3.736737012863159, modularity_loss: -0.6052950024604797, purity_loss: 4.268056869506836, regularization_loss: 0.07397517561912537 # 11:35:52 --- INFO: epoch: 471, batch: 1, loss: 3.726527452468872, modularity_loss: -0.6063229441642761, purity_loss: 4.258810520172119, regularization_loss: 0.07403992116451263 # 11:35:53 --- INFO: epoch: 472, batch: 1, loss: 3.716978073120117, modularity_loss: -0.6073740124702454, purity_loss: 4.250239849090576, regularization_loss: 0.07411223649978638 # 11:35:53 --- INFO: epoch: 473, batch: 1, loss: 3.708373546600342, modularity_loss: -0.6083994507789612, purity_loss: 4.242583274841309, regularization_loss: 0.07418975979089737 # 11:35:53 --- INFO: epoch: 474, batch: 1, loss: 3.7009212970733643, modularity_loss: -0.6093660593032837, purity_loss: 4.23601770401001, regularization_loss: 0.07426965236663818 # 11:35:53 --- INFO: epoch: 475, batch: 1, loss: 3.6947288513183594, modularity_loss: -0.6102364659309387, purity_loss: 4.230618953704834, regularization_loss: 0.07434624433517456 # 11:35:54 --- INFO: epoch: 476, batch: 1, loss: 3.6895663738250732, modularity_loss: -0.6109839677810669, purity_loss: 4.226137161254883, regularization_loss: 0.07441326230764389 # 11:35:54 --- INFO: epoch: 477, batch: 1, loss: 3.6851806640625, modularity_loss: -0.6116119027137756, purity_loss: 4.222325801849365, regularization_loss: 0.07446686178445816 # 11:35:54 --- INFO: epoch: 478, batch: 1, loss: 3.6812422275543213, modularity_loss: -0.6121276021003723, purity_loss: 4.218865394592285, regularization_loss: 0.07450444996356964 # 11:35:55 --- INFO: epoch: 479, batch: 1, loss: 3.677539825439453, modularity_loss: -0.6125479936599731, purity_loss: 4.215561389923096, regularization_loss: 0.07452645897865295 # 11:35:55 --- INFO: epoch: 480, batch: 1, loss: 3.673973560333252, modularity_loss: -0.6128899455070496, purity_loss: 4.2123284339904785, regularization_loss: 0.07453514635562897 # 11:35:55 --- INFO: epoch: 481, batch: 1, loss: 3.670515775680542, modularity_loss: -0.6131739020347595, purity_loss: 4.209155082702637, regularization_loss: 0.07453455775976181 # 11:35:56 --- INFO: epoch: 482, batch: 1, loss: 3.667203426361084, modularity_loss: -0.6134227514266968, purity_loss: 4.20609712600708, regularization_loss: 0.07452902942895889 # 11:35:56 --- INFO: epoch: 483, batch: 1, loss: 3.6641271114349365, modularity_loss: -0.6136577129364014, purity_loss: 4.2032623291015625, regularization_loss: 0.07452241331338882 # 11:35:56 --- INFO: epoch: 484, batch: 1, loss: 3.6613268852233887, modularity_loss: -0.6138933897018433, purity_loss: 4.200702667236328, regularization_loss: 0.07451746612787247 # 11:35:56 --- INFO: epoch: 485, batch: 1, loss: 3.6587977409362793, modularity_loss: -0.614139199256897, purity_loss: 4.198421001434326, regularization_loss: 0.0745159313082695 # 11:35:57 --- INFO: epoch: 486, batch: 1, loss: 3.6564364433288574, modularity_loss: -0.6143894195556641, purity_loss: 4.19630765914917, regularization_loss: 0.07451830059289932 # 11:35:57 --- INFO: epoch: 487, batch: 1, loss: 3.654141426086426, modularity_loss: -0.6146302223205566, purity_loss: 4.194247245788574, regularization_loss: 0.07452435791492462 # 11:35:57 --- INFO: epoch: 488, batch: 1, loss: 3.651805877685547, modularity_loss: -0.614840567111969, purity_loss: 4.192112922668457, regularization_loss: 0.07453348487615585 # 11:35:58 --- INFO: epoch: 489, batch: 1, loss: 3.6493313312530518, modularity_loss: -0.6149961948394775, purity_loss: 4.189782619476318, regularization_loss: 0.07454492151737213 # 11:35:58 --- INFO: epoch: 490, batch: 1, loss: 3.646756172180176, modularity_loss: -0.6150829195976257, purity_loss: 4.187281131744385, regularization_loss: 0.07455798238515854 # 11:35:58 --- INFO: epoch: 491, batch: 1, loss: 3.644167423248291, modularity_loss: -0.6150844097137451, purity_loss: 4.184680461883545, regularization_loss: 0.07457150518894196 # 11:35:59 --- INFO: epoch: 492, batch: 1, loss: 3.6415398120880127, modularity_loss: -0.6149938106536865, purity_loss: 4.181949615478516, regularization_loss: 0.07458393275737762 # 11:35:59 --- INFO: epoch: 493, batch: 1, loss: 3.638885498046875, modularity_loss: -0.6148231029510498, purity_loss: 4.17911434173584, regularization_loss: 0.0745941624045372 # 11:35:59 --- INFO: epoch: 494, batch: 1, loss: 3.636228561401367, modularity_loss: -0.6145913004875183, purity_loss: 4.1762189865112305, regularization_loss: 0.07460074126720428 # 11:36:00 --- INFO: epoch: 495, batch: 1, loss: 3.6336047649383545, modularity_loss: -0.6143289804458618, purity_loss: 4.173331260681152, regularization_loss: 0.074602410197258 # 11:36:00 --- INFO: epoch: 496, batch: 1, loss: 3.631000280380249, modularity_loss: -0.6140619516372681, purity_loss: 4.170464515686035, regularization_loss: 0.07459764927625656 # 11:36:00 --- INFO: epoch: 497, batch: 1, loss: 3.6283230781555176, modularity_loss: -0.6138187050819397, purity_loss: 4.167555809020996, regularization_loss: 0.0745859295129776 # 11:36:01 --- INFO: epoch: 498, batch: 1, loss: 3.625584602355957, modularity_loss: -0.6136263608932495, purity_loss: 4.164642810821533, regularization_loss: 0.07456820458173752 # 11:36:01 --- INFO: epoch: 499, batch: 1, loss: 3.622783660888672, modularity_loss: -0.6134976744651794, purity_loss: 4.1617350578308105, regularization_loss: 0.07454626262187958 # 11:36:01 --- INFO: epoch: 500, batch: 1, loss: 3.6199400424957275, modularity_loss: -0.613420844078064, purity_loss: 4.158838748931885, regularization_loss: 0.07452220469713211 # 11:36:02 --- INFO: epoch: 501, batch: 1, loss: 3.6171023845672607, modularity_loss: -0.6133748888969421, purity_loss: 4.155978679656982, regularization_loss: 0.07449851930141449 # 11:36:02 --- INFO: epoch: 502, batch: 1, loss: 3.614269733428955, modularity_loss: -0.6133327484130859, purity_loss: 4.153124809265137, regularization_loss: 0.07447752356529236 # 11:36:02 --- INFO: epoch: 503, batch: 1, loss: 3.611417531967163, modularity_loss: -0.6132693290710449, purity_loss: 4.15022611618042, regularization_loss: 0.07446078211069107 # 11:36:03 --- INFO: epoch: 504, batch: 1, loss: 3.608511209487915, modularity_loss: -0.613166868686676, purity_loss: 4.147229194641113, regularization_loss: 0.07444890588521957 # 11:36:03 --- INFO: epoch: 505, batch: 1, loss: 3.605525016784668, modularity_loss: -0.6130160093307495, purity_loss: 4.144099235534668, regularization_loss: 0.07444173097610474 # 11:36:03 --- INFO: epoch: 506, batch: 1, loss: 3.6024580001831055, modularity_loss: -0.6128139495849609, purity_loss: 4.140833854675293, regularization_loss: 0.07443820685148239 # 11:36:04 --- INFO: epoch: 507, batch: 1, loss: 3.5993258953094482, modularity_loss: -0.6125696897506714, purity_loss: 4.137458324432373, regularization_loss: 0.07443727552890778 # 11:36:04 --- INFO: epoch: 508, batch: 1, loss: 3.5961737632751465, modularity_loss: -0.6122933030128479, purity_loss: 4.134029865264893, regularization_loss: 0.07443727552890778 # 11:36:04 --- INFO: epoch: 509, batch: 1, loss: 3.5930728912353516, modularity_loss: -0.6120021939277649, purity_loss: 4.130638122558594, regularization_loss: 0.07443708181381226 # 11:36:05 --- INFO: epoch: 510, batch: 1, loss: 3.590001106262207, modularity_loss: -0.611706554889679, purity_loss: 4.127272605895996, regularization_loss: 0.07443508505821228 # 11:36:05 --- INFO: epoch: 511, batch: 1, loss: 3.5869479179382324, modularity_loss: -0.6114233732223511, purity_loss: 4.123940944671631, regularization_loss: 0.0744304358959198 # 11:36:05 --- INFO: epoch: 512, batch: 1, loss: 3.5838894844055176, modularity_loss: -0.6111712455749512, purity_loss: 4.1206374168396, regularization_loss: 0.07442330569028854 # 11:36:06 --- INFO: epoch: 513, batch: 1, loss: 3.580822229385376, modularity_loss: -0.6109635829925537, purity_loss: 4.117371559143066, regularization_loss: 0.07441431283950806 # 11:36:06 --- INFO: epoch: 514, batch: 1, loss: 3.577752113342285, modularity_loss: -0.6107942461967468, purity_loss: 4.114143371582031, regularization_loss: 0.07440303266048431 # 11:36:06 --- INFO: epoch: 515, batch: 1, loss: 3.574666976928711, modularity_loss: -0.6106579303741455, purity_loss: 4.110934734344482, regularization_loss: 0.0743902325630188 # 11:36:06 --- INFO: epoch: 516, batch: 1, loss: 3.571580648422241, modularity_loss: -0.6105481386184692, purity_loss: 4.107751846313477, regularization_loss: 0.07437692582607269 # 11:36:07 --- INFO: epoch: 517, batch: 1, loss: 3.568519115447998, modularity_loss: -0.6104516983032227, purity_loss: 4.104607105255127, regularization_loss: 0.07436370104551315 # 11:36:07 --- INFO: epoch: 518, batch: 1, loss: 3.565471649169922, modularity_loss: -0.6103577613830566, purity_loss: 4.101478099822998, regularization_loss: 0.07435141503810883 # 11:36:07 --- INFO: epoch: 519, batch: 1, loss: 3.562424421310425, modularity_loss: -0.610254168510437, purity_loss: 4.0983381271362305, regularization_loss: 0.07434046268463135 # 11:36:08 --- INFO: epoch: 520, batch: 1, loss: 3.5593724250793457, modularity_loss: -0.6101377010345459, purity_loss: 4.095178604125977, regularization_loss: 0.07433146238327026 # 11:36:08 --- INFO: epoch: 521, batch: 1, loss: 3.556313991546631, modularity_loss: -0.6100000143051147, purity_loss: 4.091989994049072, regularization_loss: 0.0743240937590599 # 11:36:09 --- INFO: epoch: 522, batch: 1, loss: 3.553253412246704, modularity_loss: -0.6098423004150391, purity_loss: 4.088777542114258, regularization_loss: 0.07431814074516296 # 11:36:09 --- INFO: epoch: 523, batch: 1, loss: 3.5502114295959473, modularity_loss: -0.6096738576889038, purity_loss: 4.0855712890625, regularization_loss: 0.07431399822235107 # 11:36:09 --- INFO: epoch: 524, batch: 1, loss: 3.5471713542938232, modularity_loss: -0.6095079183578491, purity_loss: 4.082367420196533, regularization_loss: 0.07431186735630035 # 11:36:10 --- INFO: epoch: 525, batch: 1, loss: 3.544124126434326, modularity_loss: -0.6093576550483704, purity_loss: 4.079169750213623, regularization_loss: 0.07431215792894363 # 11:36:10 --- INFO: epoch: 526, batch: 1, loss: 3.5410468578338623, modularity_loss: -0.6092305779457092, purity_loss: 4.075963020324707, regularization_loss: 0.07431443780660629 # 11:36:10 --- INFO: epoch: 527, batch: 1, loss: 3.5379300117492676, modularity_loss: -0.6091315150260925, purity_loss: 4.072742938995361, regularization_loss: 0.07431862503290176 # 11:36:11 --- INFO: epoch: 528, batch: 1, loss: 3.53481125831604, modularity_loss: -0.6090551018714905, purity_loss: 4.069542407989502, regularization_loss: 0.07432398945093155 # 11:36:11 --- INFO: epoch: 529, batch: 1, loss: 3.5316741466522217, modularity_loss: -0.6089891195297241, purity_loss: 4.066333770751953, regularization_loss: 0.07432956993579865 # 11:36:11 --- INFO: epoch: 530, batch: 1, loss: 3.5285391807556152, modularity_loss: -0.6089223623275757, purity_loss: 4.063127040863037, regularization_loss: 0.07433458417654037 # 11:36:12 --- INFO: epoch: 531, batch: 1, loss: 3.5254108905792236, modularity_loss: -0.6088444590568542, purity_loss: 4.059917449951172, regularization_loss: 0.07433795928955078 # 11:36:12 --- INFO: epoch: 532, batch: 1, loss: 3.522289991378784, modularity_loss: -0.6087523698806763, purity_loss: 4.056702613830566, regularization_loss: 0.07433980703353882 # 11:36:12 --- INFO: epoch: 533, batch: 1, loss: 3.5191810131073, modularity_loss: -0.6086558699607849, purity_loss: 4.053495407104492, regularization_loss: 0.07434152811765671 # 11:36:13 --- INFO: epoch: 534, batch: 1, loss: 3.5160837173461914, modularity_loss: -0.6085688471794128, purity_loss: 4.050307750701904, regularization_loss: 0.07434485107660294 # 11:36:13 --- INFO: epoch: 535, batch: 1, loss: 3.5129997730255127, modularity_loss: -0.6084942817687988, purity_loss: 4.047143459320068, regularization_loss: 0.07435066252946854 # 11:36:13 --- INFO: epoch: 536, batch: 1, loss: 3.509936809539795, modularity_loss: -0.6084328293800354, purity_loss: 4.044010639190674, regularization_loss: 0.07435906678438187 # 11:36:14 --- INFO: epoch: 537, batch: 1, loss: 3.5069172382354736, modularity_loss: -0.6083766222000122, purity_loss: 4.040925025939941, regularization_loss: 0.074368916451931 # 11:36:14 --- INFO: epoch: 538, batch: 1, loss: 3.5039377212524414, modularity_loss: -0.608316957950592, purity_loss: 4.037875652313232, regularization_loss: 0.07437888532876968 # 11:36:14 --- INFO: epoch: 539, batch: 1, loss: 3.5009870529174805, modularity_loss: -0.6082561016082764, purity_loss: 4.034853935241699, regularization_loss: 0.07438908517360687 # 11:36:15 --- INFO: epoch: 540, batch: 1, loss: 3.4980661869049072, modularity_loss: -0.608196496963501, purity_loss: 4.031863212585449, regularization_loss: 0.07439954578876495 # 11:36:15 --- INFO: epoch: 541, batch: 1, loss: 3.495177745819092, modularity_loss: -0.6081417202949524, purity_loss: 4.028908729553223, regularization_loss: 0.0744108110666275 # 11:36:16 --- INFO: epoch: 542, batch: 1, loss: 3.4923415184020996, modularity_loss: -0.608096718788147, purity_loss: 4.02601432800293, regularization_loss: 0.07442396879196167 # 11:36:16 --- INFO: epoch: 543, batch: 1, loss: 3.489562511444092, modularity_loss: -0.6080563068389893, purity_loss: 4.02318000793457, regularization_loss: 0.07443877309560776 # 11:36:17 --- INFO: epoch: 544, batch: 1, loss: 3.4868764877319336, modularity_loss: -0.6080097556114197, purity_loss: 4.020432472229004, regularization_loss: 0.07445371150970459 # 11:36:17 --- INFO: epoch: 545, batch: 1, loss: 3.4843056201934814, modularity_loss: -0.607948899269104, purity_loss: 4.017787456512451, regularization_loss: 0.07446698099374771 # 11:36:17 --- INFO: epoch: 546, batch: 1, loss: 3.481825828552246, modularity_loss: -0.6078734993934631, purity_loss: 4.015221118927002, regularization_loss: 0.07447806745767593 # 11:36:18 --- INFO: epoch: 547, batch: 1, loss: 3.479466438293457, modularity_loss: -0.6077962517738342, purity_loss: 4.012774467468262, regularization_loss: 0.07448829710483551 # 11:36:18 --- INFO: epoch: 548, batch: 1, loss: 3.4772183895111084, modularity_loss: -0.6077297925949097, purity_loss: 4.010449409484863, regularization_loss: 0.07449881732463837 # 11:36:18 --- INFO: epoch: 549, batch: 1, loss: 3.475069999694824, modularity_loss: -0.6076837778091431, purity_loss: 4.008243083953857, regularization_loss: 0.07451068609952927 # 11:36:19 --- INFO: epoch: 550, batch: 1, loss: 3.4730210304260254, modularity_loss: -0.6076596975326538, purity_loss: 4.006156921386719, regularization_loss: 0.07452377676963806 # 11:36:19 --- INFO: epoch: 551, batch: 1, loss: 3.471071243286133, modularity_loss: -0.6076537370681763, purity_loss: 4.004188060760498, regularization_loss: 0.07453705370426178 # 11:36:19 --- INFO: epoch: 552, batch: 1, loss: 3.4692130088806152, modularity_loss: -0.607658326625824, purity_loss: 4.002322196960449, regularization_loss: 0.07454905658960342 # 11:36:20 --- INFO: epoch: 553, batch: 1, loss: 3.4674367904663086, modularity_loss: -0.6076701879501343, purity_loss: 4.000547409057617, regularization_loss: 0.07455962151288986 # 11:36:20 --- INFO: epoch: 554, batch: 1, loss: 3.465729236602783, modularity_loss: -0.6076894998550415, purity_loss: 3.9988491535186768, regularization_loss: 0.0745697021484375 # 11:36:20 --- INFO: epoch: 555, batch: 1, loss: 3.464085578918457, modularity_loss: -0.6077148914337158, purity_loss: 3.997220516204834, regularization_loss: 0.07457991689443588 # 11:36:21 --- INFO: epoch: 556, batch: 1, loss: 3.4624972343444824, modularity_loss: -0.6077462434768677, purity_loss: 3.995652914047241, regularization_loss: 0.0745905190706253 # 11:36:21 --- INFO: epoch: 557, batch: 1, loss: 3.460960626602173, modularity_loss: -0.6077839136123657, purity_loss: 3.9941442012786865, regularization_loss: 0.07460035383701324 # 11:36:22 --- INFO: epoch: 558, batch: 1, loss: 3.459486722946167, modularity_loss: -0.6078293323516846, purity_loss: 3.9927077293395996, regularization_loss: 0.07460832595825195 # 11:36:22 --- INFO: epoch: 559, batch: 1, loss: 3.4580631256103516, modularity_loss: -0.6078857779502869, purity_loss: 3.9913344383239746, regularization_loss: 0.0746145099401474 # 11:36:22 --- INFO: epoch: 560, batch: 1, loss: 3.4566872119903564, modularity_loss: -0.6079564094543457, purity_loss: 3.9900238513946533, regularization_loss: 0.07461968809366226 # 11:36:23 --- INFO: epoch: 561, batch: 1, loss: 3.4553627967834473, modularity_loss: -0.6080377101898193, purity_loss: 3.9887757301330566, regularization_loss: 0.07462484389543533 # 11:36:23 --- INFO: epoch: 562, batch: 1, loss: 3.454085350036621, modularity_loss: -0.608126163482666, purity_loss: 3.9875810146331787, regularization_loss: 0.07463043183088303 # 11:36:23 --- INFO: epoch: 563, batch: 1, loss: 3.4528565406799316, modularity_loss: -0.6082156300544739, purity_loss: 3.986436128616333, regularization_loss: 0.07463616132736206 # 11:36:24 --- INFO: epoch: 564, batch: 1, loss: 3.451673984527588, modularity_loss: -0.6083011627197266, purity_loss: 3.9853339195251465, regularization_loss: 0.07464126497507095 # 11:36:24 --- INFO: epoch: 565, batch: 1, loss: 3.450528621673584, modularity_loss: -0.6083787679672241, purity_loss: 3.984261989593506, regularization_loss: 0.07464525103569031 # 11:36:24 --- INFO: epoch: 566, batch: 1, loss: 3.44942307472229, modularity_loss: -0.6084476113319397, purity_loss: 3.983222246170044, regularization_loss: 0.07464844733476639 # 11:36:25 --- INFO: epoch: 567, batch: 1, loss: 3.448355197906494, modularity_loss: -0.6085067987442017, purity_loss: 3.982210636138916, regularization_loss: 0.07465138286352158 # 11:36:25 --- INFO: epoch: 568, batch: 1, loss: 3.447329044342041, modularity_loss: -0.6085564494132996, purity_loss: 3.981231212615967, regularization_loss: 0.07465439289808273 # 11:36:25 --- INFO: epoch: 569, batch: 1, loss: 3.4463324546813965, modularity_loss: -0.6085982322692871, purity_loss: 3.980273485183716, regularization_loss: 0.07465726137161255 # 11:36:26 --- INFO: epoch: 570, batch: 1, loss: 3.4453659057617188, modularity_loss: -0.6086323857307434, purity_loss: 3.9793386459350586, regularization_loss: 0.07465960830450058 # 11:36:26 --- INFO: epoch: 571, batch: 1, loss: 3.444427490234375, modularity_loss: -0.6086603403091431, purity_loss: 3.978426456451416, regularization_loss: 0.07466133683919907 # 11:36:26 --- INFO: epoch: 572, batch: 1, loss: 3.443511486053467, modularity_loss: -0.6086817979812622, purity_loss: 3.9775304794311523, regularization_loss: 0.07466293126344681 # 11:36:27 --- INFO: epoch: 573, batch: 1, loss: 3.44262433052063, modularity_loss: -0.6086944341659546, purity_loss: 3.976653575897217, regularization_loss: 0.0746651366353035 # 11:36:27 --- INFO: epoch: 574, batch: 1, loss: 3.441760540008545, modularity_loss: -0.6086971759796143, purity_loss: 3.9757895469665527, regularization_loss: 0.07466808706521988 # 11:36:27 --- INFO: epoch: 575, batch: 1, loss: 3.4409244060516357, modularity_loss: -0.6086897850036621, purity_loss: 3.974942922592163, regularization_loss: 0.0746712014079094 # 11:36:28 --- INFO: epoch: 576, batch: 1, loss: 3.4401187896728516, modularity_loss: -0.6086709499359131, purity_loss: 3.974116325378418, regularization_loss: 0.07467330247163773 # 11:36:28 --- INFO: epoch: 577, batch: 1, loss: 3.439330577850342, modularity_loss: -0.6086453199386597, purity_loss: 3.973301410675049, regularization_loss: 0.07467443495988846 # 11:36:28 --- INFO: epoch: 578, batch: 1, loss: 3.438565731048584, modularity_loss: -0.6086165904998779, purity_loss: 3.9725069999694824, regularization_loss: 0.07467517256736755 # 11:36:28 --- INFO: epoch: 579, batch: 1, loss: 3.4378228187561035, modularity_loss: -0.6085877418518066, purity_loss: 3.9717342853546143, regularization_loss: 0.07467612624168396 # 11:36:29 --- INFO: epoch: 580, batch: 1, loss: 3.437100410461426, modularity_loss: -0.6085619926452637, purity_loss: 3.970985174179077, regularization_loss: 0.07467734068632126 # 11:36:29 --- INFO: epoch: 581, batch: 1, loss: 3.436394453048706, modularity_loss: -0.608540415763855, purity_loss: 3.9702563285827637, regularization_loss: 0.07467859983444214 # 11:36:29 --- INFO: epoch: 582, batch: 1, loss: 3.4357075691223145, modularity_loss: -0.608521044254303, purity_loss: 3.9695487022399902, regularization_loss: 0.0746799185872078 # 11:36:30 --- INFO: epoch: 583, batch: 1, loss: 3.435039758682251, modularity_loss: -0.6085017919540405, purity_loss: 3.968859910964966, regularization_loss: 0.07468163222074509 # 11:36:30 --- INFO: epoch: 584, batch: 1, loss: 3.4343841075897217, modularity_loss: -0.6084802150726318, purity_loss: 3.9681804180145264, regularization_loss: 0.07468390464782715 # 11:36:30 --- INFO: epoch: 585, batch: 1, loss: 3.4337472915649414, modularity_loss: -0.6084542870521545, purity_loss: 3.967515468597412, regularization_loss: 0.0746862068772316 # 11:36:31 --- INFO: epoch: 586, batch: 1, loss: 3.433120012283325, modularity_loss: -0.6084240078926086, purity_loss: 3.9668564796447754, regularization_loss: 0.07468755543231964 # 11:36:31 --- INFO: epoch: 587, batch: 1, loss: 3.4325149059295654, modularity_loss: -0.6083940267562866, purity_loss: 3.9662208557128906, regularization_loss: 0.07468804717063904 # 11:36:31 --- INFO: epoch: 588, batch: 1, loss: 3.431920051574707, modularity_loss: -0.6083695888519287, purity_loss: 3.965601682662964, regularization_loss: 0.07468798011541367 # 11:36:32 --- INFO: epoch: 589, batch: 1, loss: 3.4313364028930664, modularity_loss: -0.6083557605743408, purity_loss: 3.9650044441223145, regularization_loss: 0.07468771934509277 # 11:36:32 --- INFO: epoch: 590, batch: 1, loss: 3.430765151977539, modularity_loss: -0.6083537340164185, purity_loss: 3.9644315242767334, regularization_loss: 0.07468744367361069 # 11:36:32 --- INFO: epoch: 591, batch: 1, loss: 3.430205821990967, modularity_loss: -0.608362078666687, purity_loss: 3.9638805389404297, regularization_loss: 0.0746874138712883 # 11:36:33 --- INFO: epoch: 592, batch: 1, loss: 3.429654359817505, modularity_loss: -0.6083762049674988, purity_loss: 3.9633426666259766, regularization_loss: 0.07468793541193008 # 11:36:33 --- INFO: epoch: 593, batch: 1, loss: 3.429117202758789, modularity_loss: -0.6083896160125732, purity_loss: 3.962817430496216, regularization_loss: 0.0746893361210823 # 11:36:33 --- INFO: epoch: 594, batch: 1, loss: 3.4285888671875, modularity_loss: -0.6083987355232239, purity_loss: 3.9622962474823, regularization_loss: 0.07469140738248825 # 11:36:33 --- INFO: epoch: 595, batch: 1, loss: 3.428069829940796, modularity_loss: -0.6084021925926208, purity_loss: 3.961778402328491, regularization_loss: 0.07469359785318375 # 11:36:34 --- INFO: epoch: 596, batch: 1, loss: 3.427558422088623, modularity_loss: -0.6084009408950806, purity_loss: 3.96126389503479, regularization_loss: 0.07469537109136581 # 11:36:34 --- INFO: epoch: 597, batch: 1, loss: 3.4270524978637695, modularity_loss: -0.6083990335464478, purity_loss: 3.9607551097869873, regularization_loss: 0.07469645142555237 # 11:36:34 --- INFO: epoch: 598, batch: 1, loss: 3.4265573024749756, modularity_loss: -0.6083987951278687, purity_loss: 3.960259199142456, regularization_loss: 0.07469692826271057 # 11:36:35 --- INFO: epoch: 599, batch: 1, loss: 3.42606782913208, modularity_loss: -0.6084031462669373, purity_loss: 3.9597742557525635, regularization_loss: 0.07469679415225983 # 11:36:35 --- INFO: epoch: 600, batch: 1, loss: 3.425586700439453, modularity_loss: -0.6084128022193909, purity_loss: 3.9593029022216797, regularization_loss: 0.07469645142555237 # 11:36:35 --- INFO: epoch: 601, batch: 1, loss: 3.425116539001465, modularity_loss: -0.6084266901016235, purity_loss: 3.9588470458984375, regularization_loss: 0.07469626516103745 # 11:36:36 --- INFO: epoch: 602, batch: 1, loss: 3.4246468544006348, modularity_loss: -0.6084423065185547, purity_loss: 3.95839262008667, regularization_loss: 0.07469648867845535 # 11:36:36 --- INFO: epoch: 603, batch: 1, loss: 3.424189805984497, modularity_loss: -0.6084585189819336, purity_loss: 3.957951068878174, regularization_loss: 0.0746973305940628 # 11:36:36 --- INFO: epoch: 604, batch: 1, loss: 3.423737049102783, modularity_loss: -0.6084734201431274, purity_loss: 3.9575119018554688, regularization_loss: 0.07469865679740906 # 11:36:36 --- INFO: epoch: 605, batch: 1, loss: 3.4232935905456543, modularity_loss: -0.6084868907928467, purity_loss: 3.957080364227295, regularization_loss: 0.07470013946294785 # 11:36:37 --- INFO: epoch: 606, batch: 1, loss: 3.422853469848633, modularity_loss: -0.6084998846054077, purity_loss: 3.9566521644592285, regularization_loss: 0.07470130175352097 # 11:36:37 --- INFO: epoch: 607, batch: 1, loss: 3.4224154949188232, modularity_loss: -0.6085119247436523, purity_loss: 3.9562253952026367, regularization_loss: 0.07470196485519409 # 11:36:37 --- INFO: epoch: 608, batch: 1, loss: 3.4219868183135986, modularity_loss: -0.6085251569747925, purity_loss: 3.9558098316192627, regularization_loss: 0.07470208406448364 # 11:36:38 --- INFO: epoch: 609, batch: 1, loss: 3.421563148498535, modularity_loss: -0.6085386276245117, purity_loss: 3.955399990081787, regularization_loss: 0.07470188289880753 # 11:36:38 --- INFO: epoch: 610, batch: 1, loss: 3.4211442470550537, modularity_loss: -0.6085527539253235, purity_loss: 3.9549951553344727, regularization_loss: 0.07470178604125977 # 11:36:38 --- INFO: epoch: 611, batch: 1, loss: 3.420729160308838, modularity_loss: -0.6085662245750427, purity_loss: 3.9545934200286865, regularization_loss: 0.07470201700925827 # 11:36:39 --- INFO: epoch: 612, batch: 1, loss: 3.420315742492676, modularity_loss: -0.6085794568061829, purity_loss: 3.954192638397217, regularization_loss: 0.07470262050628662 # 11:36:39 --- INFO: epoch: 613, batch: 1, loss: 3.4199066162109375, modularity_loss: -0.6085907220840454, purity_loss: 3.953793525695801, regularization_loss: 0.07470368593931198 # 11:36:39 --- INFO: epoch: 614, batch: 1, loss: 3.419501304626465, modularity_loss: -0.608601450920105, purity_loss: 3.953397750854492, regularization_loss: 0.07470505684614182 # 11:36:39 --- INFO: epoch: 615, batch: 1, loss: 3.419100284576416, modularity_loss: -0.6086120009422302, purity_loss: 3.9530060291290283, regularization_loss: 0.07470634579658508 # 11:36:40 --- INFO: epoch: 616, batch: 1, loss: 3.418704032897949, modularity_loss: -0.6086233854293823, purity_loss: 3.952620267868042, regularization_loss: 0.07470722496509552 # 11:36:40 --- INFO: epoch: 617, batch: 1, loss: 3.4183120727539062, modularity_loss: -0.6086347699165344, purity_loss: 3.952239513397217, regularization_loss: 0.07470735907554626 # 11:36:40 --- INFO: epoch: 618, batch: 1, loss: 3.417924404144287, modularity_loss: -0.6086475253105164, purity_loss: 3.9518649578094482, regularization_loss: 0.07470697909593582 # 11:36:41 --- INFO: epoch: 619, batch: 1, loss: 3.417537212371826, modularity_loss: -0.6086602807044983, purity_loss: 3.951491117477417, regularization_loss: 0.07470647245645523 # 11:36:41 --- INFO: epoch: 620, batch: 1, loss: 3.417156457901001, modularity_loss: -0.6086721420288086, purity_loss: 3.951122522354126, regularization_loss: 0.07470603287220001 # 11:36:41 --- INFO: epoch: 621, batch: 1, loss: 3.4167776107788086, modularity_loss: -0.6086831092834473, purity_loss: 3.9507548809051514, regularization_loss: 0.0747058317065239 # 11:36:42 --- INFO: epoch: 622, batch: 1, loss: 3.416400909423828, modularity_loss: -0.6086924076080322, purity_loss: 3.9503872394561768, regularization_loss: 0.07470603287220001 # 11:36:42 --- INFO: epoch: 623, batch: 1, loss: 3.4160304069519043, modularity_loss: -0.6086999177932739, purity_loss: 3.950023651123047, regularization_loss: 0.07470670342445374 # 11:36:42 --- INFO: epoch: 624, batch: 1, loss: 3.4156582355499268, modularity_loss: -0.6087060570716858, purity_loss: 3.9496567249298096, regularization_loss: 0.07470755279064178 # 11:36:42 --- INFO: epoch: 625, batch: 1, loss: 3.415294885635376, modularity_loss: -0.6087099313735962, purity_loss: 3.949296474456787, regularization_loss: 0.07470835000276566 # 11:36:43 --- INFO: epoch: 626, batch: 1, loss: 3.4149301052093506, modularity_loss: -0.6087135672569275, purity_loss: 3.94893479347229, regularization_loss: 0.07470890879631042 # 11:36:43 --- INFO: epoch: 627, batch: 1, loss: 3.4145689010620117, modularity_loss: -0.6087162494659424, purity_loss: 3.948575973510742, regularization_loss: 0.07470915466547012 # 11:36:43 --- INFO: epoch: 628, batch: 1, loss: 3.414212465286255, modularity_loss: -0.608718752861023, purity_loss: 3.9482221603393555, regularization_loss: 0.07470907270908356 # 11:36:44 --- INFO: epoch: 629, batch: 1, loss: 3.4138550758361816, modularity_loss: -0.6087208390235901, purity_loss: 3.9478671550750732, regularization_loss: 0.07470884919166565 # 11:36:44 --- INFO: epoch: 630, batch: 1, loss: 3.413503646850586, modularity_loss: -0.6087228059768677, purity_loss: 3.9475176334381104, regularization_loss: 0.07470874488353729 # 11:36:44 --- INFO: epoch: 631, batch: 1, loss: 3.4131507873535156, modularity_loss: -0.6087247133255005, purity_loss: 3.947166681289673, regularization_loss: 0.07470893114805222 # 11:36:45 --- INFO: epoch: 632, batch: 1, loss: 3.4128026962280273, modularity_loss: -0.6087263822555542, purity_loss: 3.94681978225708, regularization_loss: 0.07470938563346863 # 11:36:45 --- INFO: epoch: 633, batch: 1, loss: 3.412454605102539, modularity_loss: -0.6087270975112915, purity_loss: 3.946471691131592, regularization_loss: 0.07470990717411041 # 11:36:45 --- INFO: epoch: 634, batch: 1, loss: 3.4121100902557373, modularity_loss: -0.6087270975112915, purity_loss: 3.946126699447632, regularization_loss: 0.0747104212641716 # 11:36:46 --- INFO: epoch: 635, batch: 1, loss: 3.411769151687622, modularity_loss: -0.6087260246276855, purity_loss: 3.945784330368042, regularization_loss: 0.0747108981013298 # 11:36:46 --- INFO: epoch: 636, batch: 1, loss: 3.411428928375244, modularity_loss: -0.6087247133255005, purity_loss: 3.9454421997070312, regularization_loss: 0.07471131533384323 # 11:36:46 --- INFO: epoch: 637, batch: 1, loss: 3.411085367202759, modularity_loss: -0.6087231636047363, purity_loss: 3.945096969604492, regularization_loss: 0.07471158355474472 # 11:36:46 --- INFO: epoch: 638, batch: 1, loss: 3.410750389099121, modularity_loss: -0.6087213754653931, purity_loss: 3.9447600841522217, regularization_loss: 0.0747116282582283 # 11:36:47 --- INFO: epoch: 639, batch: 1, loss: 3.4104115962982178, modularity_loss: -0.6087194681167603, purity_loss: 3.9444196224212646, regularization_loss: 0.07471141964197159 # 11:36:47 --- INFO: epoch: 640, batch: 1, loss: 3.4100804328918457, modularity_loss: -0.6087167859077454, purity_loss: 3.9440858364105225, regularization_loss: 0.07471125572919846 # 11:36:47 --- INFO: epoch: 641, batch: 1, loss: 3.4097447395324707, modularity_loss: -0.6087149381637573, purity_loss: 3.9437484741210938, regularization_loss: 0.07471132278442383 # 11:36:48 --- INFO: epoch: 642, batch: 1, loss: 3.4094150066375732, modularity_loss: -0.6087134480476379, purity_loss: 3.9434168338775635, regularization_loss: 0.07471165060997009 # 11:36:48 --- INFO: epoch: 643, batch: 1, loss: 3.4090845584869385, modularity_loss: -0.6087138056755066, purity_loss: 3.9430863857269287, regularization_loss: 0.07471201568841934 # 11:36:48 --- INFO: epoch: 644, batch: 1, loss: 3.4087586402893066, modularity_loss: -0.6087148785591125, purity_loss: 3.942761182785034, regularization_loss: 0.07471229135990143 # 11:36:49 --- INFO: epoch: 645, batch: 1, loss: 3.408432960510254, modularity_loss: -0.6087170839309692, purity_loss: 3.9424374103546143, regularization_loss: 0.07471249252557755 # 11:36:49 --- INFO: epoch: 646, batch: 1, loss: 3.408106803894043, modularity_loss: -0.6087185144424438, purity_loss: 3.942112684249878, regularization_loss: 0.07471267879009247 # 11:36:49 --- INFO: epoch: 647, batch: 1, loss: 3.4077844619750977, modularity_loss: -0.6087194681167603, purity_loss: 3.94179105758667, regularization_loss: 0.07471282035112381 # 11:36:49 --- INFO: epoch: 648, batch: 1, loss: 3.4074599742889404, modularity_loss: -0.6087188720703125, purity_loss: 3.9414658546447754, regularization_loss: 0.07471293956041336 # 11:36:50 --- INFO: epoch: 649, batch: 1, loss: 3.4071412086486816, modularity_loss: -0.6087182760238647, purity_loss: 3.9411466121673584, regularization_loss: 0.07471296936273575 # 11:36:50 --- INFO: epoch: 650, batch: 1, loss: 3.4068222045898438, modularity_loss: -0.6087173223495483, purity_loss: 3.940826654434204, regularization_loss: 0.07471298426389694 # 11:36:50 --- INFO: epoch: 651, batch: 1, loss: 3.406503677368164, modularity_loss: -0.608717679977417, purity_loss: 3.9405081272125244, regularization_loss: 0.07471313327550888 # 11:36:51 --- INFO: epoch: 652, batch: 1, loss: 3.406187057495117, modularity_loss: -0.6087191700935364, purity_loss: 3.940192699432373, regularization_loss: 0.07471346110105515 # 11:36:51 --- INFO: epoch: 653, batch: 1, loss: 3.405871629714966, modularity_loss: -0.608721137046814, purity_loss: 3.9398789405822754, regularization_loss: 0.07471375167369843 # 11:36:51 --- INFO: epoch: 654, batch: 1, loss: 3.405555248260498, modularity_loss: -0.6087243556976318, purity_loss: 3.939565658569336, regularization_loss: 0.07471399009227753 # 11:36:51 --- INFO: epoch: 655, batch: 1, loss: 3.4052374362945557, modularity_loss: -0.6087278127670288, purity_loss: 3.939251184463501, regularization_loss: 0.07471403479576111 # 11:36:52 --- INFO: epoch: 656, batch: 1, loss: 3.404923915863037, modularity_loss: -0.6087294220924377, purity_loss: 3.938939332962036, regularization_loss: 0.07471392303705215 # 11:36:52 --- INFO: epoch: 657, batch: 1, loss: 3.4046080112457275, modularity_loss: -0.6087305545806885, purity_loss: 3.938624620437622, regularization_loss: 0.07471388578414917 # 11:36:52 --- INFO: epoch: 658, batch: 1, loss: 3.404294013977051, modularity_loss: -0.6087301969528198, purity_loss: 3.938310146331787, regularization_loss: 0.07471399754285812 # 11:36:53 --- INFO: epoch: 659, batch: 1, loss: 3.4039816856384277, modularity_loss: -0.6087299585342407, purity_loss: 3.937997579574585, regularization_loss: 0.07471414655447006 # 11:36:53 --- INFO: epoch: 660, batch: 1, loss: 3.4036686420440674, modularity_loss: -0.6087304353713989, purity_loss: 3.937685012817383, regularization_loss: 0.07471413165330887 # 11:36:53 --- INFO: epoch: 661, batch: 1, loss: 3.4033560752868652, modularity_loss: -0.6087322235107422, purity_loss: 3.9373741149902344, regularization_loss: 0.0747142806649208 # 11:36:54 --- INFO: epoch: 662, batch: 1, loss: 3.4030444622039795, modularity_loss: -0.6087340116500854, purity_loss: 3.937063694000244, regularization_loss: 0.07471473515033722 # 11:36:54 --- INFO: epoch: 663, batch: 1, loss: 3.4027369022369385, modularity_loss: -0.6087347269058228, purity_loss: 3.9367563724517822, regularization_loss: 0.07471530884504318 # 11:36:54 --- INFO: epoch: 664, batch: 1, loss: 3.4024248123168945, modularity_loss: -0.6087340712547302, purity_loss: 3.9364430904388428, regularization_loss: 0.07471586018800735 # 11:36:55 --- INFO: epoch: 665, batch: 1, loss: 3.402114152908325, modularity_loss: -0.6087313890457153, purity_loss: 3.936129331588745, regularization_loss: 0.07471615821123123 # 11:36:55 --- INFO: epoch: 666, batch: 1, loss: 3.4018073081970215, modularity_loss: -0.6087266206741333, purity_loss: 3.9358177185058594, regularization_loss: 0.07471610605716705 # 11:36:55 --- INFO: epoch: 667, batch: 1, loss: 3.401498556137085, modularity_loss: -0.6087207794189453, purity_loss: 3.9355034828186035, regularization_loss: 0.07471592724323273 # 11:36:56 --- INFO: epoch: 668, batch: 1, loss: 3.4011902809143066, modularity_loss: -0.6087154150009155, purity_loss: 3.935189962387085, regularization_loss: 0.0747157633304596 # 11:36:56 --- INFO: epoch: 669, batch: 1, loss: 3.4008853435516357, modularity_loss: -0.6087104082107544, purity_loss: 3.934880256652832, regularization_loss: 0.07471555471420288 # 11:36:56 --- INFO: epoch: 670, batch: 1, loss: 3.4005777835845947, modularity_loss: -0.6087072491645813, purity_loss: 3.9345695972442627, regularization_loss: 0.07471540570259094 # 11:36:56 --- INFO: epoch: 671, batch: 1, loss: 3.4002740383148193, modularity_loss: -0.6087055206298828, purity_loss: 3.9342641830444336, regularization_loss: 0.07471542060375214 # 11:36:57 --- INFO: epoch: 672, batch: 1, loss: 3.399968385696411, modularity_loss: -0.6087043285369873, purity_loss: 3.933957099914551, regularization_loss: 0.07471569627523422 # 11:36:57 --- INFO: epoch: 673, batch: 1, loss: 3.399667501449585, modularity_loss: -0.6087037324905396, purity_loss: 3.933655023574829, regularization_loss: 0.07471621036529541 # 11:36:57 --- INFO: epoch: 674, batch: 1, loss: 3.3993635177612305, modularity_loss: -0.6087017059326172, purity_loss: 3.9333484172821045, regularization_loss: 0.07471665740013123 # 11:36:58 --- INFO: epoch: 675, batch: 1, loss: 3.399059295654297, modularity_loss: -0.608698308467865, purity_loss: 3.9330408573150635, regularization_loss: 0.07471680641174316 # 11:36:58 --- INFO: epoch: 676, batch: 1, loss: 3.3987560272216797, modularity_loss: -0.6086939573287964, purity_loss: 3.9327330589294434, regularization_loss: 0.07471685111522675 # 11:36:58 --- INFO: epoch: 677, batch: 1, loss: 3.398449420928955, modularity_loss: -0.6086899042129517, purity_loss: 3.932422399520874, regularization_loss: 0.07471691817045212 # 11:36:59 --- INFO: epoch: 678, batch: 1, loss: 3.3981475830078125, modularity_loss: -0.6086863875389099, purity_loss: 3.932116985321045, regularization_loss: 0.07471710443496704 # 11:36:59 --- INFO: epoch: 679, batch: 1, loss: 3.397845506668091, modularity_loss: -0.6086824536323547, purity_loss: 3.9318106174468994, regularization_loss: 0.07471736520528793 # 11:36:59 --- INFO: epoch: 680, batch: 1, loss: 3.3975448608398438, modularity_loss: -0.6086785197257996, purity_loss: 3.9315059185028076, regularization_loss: 0.07471759617328644 # 11:37:00 --- INFO: epoch: 681, batch: 1, loss: 3.3972411155700684, modularity_loss: -0.6086742281913757, purity_loss: 3.931197166442871, regularization_loss: 0.07471803575754166 # 11:37:00 --- INFO: epoch: 682, batch: 1, loss: 3.396941661834717, modularity_loss: -0.6086704134941101, purity_loss: 3.9308934211730957, regularization_loss: 0.0747186616063118 # 11:37:00 --- INFO: epoch: 683, batch: 1, loss: 3.3966407775878906, modularity_loss: -0.6086674928665161, purity_loss: 3.930589199066162, regularization_loss: 0.07471922039985657 # 11:37:01 --- INFO: epoch: 684, batch: 1, loss: 3.396338939666748, modularity_loss: -0.6086655259132385, purity_loss: 3.9302852153778076, regularization_loss: 0.0747193694114685 # 11:37:01 --- INFO: epoch: 685, batch: 1, loss: 3.3960366249084473, modularity_loss: -0.6086630821228027, purity_loss: 3.929980516433716, regularization_loss: 0.07471917569637299 # 11:37:01 --- INFO: epoch: 686, batch: 1, loss: 3.395739793777466, modularity_loss: -0.6086611747741699, purity_loss: 3.9296820163726807, regularization_loss: 0.0747189074754715 # 11:37:01 --- INFO: epoch: 687, batch: 1, loss: 3.3954405784606934, modularity_loss: -0.6086595058441162, purity_loss: 3.9293811321258545, regularization_loss: 0.0747188851237297 # 11:37:02 --- INFO: epoch: 688, batch: 1, loss: 3.395142078399658, modularity_loss: -0.608657717704773, purity_loss: 3.9290807247161865, regularization_loss: 0.07471900433301926 # 11:37:02 --- INFO: epoch: 689, batch: 1, loss: 3.394845724105835, modularity_loss: -0.6086556315422058, purity_loss: 3.9287824630737305, regularization_loss: 0.07471895962953568 # 11:37:02 --- INFO: epoch: 690, batch: 1, loss: 3.3945441246032715, modularity_loss: -0.60865318775177, purity_loss: 3.928478479385376, regularization_loss: 0.07471881061792374 # 11:37:03 --- INFO: epoch: 691, batch: 1, loss: 3.3942506313323975, modularity_loss: -0.6086512804031372, purity_loss: 3.928183078765869, regularization_loss: 0.07471885532140732 # 11:37:03 --- INFO: epoch: 692, batch: 1, loss: 3.393951654434204, modularity_loss: -0.608650803565979, purity_loss: 3.9278831481933594, regularization_loss: 0.07471923530101776 # 11:37:03 --- INFO: epoch: 693, batch: 1, loss: 3.3936567306518555, modularity_loss: -0.6086493134498596, purity_loss: 3.927586555480957, regularization_loss: 0.07471950352191925 # 11:37:04 --- INFO: epoch: 694, batch: 1, loss: 3.3933615684509277, modularity_loss: -0.608647882938385, purity_loss: 3.9272899627685547, regularization_loss: 0.07471954822540283 # 11:37:04 --- INFO: epoch: 695, batch: 1, loss: 3.3930654525756836, modularity_loss: -0.6086455583572388, purity_loss: 3.9269917011260986, regularization_loss: 0.0747193992137909 # 11:37:04 --- INFO: epoch: 696, batch: 1, loss: 3.392773151397705, modularity_loss: -0.6086423397064209, purity_loss: 3.926696300506592, regularization_loss: 0.07471930980682373 # 11:37:05 --- INFO: epoch: 697, batch: 1, loss: 3.392482280731201, modularity_loss: -0.6086400747299194, purity_loss: 3.9264028072357178, regularization_loss: 0.07471951842308044 # 11:37:05 --- INFO: epoch: 698, batch: 1, loss: 3.3921918869018555, modularity_loss: -0.6086380481719971, purity_loss: 3.92611026763916, regularization_loss: 0.07471972703933716 # 11:37:05 --- INFO: epoch: 699, batch: 1, loss: 3.391902446746826, modularity_loss: -0.6086361408233643, purity_loss: 3.925818681716919, regularization_loss: 0.07471977919340134 # 11:37:05 --- INFO: epoch: 700, batch: 1, loss: 3.3916144371032715, modularity_loss: -0.6086333394050598, purity_loss: 3.925528049468994, regularization_loss: 0.0747196301817894 # 11:37:06 --- INFO: epoch: 701, batch: 1, loss: 3.391327381134033, modularity_loss: -0.608630895614624, purity_loss: 3.925238609313965, regularization_loss: 0.07471958547830582 # 11:37:06 --- INFO: epoch: 702, batch: 1, loss: 3.3910417556762695, modularity_loss: -0.6086287498474121, purity_loss: 3.9249510765075684, regularization_loss: 0.07471953332424164 # 11:37:06 --- INFO: epoch: 703, batch: 1, loss: 3.3907575607299805, modularity_loss: -0.6086267828941345, purity_loss: 3.9246649742126465, regularization_loss: 0.07471925765275955 # 11:37:07 --- INFO: epoch: 704, batch: 1, loss: 3.390472888946533, modularity_loss: -0.6086251735687256, purity_loss: 3.9243791103363037, regularization_loss: 0.07471885532140732 # 11:37:07 --- INFO: epoch: 705, batch: 1, loss: 3.390190362930298, modularity_loss: -0.6086251139640808, purity_loss: 3.9240968227386475, regularization_loss: 0.07471857964992523 # 11:37:07 --- INFO: epoch: 706, batch: 1, loss: 3.3899097442626953, modularity_loss: -0.6086257100105286, purity_loss: 3.9238169193267822, regularization_loss: 0.0747186467051506 # 11:37:08 --- INFO: epoch: 707, batch: 1, loss: 3.3896307945251465, modularity_loss: -0.6086264848709106, purity_loss: 3.9235382080078125, regularization_loss: 0.07471904158592224 # 11:37:08 --- INFO: epoch: 708, batch: 1, loss: 3.389353036880493, modularity_loss: -0.6086269021034241, purity_loss: 3.923260450363159, regularization_loss: 0.07471946626901627 # 11:37:08 --- INFO: epoch: 709, batch: 1, loss: 3.38907527923584, modularity_loss: -0.6086262464523315, purity_loss: 3.9229817390441895, regularization_loss: 0.07471976429224014 # 11:37:09 --- INFO: epoch: 710, batch: 1, loss: 3.388794422149658, modularity_loss: -0.6086249947547913, purity_loss: 3.922699451446533, regularization_loss: 0.07472008466720581 # 11:37:09 --- INFO: epoch: 711, batch: 1, loss: 3.3885152339935303, modularity_loss: -0.6086239814758301, purity_loss: 3.9224188327789307, regularization_loss: 0.0747203528881073 # 11:37:09 --- INFO: epoch: 712, batch: 1, loss: 3.3882429599761963, modularity_loss: -0.6086227893829346, purity_loss: 3.922145366668701, regularization_loss: 0.07472046464681625 # 11:37:09 --- INFO: epoch: 713, batch: 1, loss: 3.3879714012145996, modularity_loss: -0.6086219549179077, purity_loss: 3.921872854232788, regularization_loss: 0.07472041994333267 # 11:37:10 --- INFO: epoch: 714, batch: 1, loss: 3.3877007961273193, modularity_loss: -0.6086221933364868, purity_loss: 3.921602725982666, regularization_loss: 0.07472028583288193 # 11:37:10 --- INFO: epoch: 715, batch: 1, loss: 3.387432336807251, modularity_loss: -0.6086224317550659, purity_loss: 3.9213345050811768, regularization_loss: 0.07472030073404312 # 11:37:10 --- INFO: epoch: 716, batch: 1, loss: 3.387162446975708, modularity_loss: -0.6086228489875793, purity_loss: 3.921064853668213, regularization_loss: 0.07472050189971924 # 11:37:11 --- INFO: epoch: 717, batch: 1, loss: 3.3868978023529053, modularity_loss: -0.6086224317550659, purity_loss: 3.920799493789673, regularization_loss: 0.07472069561481476 # 11:37:11 --- INFO: epoch: 718, batch: 1, loss: 3.38663387298584, modularity_loss: -0.6086207628250122, purity_loss: 3.9205338954925537, regularization_loss: 0.07472078502178192 # 11:37:11 --- INFO: epoch: 719, batch: 1, loss: 3.3863699436187744, modularity_loss: -0.608618974685669, purity_loss: 3.9202682971954346, regularization_loss: 0.0747205838561058 # 11:37:12 --- INFO: epoch: 720, batch: 1, loss: 3.386107921600342, modularity_loss: -0.608617901802063, purity_loss: 3.9200053215026855, regularization_loss: 0.07472046464681625 # 11:37:12 --- INFO: epoch: 721, batch: 1, loss: 3.3858487606048584, modularity_loss: -0.6086181402206421, purity_loss: 3.9197463989257812, regularization_loss: 0.07472053170204163 # 11:37:12 --- INFO: epoch: 722, batch: 1, loss: 3.385589599609375, modularity_loss: -0.6086193323135376, purity_loss: 3.9194881916046143, regularization_loss: 0.07472065091133118 # 11:37:12 --- INFO: epoch: 723, batch: 1, loss: 3.385335922241211, modularity_loss: -0.6086205244064331, purity_loss: 3.9192357063293457, regularization_loss: 0.07472066581249237 # 11:37:13 --- INFO: epoch: 724, batch: 1, loss: 3.3850817680358887, modularity_loss: -0.6086221933364868, purity_loss: 3.918982982635498, regularization_loss: 0.0747208446264267 # 11:37:13 --- INFO: epoch: 725, batch: 1, loss: 3.384828805923462, modularity_loss: -0.6086236834526062, purity_loss: 3.918731212615967, regularization_loss: 0.0747213140130043 # 11:37:13 --- INFO: epoch: 726, batch: 1, loss: 3.3845765590667725, modularity_loss: -0.6086239814758301, purity_loss: 3.9184789657592773, regularization_loss: 0.07472165673971176 # 11:37:14 --- INFO: epoch: 727, batch: 1, loss: 3.3843271732330322, modularity_loss: -0.6086238622665405, purity_loss: 3.918229341506958, regularization_loss: 0.07472165673971176 # 11:37:14 --- INFO: epoch: 728, batch: 1, loss: 3.3840792179107666, modularity_loss: -0.6086242198944092, purity_loss: 3.9179821014404297, regularization_loss: 0.07472139596939087 # 11:37:14 --- INFO: epoch: 729, batch: 1, loss: 3.3838346004486084, modularity_loss: -0.6086263656616211, purity_loss: 3.9177398681640625, regularization_loss: 0.0747210681438446 # 11:37:15 --- INFO: epoch: 730, batch: 1, loss: 3.3835926055908203, modularity_loss: -0.6086296439170837, purity_loss: 3.917501449584961, regularization_loss: 0.0747208297252655 # 11:37:15 --- INFO: epoch: 731, batch: 1, loss: 3.3833510875701904, modularity_loss: -0.608633279800415, purity_loss: 3.9172637462615967, regularization_loss: 0.07472065836191177 # 11:37:15 --- INFO: epoch: 732, batch: 1, loss: 3.3831124305725098, modularity_loss: -0.6086359024047852, purity_loss: 3.917027711868286, regularization_loss: 0.07472063601016998 # 11:37:15 --- INFO: epoch: 733, batch: 1, loss: 3.382878065109253, modularity_loss: -0.6086368560791016, purity_loss: 3.9167940616607666, regularization_loss: 0.07472086697816849 # 11:37:16 --- INFO: epoch: 734, batch: 1, loss: 3.382638931274414, modularity_loss: -0.6086379289627075, purity_loss: 3.916555643081665, regularization_loss: 0.07472129166126251 # 11:37:16 --- INFO: epoch: 735, batch: 1, loss: 3.382408618927002, modularity_loss: -0.6086374521255493, purity_loss: 3.9163243770599365, regularization_loss: 0.07472161948680878 # 11:37:16 --- INFO: epoch: 736, batch: 1, loss: 3.3821797370910645, modularity_loss: -0.608637273311615, purity_loss: 3.916095495223999, regularization_loss: 0.07472164183855057 # 11:37:17 --- INFO: epoch: 737, batch: 1, loss: 3.381951332092285, modularity_loss: -0.6086390614509583, purity_loss: 3.9158689975738525, regularization_loss: 0.07472144067287445 # 11:37:17 --- INFO: epoch: 738, batch: 1, loss: 3.381723403930664, modularity_loss: -0.6086426973342896, purity_loss: 3.915644884109497, regularization_loss: 0.07472117990255356 # 11:37:17 --- INFO: epoch: 739, batch: 1, loss: 3.3814990520477295, modularity_loss: -0.6086472272872925, purity_loss: 3.9154253005981445, regularization_loss: 0.07472096383571625 # 11:37:18 --- INFO: epoch: 740, batch: 1, loss: 3.381277561187744, modularity_loss: -0.6086505651473999, purity_loss: 3.9152073860168457, regularization_loss: 0.07472078502178192 # 11:37:18 --- INFO: epoch: 741, batch: 1, loss: 3.3810572624206543, modularity_loss: -0.6086528301239014, purity_loss: 3.914989471435547, regularization_loss: 0.07472071796655655 # 11:37:18 --- INFO: epoch: 742, batch: 1, loss: 3.38084077835083, modularity_loss: -0.6086551547050476, purity_loss: 3.9147748947143555, regularization_loss: 0.07472089678049088 # 11:37:18 --- INFO: epoch: 743, batch: 1, loss: 3.3806259632110596, modularity_loss: -0.6086583137512207, purity_loss: 3.914562940597534, regularization_loss: 0.07472134381532669 # 11:37:19 --- INFO: epoch: 744, batch: 1, loss: 3.3804121017456055, modularity_loss: -0.6086623668670654, purity_loss: 3.9143528938293457, regularization_loss: 0.07472160458564758 # 11:37:19 --- INFO: epoch: 745, batch: 1, loss: 3.380201816558838, modularity_loss: -0.6086667776107788, purity_loss: 3.914146900177002, regularization_loss: 0.07472165673971176 # 11:37:19 --- INFO: epoch: 746, batch: 1, loss: 3.379990339279175, modularity_loss: -0.6086707711219788, purity_loss: 3.9139394760131836, regularization_loss: 0.07472170144319534 # 11:37:20 --- INFO: epoch: 747, batch: 1, loss: 3.3797826766967773, modularity_loss: -0.6086737513542175, purity_loss: 3.9137344360351562, regularization_loss: 0.07472185045480728 # 11:37:20 --- INFO: epoch: 748, batch: 1, loss: 3.3795764446258545, modularity_loss: -0.6086753606796265, purity_loss: 3.913529872894287, regularization_loss: 0.07472192496061325 # 11:37:20 --- INFO: epoch: 749, batch: 1, loss: 3.3793721199035645, modularity_loss: -0.6086761355400085, purity_loss: 3.9133262634277344, regularization_loss: 0.07472185045480728 # 11:37:21 --- INFO: epoch: 750, batch: 1, loss: 3.3791720867156982, modularity_loss: -0.6086779832839966, purity_loss: 3.91312837600708, regularization_loss: 0.07472176104784012 # 11:37:21 --- INFO: epoch: 751, batch: 1, loss: 3.3789730072021484, modularity_loss: -0.6086809635162354, purity_loss: 3.9129321575164795, regularization_loss: 0.07472184300422668 # 11:37:21 --- INFO: epoch: 752, batch: 1, loss: 3.3787708282470703, modularity_loss: -0.6086852550506592, purity_loss: 3.912734270095825, regularization_loss: 0.07472191751003265 # 11:37:21 --- INFO: epoch: 753, batch: 1, loss: 3.378572702407837, modularity_loss: -0.6086894273757935, purity_loss: 3.9125401973724365, regularization_loss: 0.07472185045480728 # 11:37:22 --- INFO: epoch: 754, batch: 1, loss: 3.3783771991729736, modularity_loss: -0.6086921691894531, purity_loss: 3.9123475551605225, regularization_loss: 0.07472173869609833 # 11:37:22 --- INFO: epoch: 755, batch: 1, loss: 3.3781824111938477, modularity_loss: -0.6086947917938232, purity_loss: 3.9121556282043457, regularization_loss: 0.074721559882164 # 11:37:22 --- INFO: epoch: 756, batch: 1, loss: 3.3779866695404053, modularity_loss: -0.6086962819099426, purity_loss: 3.911961555480957, regularization_loss: 0.07472142577171326 # 11:37:23 --- INFO: epoch: 757, batch: 1, loss: 3.3777947425842285, modularity_loss: -0.6086974143981934, purity_loss: 3.911770820617676, regularization_loss: 0.07472137361764908 # 11:37:23 --- INFO: epoch: 758, batch: 1, loss: 3.377608060836792, modularity_loss: -0.6086984872817993, purity_loss: 3.9115853309631348, regularization_loss: 0.07472129166126251 # 11:37:23 --- INFO: epoch: 759, batch: 1, loss: 3.3774170875549316, modularity_loss: -0.6086995601654053, purity_loss: 3.911395311355591, regularization_loss: 0.07472124695777893 # 11:37:24 --- INFO: epoch: 760, batch: 1, loss: 3.377230167388916, modularity_loss: -0.6086998581886292, purity_loss: 3.9112091064453125, regularization_loss: 0.07472096383571625 # 11:37:24 --- INFO: epoch: 761, batch: 1, loss: 3.377042293548584, modularity_loss: -0.608700156211853, purity_loss: 3.9110217094421387, regularization_loss: 0.07472078502178192 # 11:37:24 --- INFO: epoch: 762, batch: 1, loss: 3.3768577575683594, modularity_loss: -0.6087008714675903, purity_loss: 3.9108376502990723, regularization_loss: 0.0747208446264267 # 11:37:24 --- INFO: epoch: 763, batch: 1, loss: 3.376673698425293, modularity_loss: -0.6087024211883545, purity_loss: 3.9106552600860596, regularization_loss: 0.07472086697816849 # 11:37:25 --- INFO: epoch: 764, batch: 1, loss: 3.376494884490967, modularity_loss: -0.6087031364440918, purity_loss: 3.91047739982605, regularization_loss: 0.07472074776887894 # 11:37:25 --- INFO: epoch: 765, batch: 1, loss: 3.3763132095336914, modularity_loss: -0.6087043285369873, purity_loss: 3.910296678543091, regularization_loss: 0.07472091913223267 # 11:37:25 --- INFO: epoch: 766, batch: 1, loss: 3.376133680343628, modularity_loss: -0.6087051630020142, purity_loss: 3.9101176261901855, regularization_loss: 0.07472129911184311 # 11:37:26 --- INFO: epoch: 767, batch: 1, loss: 3.375957489013672, modularity_loss: -0.6087040305137634, purity_loss: 3.909940004348755, regularization_loss: 0.07472151517868042 # 11:37:26 --- INFO: epoch: 768, batch: 1, loss: 3.3757801055908203, modularity_loss: -0.6087014675140381, purity_loss: 3.9097602367401123, regularization_loss: 0.07472142577171326 # 11:37:26 --- INFO: epoch: 769, batch: 1, loss: 3.375605821609497, modularity_loss: -0.6086981296539307, purity_loss: 3.9095826148986816, regularization_loss: 0.07472129166126251 # 11:37:27 --- INFO: epoch: 770, batch: 1, loss: 3.3754348754882812, modularity_loss: -0.6086962223052979, purity_loss: 3.909409761428833, regularization_loss: 0.07472126185894012 # 11:37:27 --- INFO: epoch: 771, batch: 1, loss: 3.3752622604370117, modularity_loss: -0.6086959838867188, purity_loss: 3.9092373847961426, regularization_loss: 0.07472093403339386 # 11:37:27 --- INFO: epoch: 772, batch: 1, loss: 3.375091552734375, modularity_loss: -0.6086970567703247, purity_loss: 3.9090678691864014, regularization_loss: 0.07472062855958939 # 11:37:27 --- INFO: epoch: 773, batch: 1, loss: 3.3749241828918457, modularity_loss: -0.608698844909668, purity_loss: 3.908902406692505, regularization_loss: 0.07472056895494461 # 11:37:28 --- INFO: epoch: 774, batch: 1, loss: 3.374755859375, modularity_loss: -0.6087007522583008, purity_loss: 3.908735990524292, regularization_loss: 0.07472071796655655 # 11:37:28 --- INFO: epoch: 775, batch: 1, loss: 3.3745923042297363, modularity_loss: -0.6087013483047485, purity_loss: 3.9085726737976074, regularization_loss: 0.07472091913223267 # 11:37:28 --- INFO: epoch: 776, batch: 1, loss: 3.3744232654571533, modularity_loss: -0.6087007522583008, purity_loss: 3.908402919769287, regularization_loss: 0.07472109794616699 # 11:37:29 --- INFO: epoch: 777, batch: 1, loss: 3.374260902404785, modularity_loss: -0.608699381351471, purity_loss: 3.9082393646240234, regularization_loss: 0.07472093403339386 # 11:37:29 --- INFO: epoch: 778, batch: 1, loss: 3.3740997314453125, modularity_loss: -0.6086994409561157, purity_loss: 3.90807843208313, regularization_loss: 0.0747208297252655 # 11:37:29 --- INFO: epoch: 779, batch: 1, loss: 3.3739380836486816, modularity_loss: -0.608701229095459, purity_loss: 3.9079184532165527, regularization_loss: 0.07472071796655655 # 11:37:29 --- INFO: epoch: 780, batch: 1, loss: 3.373779773712158, modularity_loss: -0.6087039709091187, purity_loss: 3.9077632427215576, regularization_loss: 0.07472056895494461 # 11:37:30 --- INFO: epoch: 781, batch: 1, loss: 3.373619556427002, modularity_loss: -0.608706533908844, purity_loss: 3.9076056480407715, regularization_loss: 0.07472051680088043 # 11:37:30 --- INFO: epoch: 782, batch: 1, loss: 3.3734633922576904, modularity_loss: -0.6087087392807007, purity_loss: 3.9074513912200928, regularization_loss: 0.07472073286771774 # 11:37:30 --- INFO: epoch: 783, batch: 1, loss: 3.373309373855591, modularity_loss: -0.6087095737457275, purity_loss: 3.9072978496551514, regularization_loss: 0.07472101598978043 # 11:37:31 --- INFO: epoch: 784, batch: 1, loss: 3.373154401779175, modularity_loss: -0.6087086796760559, purity_loss: 3.907142162322998, regularization_loss: 0.07472088187932968 # 11:37:31 --- INFO: epoch: 785, batch: 1, loss: 3.372997999191284, modularity_loss: -0.6087080240249634, purity_loss: 3.906985282897949, regularization_loss: 0.07472073286771774 # 11:37:31 --- INFO: epoch: 786, batch: 1, loss: 3.3728485107421875, modularity_loss: -0.6087089776992798, purity_loss: 3.906836748123169, regularization_loss: 0.0747205913066864 # 11:37:31 --- INFO: epoch: 787, batch: 1, loss: 3.37269926071167, modularity_loss: -0.6087101697921753, purity_loss: 3.906688928604126, regularization_loss: 0.07472040504217148 # 11:37:32 --- INFO: epoch: 788, batch: 1, loss: 3.3725497722625732, modularity_loss: -0.6087112426757812, purity_loss: 3.906540632247925, regularization_loss: 0.0747203379869461 # 11:37:32 --- INFO: epoch: 789, batch: 1, loss: 3.372401237487793, modularity_loss: -0.6087126731872559, purity_loss: 3.906393527984619, regularization_loss: 0.07472032308578491 # 11:37:32 --- INFO: epoch: 790, batch: 1, loss: 3.372250556945801, modularity_loss: -0.6087139844894409, purity_loss: 3.9062440395355225, regularization_loss: 0.07472048699855804 # 11:37:33 --- INFO: epoch: 791, batch: 1, loss: 3.3721022605895996, modularity_loss: -0.6087154746055603, purity_loss: 3.906097173690796, regularization_loss: 0.07472061365842819 # 11:37:33 --- INFO: epoch: 792, batch: 1, loss: 3.3719561100006104, modularity_loss: -0.6087169647216797, purity_loss: 3.9059524536132812, regularization_loss: 0.07472064346075058 # 11:37:33 --- INFO: epoch: 793, batch: 1, loss: 3.3718109130859375, modularity_loss: -0.6087177991867065, purity_loss: 3.905808210372925, regularization_loss: 0.07472051680088043 # 11:37:34 --- INFO: epoch: 794, batch: 1, loss: 3.37166690826416, modularity_loss: -0.6087191104888916, purity_loss: 3.905665874481201, regularization_loss: 0.07472027093172073 # 11:37:34 --- INFO: epoch: 795, batch: 1, loss: 3.371525764465332, modularity_loss: -0.6087210774421692, purity_loss: 3.905526638031006, regularization_loss: 0.07472021877765656 # 11:37:34 --- INFO: epoch: 796, batch: 1, loss: 3.371382236480713, modularity_loss: -0.6087223291397095, purity_loss: 3.9053843021392822, regularization_loss: 0.07472039759159088 # 11:37:34 --- INFO: epoch: 797, batch: 1, loss: 3.371239423751831, modularity_loss: -0.6087222099304199, purity_loss: 3.9052412509918213, regularization_loss: 0.07472032308578491 # 11:37:35 --- INFO: epoch: 798, batch: 1, loss: 3.3710997104644775, modularity_loss: -0.6087217926979065, purity_loss: 3.9051010608673096, regularization_loss: 0.07472048699855804 # 11:37:35 --- INFO: epoch: 799, batch: 1, loss: 3.3709588050842285, modularity_loss: -0.6087220907211304, purity_loss: 3.9049599170684814, regularization_loss: 0.07472088187932968 # 11:37:35 --- INFO: epoch: 800, batch: 1, loss: 3.370821475982666, modularity_loss: -0.6087215542793274, purity_loss: 3.9048221111297607, regularization_loss: 0.07472094893455505 # 11:37:36 --- INFO: epoch: 801, batch: 1, loss: 3.370682716369629, modularity_loss: -0.6087210178375244, purity_loss: 3.9046831130981445, regularization_loss: 0.07472068071365356 # 11:37:36 --- INFO: epoch: 802, batch: 1, loss: 3.37054443359375, modularity_loss: -0.608720064163208, purity_loss: 3.9045441150665283, regularization_loss: 0.07472044974565506 # 11:37:36 --- INFO: epoch: 803, batch: 1, loss: 3.370408296585083, modularity_loss: -0.6087198257446289, purity_loss: 3.9044077396392822, regularization_loss: 0.07472046464681625 # 11:37:37 --- INFO: epoch: 804, batch: 1, loss: 3.3702731132507324, modularity_loss: -0.6087179780006409, purity_loss: 3.904270648956299, regularization_loss: 0.07472040504217148 # 11:37:37 --- INFO: epoch: 805, batch: 1, loss: 3.370136022567749, modularity_loss: -0.6087155938148499, purity_loss: 3.9041314125061035, regularization_loss: 0.07472021877765656 # 11:37:37 --- INFO: epoch: 806, batch: 1, loss: 3.370004415512085, modularity_loss: -0.6087132096290588, purity_loss: 3.9039974212646484, regularization_loss: 0.07472027093172073 # 11:37:37 --- INFO: epoch: 807, batch: 1, loss: 3.3698718547821045, modularity_loss: -0.6087116003036499, purity_loss: 3.903862953186035, regularization_loss: 0.07472051680088043 # 11:37:38 --- INFO: epoch: 808, batch: 1, loss: 3.3697381019592285, modularity_loss: -0.6087098717689514, purity_loss: 3.9037275314331055, regularization_loss: 0.0747205913066864 # 11:37:38 --- INFO: epoch: 809, batch: 1, loss: 3.3696084022521973, modularity_loss: -0.6087083220481873, purity_loss: 3.9035964012145996, regularization_loss: 0.07472043484449387 # 11:37:38 --- INFO: epoch: 810, batch: 1, loss: 3.3694772720336914, modularity_loss: -0.6087076663970947, purity_loss: 3.9034645557403564, regularization_loss: 0.0747203677892685 # 11:37:39 --- INFO: epoch: 811, batch: 1, loss: 3.3693482875823975, modularity_loss: -0.6087066531181335, purity_loss: 3.903334617614746, regularization_loss: 0.0747203528881073 # 11:37:39 --- INFO: epoch: 812, batch: 1, loss: 3.36921763420105, modularity_loss: -0.6087048053741455, purity_loss: 3.9032022953033447, regularization_loss: 0.07472015917301178 # 11:37:39 --- INFO: epoch: 813, batch: 1, loss: 3.3690872192382812, modularity_loss: -0.6087033152580261, purity_loss: 3.9030704498291016, regularization_loss: 0.07471994310617447 # 11:37:40 --- INFO: epoch: 814, batch: 1, loss: 3.36896014213562, modularity_loss: -0.608702540397644, purity_loss: 3.902942657470703, regularization_loss: 0.07471997290849686 # 11:37:40 --- INFO: epoch: 815, batch: 1, loss: 3.368832588195801, modularity_loss: -0.6087023019790649, purity_loss: 3.9028146266937256, regularization_loss: 0.07472013682126999 # 11:37:40 --- INFO: epoch: 816, batch: 1, loss: 3.3687071800231934, modularity_loss: -0.6087015867233276, purity_loss: 3.902688503265381, regularization_loss: 0.0747201219201088 # 11:37:40 --- INFO: epoch: 817, batch: 1, loss: 3.368579387664795, modularity_loss: -0.6087002754211426, purity_loss: 3.902559757232666, regularization_loss: 0.07471991330385208 # 11:37:41 --- INFO: epoch: 818, batch: 1, loss: 3.368454933166504, modularity_loss: -0.6086994409561157, purity_loss: 3.9024345874786377, regularization_loss: 0.07471971213817596 # 11:37:41 --- INFO: epoch: 819, batch: 1, loss: 3.368333339691162, modularity_loss: -0.6086984276771545, purity_loss: 3.9023122787475586, regularization_loss: 0.0747196301817894 # 11:37:41 --- INFO: epoch: 820, batch: 1, loss: 3.368211030960083, modularity_loss: -0.6086968183517456, purity_loss: 3.902188301086426, regularization_loss: 0.07471960037946701 # 11:37:42 --- INFO: epoch: 821, batch: 1, loss: 3.368088722229004, modularity_loss: -0.6086952686309814, purity_loss: 3.902064323425293, regularization_loss: 0.0747196227312088 # 11:37:42 --- INFO: epoch: 822, batch: 1, loss: 3.3679676055908203, modularity_loss: -0.6086933612823486, purity_loss: 3.9019412994384766, regularization_loss: 0.07471977919340134 # 11:37:42 --- INFO: epoch: 823, batch: 1, loss: 3.367844343185425, modularity_loss: -0.6086910963058472, purity_loss: 3.901815414428711, regularization_loss: 0.07472006976604462 # 11:37:43 --- INFO: epoch: 824, batch: 1, loss: 3.367724895477295, modularity_loss: -0.6086887121200562, purity_loss: 3.901693344116211, regularization_loss: 0.07472028583288193 # 11:37:43 --- INFO: epoch: 825, batch: 1, loss: 3.367605447769165, modularity_loss: -0.6086865663528442, purity_loss: 3.901571750640869, regularization_loss: 0.07472020387649536 # 11:37:43 --- INFO: epoch: 826, batch: 1, loss: 3.367486000061035, modularity_loss: -0.6086844801902771, purity_loss: 3.9014506340026855, regularization_loss: 0.07471991330385208 # 11:37:43 --- INFO: epoch: 827, batch: 1, loss: 3.3673691749572754, modularity_loss: -0.6086835861206055, purity_loss: 3.9013330936431885, regularization_loss: 0.0747196227312088 # 11:37:44 --- INFO: epoch: 828, batch: 1, loss: 3.3672499656677246, modularity_loss: -0.6086843013763428, purity_loss: 3.901214838027954, regularization_loss: 0.0747193992137909 # 11:37:44 --- INFO: epoch: 829, batch: 1, loss: 3.3671350479125977, modularity_loss: -0.6086848378181458, purity_loss: 3.9011006355285645, regularization_loss: 0.0747193917632103 # 11:37:44 --- INFO: epoch: 830, batch: 1, loss: 3.367018699645996, modularity_loss: -0.6086846590042114, purity_loss: 3.9009838104248047, regularization_loss: 0.0747196152806282 # 11:37:45 --- INFO: epoch: 831, batch: 1, loss: 3.3669023513793945, modularity_loss: -0.6086817979812622, purity_loss: 3.900864362716675, regularization_loss: 0.07471993565559387 # 11:37:45 --- INFO: epoch: 832, batch: 1, loss: 3.366786241531372, modularity_loss: -0.6086785793304443, purity_loss: 3.900744676589966, regularization_loss: 0.07472006976604462 # 11:37:45 --- INFO: epoch: 833, batch: 1, loss: 3.366670846939087, modularity_loss: -0.6086764335632324, purity_loss: 3.900627374649048, regularization_loss: 0.07471989095211029 # 11:37:46 --- INFO: epoch: 834, batch: 1, loss: 3.3665590286254883, modularity_loss: -0.6086758971214294, purity_loss: 3.90051531791687, regularization_loss: 0.07471956312656403 # 11:37:46 --- INFO: epoch: 835, batch: 1, loss: 3.3664467334747314, modularity_loss: -0.6086772680282593, purity_loss: 3.900404691696167, regularization_loss: 0.07471925765275955 # 11:37:46 --- INFO: epoch: 836, batch: 1, loss: 3.366333484649658, modularity_loss: -0.6086784601211548, purity_loss: 3.9002928733825684, regularization_loss: 0.07471904903650284 # 11:37:46 --- INFO: epoch: 837, batch: 1, loss: 3.3662214279174805, modularity_loss: -0.6086785793304443, purity_loss: 3.9001808166503906, regularization_loss: 0.0747191533446312 # 11:37:47 --- INFO: epoch: 838, batch: 1, loss: 3.3661134243011475, modularity_loss: -0.6086772084236145, purity_loss: 3.900071144104004, regularization_loss: 0.07471956312656403 # 11:37:47 --- INFO: epoch: 839, batch: 1, loss: 3.3660027980804443, modularity_loss: -0.6086750030517578, purity_loss: 3.8999578952789307, regularization_loss: 0.0747198760509491 # 11:37:47 --- INFO: epoch: 840, batch: 1, loss: 3.365891456604004, modularity_loss: -0.6086729764938354, purity_loss: 3.8998444080352783, regularization_loss: 0.07471991330385208 # 11:37:48 --- INFO: epoch: 841, batch: 1, loss: 3.3657798767089844, modularity_loss: -0.6086714267730713, purity_loss: 3.899731397628784, regularization_loss: 0.07471980899572372 # 11:37:48 --- INFO: epoch: 842, batch: 1, loss: 3.3656721115112305, modularity_loss: -0.6086705923080444, purity_loss: 3.899623155593872, regularization_loss: 0.07471960783004761 # 11:37:48 --- INFO: epoch: 843, batch: 1, loss: 3.365560531616211, modularity_loss: -0.6086690425872803, purity_loss: 3.899510145187378, regularization_loss: 0.07471943646669388 # 11:37:49 --- INFO: epoch: 844, batch: 1, loss: 3.3654513359069824, modularity_loss: -0.6086664199829102, purity_loss: 3.8993983268737793, regularization_loss: 0.07471950352191925 # 11:37:49 --- INFO: epoch: 845, batch: 1, loss: 3.3653407096862793, modularity_loss: -0.6086632013320923, purity_loss: 3.8992841243743896, regularization_loss: 0.07471966743469238 # 11:37:49 --- INFO: epoch: 846, batch: 1, loss: 3.365234136581421, modularity_loss: -0.608659029006958, purity_loss: 3.8991734981536865, regularization_loss: 0.0747196301817894 # 11:37:50 --- INFO: epoch: 847, batch: 1, loss: 3.3651249408721924, modularity_loss: -0.6086568236351013, purity_loss: 3.899062156677246, regularization_loss: 0.0747196152806282 # 11:37:50 --- INFO: epoch: 848, batch: 1, loss: 3.365017890930176, modularity_loss: -0.6086575984954834, purity_loss: 3.898955821990967, regularization_loss: 0.07471958547830582 # 11:37:50 --- INFO: epoch: 849, batch: 1, loss: 3.3649096488952637, modularity_loss: -0.6086587905883789, purity_loss: 3.8988492488861084, regularization_loss: 0.07471923530101776 # 11:37:50 --- INFO: epoch: 850, batch: 1, loss: 3.364804744720459, modularity_loss: -0.6086594462394714, purity_loss: 3.89874529838562, regularization_loss: 0.07471877336502075 # 11:37:51 --- INFO: epoch: 851, batch: 1, loss: 3.3647005558013916, modularity_loss: -0.6086602210998535, purity_loss: 3.8986423015594482, regularization_loss: 0.07471855729818344 # 11:37:51 --- INFO: epoch: 852, batch: 1, loss: 3.3645946979522705, modularity_loss: -0.6086597442626953, purity_loss: 3.898535966873169, regularization_loss: 0.07471852749586105 # 11:37:51 --- INFO: epoch: 853, batch: 1, loss: 3.364490032196045, modularity_loss: -0.6086597442626953, purity_loss: 3.8984313011169434, regularization_loss: 0.07471845299005508 # 11:37:52 --- INFO: epoch: 854, batch: 1, loss: 3.3643879890441895, modularity_loss: -0.6086595058441162, purity_loss: 3.898329257965088, regularization_loss: 0.07471834868192673 # 11:37:52 --- INFO: epoch: 855, batch: 1, loss: 3.3642866611480713, modularity_loss: -0.6086603999137878, purity_loss: 3.898228645324707, regularization_loss: 0.07471837848424911 # 11:37:52 --- INFO: epoch: 856, batch: 1, loss: 3.3641834259033203, modularity_loss: -0.6086607575416565, purity_loss: 3.8981258869171143, regularization_loss: 0.0747184082865715 # 11:37:53 --- INFO: epoch: 857, batch: 1, loss: 3.3640835285186768, modularity_loss: -0.6086597442626953, purity_loss: 3.8980250358581543, regularization_loss: 0.07471821457147598 # 11:37:53 --- INFO: epoch: 858, batch: 1, loss: 3.3639824390411377, modularity_loss: -0.6086573600769043, purity_loss: 3.8979220390319824, regularization_loss: 0.07471783459186554 # 11:37:53 --- INFO: epoch: 859, batch: 1, loss: 3.363884449005127, modularity_loss: -0.6086558103561401, purity_loss: 3.897822618484497, regularization_loss: 0.07471772283315659 # 11:37:53 --- INFO: epoch: 860, batch: 1, loss: 3.363784074783325, modularity_loss: -0.6086548566818237, purity_loss: 3.897721290588379, regularization_loss: 0.07471761107444763 # 11:37:54 --- INFO: epoch: 861, batch: 1, loss: 3.3636832237243652, modularity_loss: -0.6086538434028625, purity_loss: 3.8976197242736816, regularization_loss: 0.07471734285354614 # 11:37:54 --- INFO: epoch: 862, batch: 1, loss: 3.363584518432617, modularity_loss: -0.6086530089378357, purity_loss: 3.897520065307617, regularization_loss: 0.07471734285354614 # 11:37:54 --- INFO: epoch: 863, batch: 1, loss: 3.363487720489502, modularity_loss: -0.6086521148681641, purity_loss: 3.8974220752716064, regularization_loss: 0.07471767067909241 # 11:37:55 --- INFO: epoch: 864, batch: 1, loss: 3.3633904457092285, modularity_loss: -0.6086492538452148, purity_loss: 3.897321939468384, regularization_loss: 0.07471783459186554 # 11:37:55 --- INFO: epoch: 865, batch: 1, loss: 3.363291025161743, modularity_loss: -0.6086451411247253, purity_loss: 3.8972184658050537, regularization_loss: 0.07471775263547897 # 11:37:55 --- INFO: epoch: 866, batch: 1, loss: 3.363197088241577, modularity_loss: -0.6086416244506836, purity_loss: 3.8971211910247803, regularization_loss: 0.07471756637096405 # 11:37:56 --- INFO: epoch: 867, batch: 1, loss: 3.3630990982055664, modularity_loss: -0.608640193939209, purity_loss: 3.897021770477295, regularization_loss: 0.07471758872270584 # 11:37:56 --- INFO: epoch: 868, batch: 1, loss: 3.363003969192505, modularity_loss: -0.608640193939209, purity_loss: 3.8969266414642334, regularization_loss: 0.07471749186515808 # 11:37:56 --- INFO: epoch: 869, batch: 1, loss: 3.3629074096679688, modularity_loss: -0.6086399555206299, purity_loss: 3.8968303203582764, regularization_loss: 0.07471711933612823 # 11:37:56 --- INFO: epoch: 870, batch: 1, loss: 3.362811803817749, modularity_loss: -0.6086399555206299, purity_loss: 3.8967349529266357, regularization_loss: 0.07471687346696854 # 11:37:57 --- INFO: epoch: 871, batch: 1, loss: 3.362717628479004, modularity_loss: -0.6086417436599731, purity_loss: 3.8966422080993652, regularization_loss: 0.07471714913845062 # 11:37:57 --- INFO: epoch: 872, batch: 1, loss: 3.362619638442993, modularity_loss: -0.6086426377296448, purity_loss: 3.896544933319092, regularization_loss: 0.07471726089715958 # 11:37:57 --- INFO: epoch: 873, batch: 1, loss: 3.362522602081299, modularity_loss: -0.6086419224739075, purity_loss: 3.8964476585388184, regularization_loss: 0.0747169554233551 # 11:37:58 --- INFO: epoch: 874, batch: 1, loss: 3.3624322414398193, modularity_loss: -0.6086419820785522, purity_loss: 3.896357536315918, regularization_loss: 0.07471676915884018 # 11:37:58 --- INFO: epoch: 875, batch: 1, loss: 3.362335205078125, modularity_loss: -0.608643651008606, purity_loss: 3.8962621688842773, regularization_loss: 0.07471683621406555 # 11:37:58 --- INFO: epoch: 876, batch: 1, loss: 3.3622403144836426, modularity_loss: -0.6086437702178955, purity_loss: 3.896167516708374, regularization_loss: 0.0747164860367775 # 11:37:58 --- INFO: epoch: 877, batch: 1, loss: 3.3621551990509033, modularity_loss: -0.6086429357528687, purity_loss: 3.8960821628570557, regularization_loss: 0.07471602410078049 # 11:37:59 --- INFO: epoch: 878, batch: 1, loss: 3.3620612621307373, modularity_loss: -0.6086430549621582, purity_loss: 3.8959882259368896, regularization_loss: 0.07471617311239243 # 11:37:59 --- INFO: epoch: 879, batch: 1, loss: 3.361969232559204, modularity_loss: -0.6086426973342896, purity_loss: 3.895895481109619, regularization_loss: 0.07471641898155212 # 11:37:59 --- INFO: epoch: 880, batch: 1, loss: 3.361877918243408, modularity_loss: -0.608640193939209, purity_loss: 3.8958020210266113, regularization_loss: 0.0747162401676178 # 11:38:00 --- INFO: epoch: 881, batch: 1, loss: 3.361787796020508, modularity_loss: -0.6086382865905762, purity_loss: 3.895709991455078, regularization_loss: 0.07471606880426407 # 11:38:00 --- INFO: epoch: 882, batch: 1, loss: 3.3616981506347656, modularity_loss: -0.6086363792419434, purity_loss: 3.895618438720703, regularization_loss: 0.07471617311239243 # 11:38:00 --- INFO: epoch: 883, batch: 1, loss: 3.3616058826446533, modularity_loss: -0.6086349487304688, purity_loss: 3.895524501800537, regularization_loss: 0.07471639662981033 # 11:38:01 --- INFO: epoch: 884, batch: 1, loss: 3.361515522003174, modularity_loss: -0.6086326837539673, purity_loss: 3.8954317569732666, regularization_loss: 0.07471631467342377 # 11:38:01 --- INFO: epoch: 885, batch: 1, loss: 3.3614261150360107, modularity_loss: -0.6086311340332031, purity_loss: 3.895340919494629, regularization_loss: 0.07471625506877899 # 11:38:01 --- INFO: epoch: 886, batch: 1, loss: 3.361335277557373, modularity_loss: -0.6086299419403076, purity_loss: 3.895249128341675, regularization_loss: 0.07471618801355362 # 11:38:01 --- INFO: epoch: 887, batch: 1, loss: 3.361248016357422, modularity_loss: -0.6086293458938599, purity_loss: 3.8951616287231445, regularization_loss: 0.07471571862697601 # 11:38:02 --- INFO: epoch: 888, batch: 1, loss: 3.36116099357605, modularity_loss: -0.6086305379867554, purity_loss: 3.895076274871826, regularization_loss: 0.07471520453691483 # 11:38:02 --- INFO: epoch: 889, batch: 1, loss: 3.361072540283203, modularity_loss: -0.6086328029632568, purity_loss: 3.8949902057647705, regularization_loss: 0.07471514493227005 # 11:38:02 --- INFO: epoch: 890, batch: 1, loss: 3.3609845638275146, modularity_loss: -0.6086337566375732, purity_loss: 3.8949031829833984, regularization_loss: 0.07471514493227005 # 11:38:03 --- INFO: epoch: 891, batch: 1, loss: 3.3608970642089844, modularity_loss: -0.6086312532424927, purity_loss: 3.894813299179077, regularization_loss: 0.0747150406241417 # 11:38:03 --- INFO: epoch: 892, batch: 1, loss: 3.3608102798461914, modularity_loss: -0.6086273193359375, purity_loss: 3.8947224617004395, regularization_loss: 0.07471522688865662 # 11:38:03 --- INFO: epoch: 893, batch: 1, loss: 3.3607234954833984, modularity_loss: -0.608623206615448, purity_loss: 3.8946311473846436, regularization_loss: 0.0747155025601387 # 11:38:04 --- INFO: epoch: 894, batch: 1, loss: 3.3606367111206055, modularity_loss: -0.6086186170578003, purity_loss: 3.8945398330688477, regularization_loss: 0.07471556216478348 # 11:38:04 --- INFO: epoch: 895, batch: 1, loss: 3.3605518341064453, modularity_loss: -0.6086139678955078, purity_loss: 3.8944501876831055, regularization_loss: 0.07471547275781631 # 11:38:04 --- INFO: epoch: 896, batch: 1, loss: 3.3604631423950195, modularity_loss: -0.6086108684539795, purity_loss: 3.8943583965301514, regularization_loss: 0.07471547275781631 # 11:38:05 --- INFO: epoch: 897, batch: 1, loss: 3.360379219055176, modularity_loss: -0.6086083054542542, purity_loss: 3.8942723274230957, regularization_loss: 0.07471532374620438 # 11:38:05 --- INFO: epoch: 898, batch: 1, loss: 3.360293388366699, modularity_loss: -0.608607292175293, purity_loss: 3.8941855430603027, regularization_loss: 0.0747152715921402 # 11:38:05 --- INFO: epoch: 899, batch: 1, loss: 3.3602099418640137, modularity_loss: -0.6086069345474243, purity_loss: 3.89410138130188, regularization_loss: 0.07471535354852676 # 11:38:06 --- INFO: epoch: 900, batch: 1, loss: 3.3601222038269043, modularity_loss: -0.6086060404777527, purity_loss: 3.8940131664276123, regularization_loss: 0.07471512258052826 # 11:38:06 --- INFO: epoch: 901, batch: 1, loss: 3.3600378036499023, modularity_loss: -0.6086047887802124, purity_loss: 3.893927812576294, regularization_loss: 0.07471483200788498 # 11:38:06 --- INFO: epoch: 902, batch: 1, loss: 3.359954595565796, modularity_loss: -0.608603835105896, purity_loss: 3.893843650817871, regularization_loss: 0.07471473515033722 # 11:38:07 --- INFO: epoch: 903, batch: 1, loss: 3.3598713874816895, modularity_loss: -0.6086021661758423, purity_loss: 3.893758773803711, regularization_loss: 0.07471466809511185 # 11:38:07 --- INFO: epoch: 904, batch: 1, loss: 3.3597888946533203, modularity_loss: -0.6085999011993408, purity_loss: 3.89367413520813, regularization_loss: 0.07471456378698349 # 11:38:07 --- INFO: epoch: 905, batch: 1, loss: 3.3597071170806885, modularity_loss: -0.6085981130599976, purity_loss: 3.8935906887054443, regularization_loss: 0.07471449673175812 # 11:38:07 --- INFO: epoch: 906, batch: 1, loss: 3.3596251010894775, modularity_loss: -0.6085958480834961, purity_loss: 3.8935065269470215, regularization_loss: 0.07471442967653275 # 11:38:08 --- INFO: epoch: 907, batch: 1, loss: 3.3595428466796875, modularity_loss: -0.6085939407348633, purity_loss: 3.8934223651885986, regularization_loss: 0.07471437752246857 # 11:38:08 --- INFO: epoch: 908, batch: 1, loss: 3.3594632148742676, modularity_loss: -0.6085922122001648, purity_loss: 3.893341064453125, regularization_loss: 0.07471431791782379 # 11:38:08 --- INFO: epoch: 909, batch: 1, loss: 3.359382390975952, modularity_loss: -0.6085900068283081, purity_loss: 3.8932583332061768, regularization_loss: 0.07471413165330887 # 11:38:09 --- INFO: epoch: 910, batch: 1, loss: 3.3593056201934814, modularity_loss: -0.6085877418518066, purity_loss: 3.893179416656494, regularization_loss: 0.07471396774053574 # 11:38:09 --- INFO: epoch: 911, batch: 1, loss: 3.3592257499694824, modularity_loss: -0.6085848808288574, purity_loss: 3.893096685409546, regularization_loss: 0.07471387088298798 # 11:38:09 --- INFO: epoch: 912, batch: 1, loss: 3.359145402908325, modularity_loss: -0.6085816621780396, purity_loss: 3.8930132389068604, regularization_loss: 0.0747138261795044 # 11:38:10 --- INFO: epoch: 913, batch: 1, loss: 3.359071731567383, modularity_loss: -0.6085776090621948, purity_loss: 3.8929355144500732, regularization_loss: 0.0747138038277626 # 11:38:10 --- INFO: epoch: 914, batch: 1, loss: 3.3589890003204346, modularity_loss: -0.6085737943649292, purity_loss: 3.8928489685058594, regularization_loss: 0.07471388578414917 # 11:38:10 --- INFO: epoch: 915, batch: 1, loss: 3.3589136600494385, modularity_loss: -0.6085696220397949, purity_loss: 3.8927693367004395, regularization_loss: 0.07471396774053574 # 11:38:10 --- INFO: epoch: 916, batch: 1, loss: 3.358834743499756, modularity_loss: -0.6085658073425293, purity_loss: 3.892686605453491, regularization_loss: 0.07471392303705215 # 11:38:11 --- INFO: epoch: 917, batch: 1, loss: 3.3587582111358643, modularity_loss: -0.608563244342804, purity_loss: 3.8926076889038086, regularization_loss: 0.07471374422311783 # 11:38:11 --- INFO: epoch: 918, batch: 1, loss: 3.358682632446289, modularity_loss: -0.6085621118545532, purity_loss: 3.892531156539917, regularization_loss: 0.07471358776092529 # 11:38:11 --- INFO: epoch: 919, batch: 1, loss: 3.3586058616638184, modularity_loss: -0.6085608005523682, purity_loss: 3.89245343208313, regularization_loss: 0.07471328228712082 # 11:38:12 --- INFO: epoch: 920, batch: 1, loss: 3.358531951904297, modularity_loss: -0.6085584163665771, purity_loss: 3.8923773765563965, regularization_loss: 0.07471304386854172 # 11:38:12 --- INFO: epoch: 921, batch: 1, loss: 3.358454704284668, modularity_loss: -0.6085555553436279, purity_loss: 3.8922972679138184, regularization_loss: 0.07471306622028351 # 11:38:12 --- INFO: epoch: 922, batch: 1, loss: 3.358382225036621, modularity_loss: -0.608552098274231, purity_loss: 3.892221212387085, regularization_loss: 0.07471314072608948 # 11:38:13 --- INFO: epoch: 923, batch: 1, loss: 3.358306884765625, modularity_loss: -0.6085484027862549, purity_loss: 3.8921422958374023, regularization_loss: 0.07471313327550888 # 11:38:13 --- INFO: epoch: 924, batch: 1, loss: 3.3582303524017334, modularity_loss: -0.60854572057724, purity_loss: 3.8920629024505615, regularization_loss: 0.07471310347318649 # 11:38:13 --- INFO: epoch: 925, batch: 1, loss: 3.358159303665161, modularity_loss: -0.6085429191589355, purity_loss: 3.891989231109619, regularization_loss: 0.07471305876970291 # 11:38:13 --- INFO: epoch: 926, batch: 1, loss: 3.3580844402313232, modularity_loss: -0.6085397005081177, purity_loss: 3.891911268234253, regularization_loss: 0.07471288740634918 # 11:38:14 --- INFO: epoch: 927, batch: 1, loss: 3.358010768890381, modularity_loss: -0.6085366010665894, purity_loss: 3.8918347358703613, regularization_loss: 0.07471274584531784 # 11:38:14 --- INFO: epoch: 928, batch: 1, loss: 3.3579370975494385, modularity_loss: -0.6085345149040222, purity_loss: 3.891758918762207, regularization_loss: 0.07471276074647903 # 11:38:14 --- INFO: epoch: 929, batch: 1, loss: 3.3578662872314453, modularity_loss: -0.6085318922996521, purity_loss: 3.8916854858398438, regularization_loss: 0.07471269369125366 # 11:38:15 --- INFO: epoch: 930, batch: 1, loss: 3.35779070854187, modularity_loss: -0.6085291504859924, purity_loss: 3.8916072845458984, regularization_loss: 0.0747125968337059 # 11:38:15 --- INFO: epoch: 931, batch: 1, loss: 3.3577191829681396, modularity_loss: -0.6085257530212402, purity_loss: 3.8915321826934814, regularization_loss: 0.07471267879009247 # 11:38:15 --- INFO: epoch: 932, batch: 1, loss: 3.35764741897583, modularity_loss: -0.6085220575332642, purity_loss: 3.8914568424224854, regularization_loss: 0.07471269369125366 # 11:38:16 --- INFO: epoch: 933, batch: 1, loss: 3.357576847076416, modularity_loss: -0.6085176467895508, purity_loss: 3.8913819789886475, regularization_loss: 0.07471262663602829 # 11:38:16 --- INFO: epoch: 934, batch: 1, loss: 3.357503890991211, modularity_loss: -0.6085143089294434, purity_loss: 3.891305685043335, regularization_loss: 0.07471262663602829 # 11:38:16 --- INFO: epoch: 935, batch: 1, loss: 3.3574321269989014, modularity_loss: -0.6085120439529419, purity_loss: 3.8912315368652344, regularization_loss: 0.07471258193254471 # 11:38:17 --- INFO: epoch: 936, batch: 1, loss: 3.35736083984375, modularity_loss: -0.6085104942321777, purity_loss: 3.8911592960357666, regularization_loss: 0.07471216470003128 # 11:38:17 --- INFO: epoch: 937, batch: 1, loss: 3.3572921752929688, modularity_loss: -0.6085103750228882, purity_loss: 3.8910906314849854, regularization_loss: 0.07471182942390442 # 11:38:17 --- INFO: epoch: 938, batch: 1, loss: 3.3572206497192383, modularity_loss: -0.6085109114646912, purity_loss: 3.891019821166992, regularization_loss: 0.0747116357088089 # 11:38:17 --- INFO: epoch: 939, batch: 1, loss: 3.3571510314941406, modularity_loss: -0.6085106730461121, purity_loss: 3.8909502029418945, regularization_loss: 0.0747113898396492 # 11:38:18 --- INFO: epoch: 940, batch: 1, loss: 3.3570804595947266, modularity_loss: -0.6085097193717957, purity_loss: 3.890878677368164, regularization_loss: 0.07471135258674622 # 11:38:18 --- INFO: epoch: 941, batch: 1, loss: 3.3570122718811035, modularity_loss: -0.6085082292556763, purity_loss: 3.8908090591430664, regularization_loss: 0.07471150159835815 # 11:38:18 --- INFO: epoch: 942, batch: 1, loss: 3.356943130493164, modularity_loss: -0.608505129814148, purity_loss: 3.8907368183135986, regularization_loss: 0.07471148669719696 # 11:38:19 --- INFO: epoch: 943, batch: 1, loss: 3.3568732738494873, modularity_loss: -0.6085014939308167, purity_loss: 3.8906633853912354, regularization_loss: 0.0747114047408104 # 11:38:19 --- INFO: epoch: 944, batch: 1, loss: 3.3568053245544434, modularity_loss: -0.6084985733032227, purity_loss: 3.890592336654663, regularization_loss: 0.07471145689487457 # 11:38:19 --- INFO: epoch: 945, batch: 1, loss: 3.3567354679107666, modularity_loss: -0.6084975600242615, purity_loss: 3.89052152633667, regularization_loss: 0.07471141964197159 # 11:38:20 --- INFO: epoch: 946, batch: 1, loss: 3.3566694259643555, modularity_loss: -0.6084966659545898, purity_loss: 3.8904547691345215, regularization_loss: 0.07471121847629547 # 11:38:20 --- INFO: epoch: 947, batch: 1, loss: 3.3566014766693115, modularity_loss: -0.6084957122802734, purity_loss: 3.8903861045837402, regularization_loss: 0.0747111588716507 # 11:38:20 --- INFO: epoch: 948, batch: 1, loss: 3.3565309047698975, modularity_loss: -0.6084946393966675, purity_loss: 3.8903143405914307, regularization_loss: 0.07471119612455368 # 11:38:20 --- INFO: epoch: 949, batch: 1, loss: 3.3564648628234863, modularity_loss: -0.6084920167922974, purity_loss: 3.8902456760406494, regularization_loss: 0.07471106946468353 # 11:38:21 --- INFO: epoch: 950, batch: 1, loss: 3.3563952445983887, modularity_loss: -0.6084898114204407, purity_loss: 3.89017391204834, regularization_loss: 0.07471103221178055 # 11:38:21 --- INFO: epoch: 951, batch: 1, loss: 3.3563313484191895, modularity_loss: -0.6084879636764526, purity_loss: 3.890108346939087, regularization_loss: 0.07471106201410294 # 11:38:21 --- INFO: epoch: 952, batch: 1, loss: 3.356266975402832, modularity_loss: -0.6084863543510437, purity_loss: 3.890042304992676, regularization_loss: 0.074710913002491 # 11:38:22 --- INFO: epoch: 953, batch: 1, loss: 3.356199264526367, modularity_loss: -0.6084855794906616, purity_loss: 3.8899741172790527, regularization_loss: 0.07471081614494324 # 11:38:22 --- INFO: epoch: 954, batch: 1, loss: 3.356135845184326, modularity_loss: -0.6084851026535034, purity_loss: 3.8899102210998535, regularization_loss: 0.07471080124378204 # 11:38:22 --- INFO: epoch: 955, batch: 1, loss: 3.3560678958892822, modularity_loss: -0.6084853410720825, purity_loss: 3.8898427486419678, regularization_loss: 0.07471051812171936 # 11:38:23 --- INFO: epoch: 956, batch: 1, loss: 3.356001377105713, modularity_loss: -0.6084868907928467, purity_loss: 3.8897781372070312, regularization_loss: 0.0747101902961731 # 11:38:23 --- INFO: epoch: 957, batch: 1, loss: 3.3559372425079346, modularity_loss: -0.6084891557693481, purity_loss: 3.889716386795044, regularization_loss: 0.074709951877594 # 11:38:23 --- INFO: epoch: 958, batch: 1, loss: 3.3558707237243652, modularity_loss: -0.6084906458854675, purity_loss: 3.8896515369415283, regularization_loss: 0.07470972836017609 # 11:38:24 --- INFO: epoch: 959, batch: 1, loss: 3.355807304382324, modularity_loss: -0.6084908246994019, purity_loss: 3.8895885944366455, regularization_loss: 0.07470959424972534 # 11:38:24 --- INFO: epoch: 960, batch: 1, loss: 3.355739116668701, modularity_loss: -0.6084907054901123, purity_loss: 3.8895201683044434, regularization_loss: 0.07470975816249847 # 11:38:24 --- INFO: epoch: 961, batch: 1, loss: 3.3556771278381348, modularity_loss: -0.6084891557693481, purity_loss: 3.889456272125244, regularization_loss: 0.07470987737178802 # 11:38:25 --- INFO: epoch: 962, batch: 1, loss: 3.3556151390075684, modularity_loss: -0.6084870100021362, purity_loss: 3.889392375946045, regularization_loss: 0.07470982521772385 # 11:38:25 --- INFO: epoch: 963, batch: 1, loss: 3.35555362701416, modularity_loss: -0.608485221862793, purity_loss: 3.889328956604004, regularization_loss: 0.07470980286598206 # 11:38:25 --- INFO: epoch: 964, batch: 1, loss: 3.3554887771606445, modularity_loss: -0.6084840893745422, purity_loss: 3.889263153076172, regularization_loss: 0.07470960915088654 # 11:38:26 --- INFO: epoch: 965, batch: 1, loss: 3.355426549911499, modularity_loss: -0.6084831953048706, purity_loss: 3.889200448989868, regularization_loss: 0.07470928132534027 # 11:38:26 --- INFO: epoch: 966, batch: 1, loss: 3.355362892150879, modularity_loss: -0.6084827184677124, purity_loss: 3.88913631439209, regularization_loss: 0.07470914721488953 # 11:38:26 --- INFO: epoch: 967, batch: 1, loss: 3.3552968502044678, modularity_loss: -0.6084824204444885, purity_loss: 3.8890700340270996, regularization_loss: 0.07470916956663132 # 11:38:27 --- INFO: epoch: 968, batch: 1, loss: 3.355233907699585, modularity_loss: -0.6084803938865662, purity_loss: 3.889005184173584, regularization_loss: 0.07470910996198654 # 11:38:27 --- INFO: epoch: 969, batch: 1, loss: 3.355172634124756, modularity_loss: -0.6084768772125244, purity_loss: 3.8889403343200684, regularization_loss: 0.07470916956663132 # 11:38:27 --- INFO: epoch: 970, batch: 1, loss: 3.355111837387085, modularity_loss: -0.6084741353988647, purity_loss: 3.8888766765594482, regularization_loss: 0.07470931112766266 # 11:38:28 --- INFO: epoch: 971, batch: 1, loss: 3.3550498485565186, modularity_loss: -0.6084709167480469, purity_loss: 3.8888115882873535, regularization_loss: 0.07470913976430893 # 11:38:28 --- INFO: epoch: 972, batch: 1, loss: 3.3549880981445312, modularity_loss: -0.6084688901901245, purity_loss: 3.8887481689453125, regularization_loss: 0.07470890879631042 # 11:38:28 --- INFO: epoch: 973, batch: 1, loss: 3.3549273014068604, modularity_loss: -0.6084681153297424, purity_loss: 3.8886866569519043, regularization_loss: 0.07470883429050446 # 11:38:29 --- INFO: epoch: 974, batch: 1, loss: 3.354865550994873, modularity_loss: -0.6084681749343872, purity_loss: 3.888624906539917, regularization_loss: 0.07470870018005371 # 11:38:29 --- INFO: epoch: 975, batch: 1, loss: 3.3548054695129395, modularity_loss: -0.608467698097229, purity_loss: 3.8885645866394043, regularization_loss: 0.07470859587192535 # 11:38:29 --- INFO: epoch: 976, batch: 1, loss: 3.354745626449585, modularity_loss: -0.6084665060043335, purity_loss: 3.8885035514831543, regularization_loss: 0.07470859587192535 # 11:38:30 --- INFO: epoch: 977, batch: 1, loss: 3.3546838760375977, modularity_loss: -0.6084654331207275, purity_loss: 3.8884408473968506, regularization_loss: 0.07470858097076416 # 11:38:30 --- INFO: epoch: 978, batch: 1, loss: 3.3546218872070312, modularity_loss: -0.6084632873535156, purity_loss: 3.8883767127990723, regularization_loss: 0.07470840215682983 # 11:38:30 --- INFO: epoch: 979, batch: 1, loss: 3.3545637130737305, modularity_loss: -0.6084608435630798, purity_loss: 3.8883161544799805, regularization_loss: 0.07470832020044327 # 11:38:31 --- INFO: epoch: 980, batch: 1, loss: 3.3545026779174805, modularity_loss: -0.6084582805633545, purity_loss: 3.8882527351379395, regularization_loss: 0.07470832020044327 # 11:38:31 --- INFO: epoch: 981, batch: 1, loss: 3.3544421195983887, modularity_loss: -0.6084554195404053, purity_loss: 3.8881893157958984, regularization_loss: 0.07470821589231491 # 11:38:31 --- INFO: epoch: 982, batch: 1, loss: 3.354381799697876, modularity_loss: -0.6084536910057068, purity_loss: 3.888127565383911, regularization_loss: 0.07470792531967163 # 11:38:32 --- INFO: epoch: 983, batch: 1, loss: 3.3543262481689453, modularity_loss: -0.6084543466567993, purity_loss: 3.8880727291107178, regularization_loss: 0.0747077539563179 # 11:38:32 --- INFO: epoch: 984, batch: 1, loss: 3.3542652130126953, modularity_loss: -0.6084551811218262, purity_loss: 3.8880128860473633, regularization_loss: 0.07470749318599701 # 11:38:32 --- INFO: epoch: 985, batch: 1, loss: 3.3542048931121826, modularity_loss: -0.6084557771682739, purity_loss: 3.887953519821167, regularization_loss: 0.07470718771219254 # 11:38:32 --- INFO: epoch: 986, batch: 1, loss: 3.354147434234619, modularity_loss: -0.6084555387496948, purity_loss: 3.8878958225250244, regularization_loss: 0.07470723986625671 # 11:38:33 --- INFO: epoch: 987, batch: 1, loss: 3.3540899753570557, modularity_loss: -0.6084539890289307, purity_loss: 3.8878366947174072, regularization_loss: 0.07470730692148209 # 11:38:33 --- INFO: epoch: 988, batch: 1, loss: 3.3540306091308594, modularity_loss: -0.6084518432617188, purity_loss: 3.887775182723999, regularization_loss: 0.07470717281103134 # 11:38:33 --- INFO: epoch: 989, batch: 1, loss: 3.3539719581604004, modularity_loss: -0.6084514856338501, purity_loss: 3.887716293334961, regularization_loss: 0.07470714300870895 # 11:38:34 --- INFO: epoch: 990, batch: 1, loss: 3.353915214538574, modularity_loss: -0.608452558517456, purity_loss: 3.887660503387451, regularization_loss: 0.07470720261335373 # 11:38:34 --- INFO: epoch: 991, batch: 1, loss: 3.3538575172424316, modularity_loss: -0.6084526777267456, purity_loss: 3.8876030445098877, regularization_loss: 0.07470700889825821 # 11:38:34 --- INFO: epoch: 992, batch: 1, loss: 3.3538012504577637, modularity_loss: -0.6084530353546143, purity_loss: 3.887547492980957, regularization_loss: 0.0747067853808403 # 11:38:35 --- INFO: epoch: 993, batch: 1, loss: 3.3537447452545166, modularity_loss: -0.6084531545639038, purity_loss: 3.887491226196289, regularization_loss: 0.07470668852329254 # 11:38:35 --- INFO: epoch: 994, batch: 1, loss: 3.353687286376953, modularity_loss: -0.6084524393081665, purity_loss: 3.8874335289001465, regularization_loss: 0.0747063159942627 # 11:38:35 --- INFO: epoch: 995, batch: 1, loss: 3.3536300659179688, modularity_loss: -0.6084518432617188, purity_loss: 3.887375831604004, regularization_loss: 0.07470611482858658 # 11:38:36 --- INFO: epoch: 996, batch: 1, loss: 3.353571891784668, modularity_loss: -0.6084519624710083, purity_loss: 3.887317657470703, regularization_loss: 0.07470627874135971 # 11:38:36 --- INFO: epoch: 997, batch: 1, loss: 3.353517770767212, modularity_loss: -0.608451247215271, purity_loss: 3.8872628211975098, regularization_loss: 0.07470627874135971 # 11:38:36 --- INFO: epoch: 998, batch: 1, loss: 3.353461265563965, modularity_loss: -0.6084499955177307, purity_loss: 3.887204885482788, regularization_loss: 0.07470636069774628 # 11:38:37 --- INFO: epoch: 999, batch: 1, loss: 3.3534069061279297, modularity_loss: -0.6084499359130859, purity_loss: 3.887150526046753, regularization_loss: 0.07470645755529404 # 11:38:37 --- INFO: epoch: 1000, batch: 1, loss: 3.3533525466918945, modularity_loss: -0.6084506511688232, purity_loss: 3.887096881866455, regularization_loss: 0.07470621913671494 # 11:38:37 --- INFO: Training process end. # 11:38:37 --- INFO: Evaluating process start. # 11:38:37 --- INFO: Evaluate loss, {&#39;modularity_loss&#39;: -0.6084526777267456, &#39;purity_loss&#39;: 3.8870439529418945, &#39;regularization_loss&#39;: 0.07470588386058807, &#39;total_loss&#39;: 3.353297233581543} # 11:38:37 --- INFO: Evaluating process end. # 11:38:37 --- INFO: Predicting process start. # 11:38:37 --- INFO: Generating prediction results for mouse2_slice229. # 11:38:38 --- INFO: Generating prediction results for mouse2_slice300. # 11:38:38 --- INFO: Predicting process end. # 11:38:38 --- INFO: --------------------- GNN end ---------------------- # 11:38:38 --- INFO: ----------------- Niche trajectory ------------------ # 11:38:38 --- INFO: Loading consolidate s_array and out_adj_array... # 11:38:38 --- INFO: Loading dataset. # 11:38:38 --- INFO: Maximum number of cell in one sample is: 5100. # Processing... # 11:38:38 --- INFO: Processing sample 1 of 2: mouse2_slice229 # 11:38:39 --- INFO: Processing sample 2 of 2: mouse2_slice300 # Done! # 11:38:39 --- INFO: Processing sample 1 of 2: mouse2_slice229 # 11:38:39 --- INFO: Processing sample 2 of 2: mouse2_slice300 # 11:38:39 --- INFO: Calculating NTScore for each niche. # 11:38:39 --- INFO: Finding niche trajectory with maximum connectivity using Brute Force. # 11:38:39 --- INFO: Calculating NTScore for each niche cluster based on the trajectory path. # 11:38:39 --- INFO: Projecting NTScore from niche-level to cell-level. # 11:38:39 --- INFO: Output NTScore tables. # 11:38:39 --- INFO: --------------- Niche trajectory end ---------------- 16.1.3 visualization 16.1.3.1 load ONTraC results giotto_obj &lt;- loadOntraCResults(gobject = giotto_obj, ontrac_results_dir = data_path) The NTScore and binarized niche cluster info were stored in cell metadata head(pDataDT(giotto_obj, spat_unit = &quot;cell&quot;, feat_type = &quot;niche cluster&quot;)) # cell_ID sample_id slice_id class_label subclass label list_ID NicheCluster NTScore # &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;int&gt; &lt;num&gt; # 1: mouse2_slice229-100101435705986292663283283043431511315 mouse2_sample6 mouse2_slice229 Glutamatergic L6 CT L6_CT_5 mouse2_slice229 2 0.7998957 # 2: mouse2_slice229-100104370212612969023746137269354247741 mouse2_sample6 mouse2_slice229 Other OPC OPC mouse2_slice229 0 0.2003027 # 3: mouse2_slice229-100128078183217482733448056590230529739 mouse2_sample6 mouse2_slice229 Glutamatergic L2/3 IT L23_IT_4 mouse2_slice229 0 0.2350597 # 4: mouse2_slice229-100209662400867003194056898065587980841 mouse2_sample6 mouse2_slice229 Other Oligo Oligo_1 mouse2_slice229 1 0.3990417 # 5: mouse2_slice229-100218038012295593766653119076639444055 mouse2_sample6 mouse2_slice229 Glutamatergic L2/3 IT L23_IT_4 mouse2_slice229 0 0.2910255 # 6: mouse2_slice229-100252992997994275968450436343196667192 mouse2_sample6 mouse2_slice229 Other Astro Astro_2 mouse2_slice229 2 0.8007477 The probability matrix of each cell assigned to each niche cluster and connectivity between niche cluster were stored here. GiottoClass::list_expression(giotto_obj) # spat_unit feat_type name # &lt;char&gt; &lt;char&gt; &lt;char&gt; # 1: cell rna raw # 2: cell niche cluster prob # 3: niche cluster connectivity normalized 16.1.3.2 niche cluster prob spatFeatPlot2D(gobject = giotto_obj, spat_unit = &#39;cell&#39;, feat_type = &#39;niche cluster&#39;, expression_values = &quot;prob&quot;, group_by = &#39;list_ID&#39;, feats = rownames(giotto_obj@expression$cell$`niche cluster`$prob), point_border_col = &#39;gray&#39; ) 16.1.3.3 binarized niche cluster spatPlot2D(giotto_obj, spat_unit = &quot;cell&quot;, group_by = &#39;list_ID&#39;, cell_color = &quot;NicheCluster&quot;, color_as_factor = T, point_size = 1, point_border_stroke = NA, title=&quot;Niche cluster&quot;) 16.1.3.4 niche cluster spatial connectivity set.seed(100) # fix the node positions plotNicheClusterConnectivity(gobject = giotto_obj) 16.1.3.5 NT score spatPlot2D(gobject = giotto_obj, spat_unit = &#39;cell&#39;, feat_type = &#39;rna&#39;, group_by = &#39;list_ID&#39;, cell_color = &quot;NTScore&quot;, color_as_factor = FALSE, cell_color_gradient = &quot;turbo&quot;, point_size = 1, point_border_stroke = NA ) plotCellTypeNTScore(gobject = giotto_obj, cell_type = &quot;subclass&quot;) 16.1.3.6 Cell type composition within niche cluster plotCTCompositionInNicheCluster(gobject = giotto_obj, cell_type = &quot;subclass&quot;) "],["interactivity-with-the-rspatial-ecosystem.html", "17 Interactivity with the R/Spatial ecosystem 17.1 Kriging 17.2 Downloading the dataset 17.3 Importing visium data 17.4 Adding cell polygons to Giotto object 17.5 Performing kriging 17.6 Reading in larger dataset 17.7 Analyzing interpolated features", " 17 Interactivity with the R/Spatial ecosystem Jeff Sheridan August 7th 2024 17.1 Kriging Low resolution spatial data typically covers multiple cells making it difficult to delineate the cell contribution to gene expression. Using a process called kriging we can interpolate gene expression at the single cell levels from low resolution datasets. Kriging is a spatial interpolation technique that estimates unknown values at specific locations by weighing nearby known values based on distance and spatial trends. It uses a model to account for both the distance between points and the overall pattern in the data to make accurate predictions. By taking discrete measurement spots, such as those used for visium, we can interpolate gene expression to a finer scale using kriging. 17.1.1 Visium technology Figure 17.1: Overview of Visium. Source: 10X Genomics. Visium by 10x Genomics is a spatial gene expression platform that allows for the mapping of gene expression to high-resolution histology through RNA sequencing The process involves placing a tissue section on a specially prepared slide with an array of barcoded spots, which are 55 µm in diameter with a spot to spot distance of 100 µm. Each spot contains unique barcodes that capture the mRNA from the tissue section, preserving the spatial information. After the tissue is imaged and RNA is captured, the mRNA is sequenced, and the data is mapped back to the tissue’s spatial coordinates. This technology is particularly useful in understanding complex tissue environments, such as tumors, by providing insights into how gene expression varies across different regions. 17.1.2 Dataset For this tutorial we’ll be using the mouse brain dataset described in section 6. Visium datasets require a high resolution H&amp;E or IF image to align spots to. Using these images we can identify individual nuclei and cells to be used for kriging. Identifying nuclei is outside the scope of the current tutorial but is required to perform kriging. 17.1.3 Generating a geojson file of nuclei location For the following sections we will need to create a geojson that contains polygon information for the nuclei in the sample. We will be providing this in the following link, however when using for your own datasets this will need to be done outside of Giotto. A tutorial for this using qupath can be found here. 17.2 Downloading the dataset We first need to import a dataset that we want to perform kriging on. data_directory &lt;- &quot;data&quot; download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Adult_Mouse_Brain/V1_Adult_Mouse_Brain_raw_feature_bc_matrix.tar.gz&quot;, destfile = &quot;data/V1_Adult_Mouse_Brain_raw_feature_bc_matrix.tar.gz&quot;) download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Adult_Mouse_Brain/V1_Adult_Mouse_Brain_spatial.tar.gz&quot;, destfile = &quot;data/V1_Adult_Mouse_Brain_spatial.tar.gz&quot;) After downloading, unzip the gz files. You should get the “raw_feature_bc_matrix” and “spatial” folders inside “data/”. 17.3 Importing visium data We’re going to begin by creating a Giotto object for the visium mouse brain dataset. This tutorial won’t go into detail about each of these steps as these have been covered for this dataset in section 6. To get the best results when performing gene expression interpolation we need to identify spatially distinct genes. Therefore, we need to perform nearest neighbour to create a spatial network. library(Giotto) save_directory &lt;- &#39;results&#39; visium_save_directory &lt;- file.path(save_directory, &#39;visium_mouse_brain&#39;) subcell_save_directory &lt;- file.path(save_directory, &#39;pseudo_subcellular/&#39;) instrs &lt;- createGiottoInstructions(show_plot = TRUE, save_plot = TRUE, save_dir = visium_save_directory) v_brain &lt;- createGiottoVisiumObject(data_directory, gene_column_index = 2, instructions = instrs) # Subset to in tissue only cm = pDataDT(v_brain) in_tissue_barcodes = cm[in_tissue == 1]$cell_ID v_brain = subsetGiotto(v_brain, cell_ids = in_tissue_barcodes) # Filter v_brain = filterGiotto(gobject = v_brain, expression_threshold = 1, feat_det_in_min_cells = 50, min_det_feats_per_cell = 1000, expression_values = c(&#39;raw&#39;)) # Normalize v_brain = normalizeGiotto(gobject = v_brain, scalefactor = 6000, verbose = TRUE) # Add stats v_brain = addStatistics(gobject = v_brain) # ID HVF v_brain = calculateHVF(gobject = v_brain, method = &quot;cov_loess&quot;) fm = fDataDT(v_brain) hv_feats = fm[hvf == &#39;yes&#39; &amp; perc_cells &gt; 3 &amp; mean_expr_det &gt; 0.4]$feat_ID length(hv_feats) # Dimension Reductions v_brain = runPCA(gobject = v_brain, feats_to_use = hv_feats) v_brain = runUMAP(v_brain, dimensions_to_use = 1:10, n_neighbors = 15, set_seed = TRUE) # NN Network v_brain = createNearestNetwork(gobject = v_brain, dimensions_to_use = 1:10, k = 15) # Leiden Cluster v_brain = doLeidenCluster(gobject = v_brain, resolution = 0.4, n_iterations = 1000, set_seed = TRUE) # Spatial Network (kNN) v_brain &lt;- createSpatialNetwork(gobject = v_brain, method = &#39;kNN&#39;, k = 5, maximum_distance_knn = 400, name = &#39;spatial_network&#39;) spatPlot2D(gobject = v_brain, spat_unit = &#39;cell&#39;, cell_color = &#39;leiden_clus&#39;, show_image = T, point_size = 1.5, point_shape = &#39;no_border&#39;, background_color = &#39;black&#39;, show_legend = TRUE, save_plot = T, save_param = list(save_name = &#39;03_ses6_1_vis_spat&#39;)) Here we can see the clustering of the regular visium spots is able to identify distinct regions of the mouse brain. Figure 17.2: Mouse brain spatial plot showing leiden clustering 17.3.1 Identifying spatially organized features We need to identify genes to be used for interpolation. This works best with genes that are spatially distinct. To identify these genes we’ll use binSpect(). For this tutorial we’ll only use the top 15 spatially distinct genes. The more genes used for interpolation the longer the analysis will take. When running this for your own datasets you should use more genes. We are only using 15 here to minimize analysis time. # Spatially Variable Features ranktest = binSpect(v_brain, bin_method = &#39;rank&#39;, calc_hub = T, hub_min_int = 5, spatial_network_name = &#39;spatial_network&#39;, do_parallel = T, cores = 8) #not able to provide a seed number, so do not set one # Getting the top 15 spatially organized genes ext_spatial_features = ranktest[1:15,]$feats 17.4 Adding cell polygons to Giotto object 17.4.1 Read in the poly information First we need to read in the geojson file that contains the cell polygons that we’ll interpolate gene expression onto. These will then be added to the Giotto object as a new polygon object. This won’t affect the visium polygons. Both polygons will be stored within the same Giotto object. # Read in the data stardist_cell_poly_path &lt;- file.path(data_directory, &quot;segmentations/stardist_only_cell_bounds.geojson&quot;) stardist_cell_gpoly &lt;- createGiottoPolygonsFromGeoJSON(GeoJSON = stardist_cell_poly_path, name = &quot;stardist_cell&quot;, calc_centroids = TRUE) stardist_cell_gpoly &lt;- flip(stardist_cell_gpoly) 17.4.2 Vizualizing polygons Below we can see a vizualization of the polygons for the visium and the nuclei we identified from the H&amp;E image. The visium dataset has 2698 spots compared to teh 36694 nuclei we identified. Just using the visium spots we’re therefore losing a lot of the spatial data for individual cells. With the increased number of spots and them directly correlating with the tissue, through the spots alone we are able to better see the actual sturcture of the mouse brain. plot(getPolygonInfo(v_brain)) plot(stardist_cell_gpoly, max_poly = 1e6) Figure 17.3: Mouse brain cell polygons from the visium dataset Figure 17.4: Mouse brain cell polygons with artifacts removed and flipped 17.4.3 Showing Giotto object prior to polygon addition Before we add the polygons we’re can see the gobject contains ‘cell’ as a spatial unit and a polygon. print(v_brain) Figure 17.5: Giotto object before adding subcellular polygons. 17.4.4 Adding polygons to giotto object After we add the nuclei polygons we can see that a new polygon name, ‘stardist_cell’ has been added to the gobject. v_brain &lt;- addGiottoPolygons(v_brain, gpolygons = list(&#39;stardist_cell&#39; = stardist_cell_gpoly)) print(v_brain) Figure 17.6: Giotto object after to adding subcellular polygons. 17.4.5 Check polygon information We can now see the addition of the new polygons under the name ‘stardist_cell’. Each of the new polyons is given a unique poly_ID as shown below. Each polygon is also added into same space as the original visium spots, therefore line up with the same image as the visium spots. poly_info &lt;- getPolygonInfo(v_brain,polygon_name = &#39;stardist_cell&#39;) print(poly_info) Figure 17.7: Polygon information for stardist_cell. 17.5 Performing kriging 17.5.1 Interpolating features Now we can perform the first step in interpolating expression data onto cell polygons. This involves creating a raster image for the gene expression of each of the selected genes. The steps from here can be time consuming and require large amounts of memory. We will only be analyzing 15 genes to show the process of expression interpolation. For clustering and other analyses more genes are required. future::plan(future::multisession()) # comment out for single threading subcell_v_brain &lt;- interpolateFeature(v_brain, spat_unit = &#39;cell&#39;, feat_type = &#39;rna&#39;, ext = ext(v_brain), feats = ext_spatial_features, overwrite = T) print(subcell_v_brain) Figure 17.8: Giotto object after to interpolating features. Addition of images for each interoplated feature (left) and an example of rasterized gene expression image (right). For each gene that we interpolate a raster image is exported based on the gene expression. Shown below is an example of an output for the gene Pantr1. Figure 17.9: Raster of gene expression interpolation for Pantr1 17.5.2 Expression overlap The raster we created above gives the gene expression in a graphical form. We next need to determine how that relates to the nuclei location. To determine that we will calculate the overlap of the rasterized gene expression image to the polygons supplied earlier. This step also takes more time the more genes that are provided. For large datasets please allow up to multiple hours for these steps to run. subcell_v_brain &lt;- calculateOverlapPolygonImages(gobject = subcell_v_brain, name_overlap = &quot;rna&quot;, spatial_info = &quot;stardist_cell&quot;, image_names = ext_spatial_features) subcell_v_brain &lt;- Giotto::overlapToMatrix(x = subcell_v_brain, poly_info = &quot;stardist_cell&quot;, feat_info = &quot;rna&quot;, aggr_function = &quot;sum&quot;, type=&#39;intensity&#39;) After performing the overlap we now have expression data for each gene provided. This can be seen below where we see the interpolated gene expression for genes in each of the nuclei we identified. Figure 17.10: Gene expression for cells based on interpolation. 17.6 Reading in larger dataset For better results more genes are required. The above data used only 15 genes. We will now read in a dataset that has 1500 interpolated genes an use this for the remained of the tutorial. If you haven’t downloaded this dataset please download it here. subcell_v_brain &lt;- loadGiotto(file.path(data_directory, &#39;subcellular_gobject&#39;)) 17.7 Analyzing interpolated features 17.7.1 Filter and normalization Now that we have a valid spat unit and gene expression data for each of the provided genes we can now perform the same analyses we used for the regular visium data. Please note that due to the differences in cell number that the valeus used for the current analysis aren’t identical to the visium analysis. subcell_v_brain &lt;- filterGiotto(gobject = subcell_v_brain, spat_unit = &quot;stardist_cell&quot;, expression_values = &quot;raw&quot;, expression_threshold = 1, feat_det_in_min_cells = 0, min_det_feats_per_cell = 1) subcell_v_brain &lt;- normalizeGiotto(gobject = subcell_v_brain, spat_unit = &quot;stardist_cell&quot;, scalefactor = 6000, verbose = T) 17.7.2 Visualizing gene expression from interpolated expression Since we have the gene expression information for both the visium and the interpolated gene expression we can vizualize gene expression for both from the same Giotto object. We will look at the expression for two genes ‘Sparc’ and ‘Pantr1’ for both the visium and interpolated data. spatFeatPlot2D(subcell_v_brain, spat_unit = &#39;cell&#39;, gradient_style = &#39;sequential&#39;, cell_color_gradient = &#39;Geyser&#39;, feats = &#39;Sparc&#39;, point_size = 2, save_plot = TRUE, show_image = TRUE, save_param = list(save_name = &#39;03_ses6_sparc_vis&#39;)) spatFeatPlot2D(subcell_v_brain, spat_unit = &#39;stardist_cell&#39;, gradient_style = &#39;sequential&#39;, cell_color_gradient = &#39;Geyser&#39;, feats = &#39;Sparc&#39;, point_size = 0.6, save_plot = TRUE, show_image = TRUE, save_param = list(save_name = &#39;03_ses6_sparc&#39;)) spatFeatPlot2D(subcell_v_brain, spat_unit = &#39;cell&#39;, gradient_style = &#39;sequential&#39;, feats = &#39;Pantr1&#39;, cell_color_gradient = &#39;Geyser&#39;, point_size = 2, save_plot = TRUE, show_image = TRUE, save_param = list(save_name = &#39;03_ses6_pantr1_vis&#39;)) spatFeatPlot2D(subcell_v_brain, spat_unit = &#39;stardist_cell&#39;, gradient_style = &#39;sequential&#39;, cell_color_gradient = &#39;Geyser&#39;, feats = &#39;Pantr1&#39;, point_size = 0.6, save_plot = TRUE, show_image = TRUE, save_param = list(save_name = &#39;03_ses6_pantr1&#39;)) Below we can see the gene expression for both datatypes. With the interpolated gene expression we’re able to get a better idea as to the cells that are expressing each of the genes. This is especially clear with Pantr1, which clearly localizes to the pyramidal layer. Figure 17.11: Gene expression for visium (left) and interpolated (right) expression for Sparc (top) and Pantr1 (bottom). 17.7.3 Run PCA subcell_v_brain &lt;- runPCA(gobject = subcell_v_brain, spat_unit = &quot;stardist_cell&quot;, expression_values = &quot;normalized&quot;, feats_to_use = NULL) 17.7.4 Clustering # UMAP subcell_v_brain &lt;- runUMAP(subcell_v_brain, spat_unit = &quot;stardist_cell&quot;, dimensions_to_use = 1:15, n_neighbors = 1000, min_dist = 0.001, spread = 1) # NN Network subcell_v_brain &lt;- createNearestNetwork(gobject = subcell_v_brain, spat_unit = &quot;stardist_cell&quot;, dimensions_to_use = 1:10, feats_to_use = hv_feats, expression_values = &#39;normalized&#39;, k = 70) subcell_v_brain &lt;- doLeidenCluster(gobject = subcell_v_brain, spat_unit = &quot;stardist_cell&quot;, resolution = 0.15, n_iterations = 100, partition_type = &#39;RBConfigurationVertexPartition&#39;) plotUMAP(subcell_v_brain, spat_unit = &#39;stardist_cell&#39;, cell_color = &#39;leiden_clus&#39;) Figure 17.12: UMAP for stardist_cell based on the 1500 interpolated gene expressions. Colored based on leiden clustering. 17.7.5 Visualizing clustering Vizualizing the clustering for both the visium dataset and the interpolated dataset we can similar clusters. However, with the interpolated dataset we are able to see finer detail for each cluster. spatPlot2D(gobject = subcell_v_brain, spat_unit = &#39;cell&#39;, cell_color = &#39;leiden_clus&#39;, show_image = T, point_size = 0.5, point_shape = &#39;no_border&#39;, background_color = &#39;black&#39;, save_plot = F, show_legend = TRUE) spatPlot2D(gobject = subcell_v_brain, spat_unit = &#39;stardist_cell&#39;, cell_color = &#39;leiden_clus&#39;, show_image = T, point_size = 0.1, point_shape = &#39;no_border&#39;, background_color = &#39;black&#39;, show_legend = TRUE, save_plot = TRUE, save_param = list(save_name = &#39;03_ses6_subcell_spat&#39;)) Figure 17.13: Spatial plots showing leiden clustering mapped onto the base visium spots (left) and individual nuceli through interpolation (right) 17.7.6 Cropping objects We are also able to crop both spat units simultaneosly to zoom in on specific regions of the tissue such as seen below. subcell_v_brain_crop &lt;- subsetGiottoLocs(gobject = subcell_v_brain, spat_unit = &quot;:all:&quot;, x_min = 4000, x_max = 7000, y_min = -6500, y_max = -3500, z_max = NULL, z_min = NULL) spatPlot2D(gobject = subcell_v_brain_crop, spat_unit = &#39;cell&#39;, cell_color = &#39;leiden_clus&#39;, show_image = T, point_size = 2, point_shape = &#39;no_border&#39;, background_color = &#39;black&#39;, show_legend = TRUE, save_plot = TRUE, save_param = list(save_name = &#39;03_ses6_vis_spat_crop&#39;)) spatPlot2D(gobject = subcell_v_brain_crop, spat_unit = &#39;stardist_cell&#39;, cell_color = &#39;leiden_clus&#39;, show_image = T, point_size = 0.1, point_shape = &#39;no_border&#39;, background_color = &#39;black&#39;, show_legend = TRUE, save_plot = TRUE, save_param = list(save_name = &#39;03_ses6_subcell_spat_crop&#39;)) Figure 17.14: Spatial plots showing leiden clustering mapped onto the base visium spots (left) and individual nuceli through interpolation (right) "],["contributing-to-giotto.html", "18 Contributing to Giotto 18.1 Contribution guideline", " 18 Contributing to Giotto Jiaji George Chen August 7th 2024 save_dir &lt;- &quot;~/Documents/GitHub/giotto_workshop_2024/img/03_session7&quot; 18.1 Contribution guideline https://drieslab.github.io/Giotto_website/CONTRIBUTING.html "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
